{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00910a35-ffbc-4497-bcc8-21f008c326fb",
   "metadata": {},
   "source": [
    "# Grapher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd8be8-14cc-4d80-a944-76c5235c078b",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99bc773-edf8-4567-8767-a742662cb8ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### UKBB_94traits_release1.{tsv|bed}.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef1038-e49a-4607-9c7d-5ce6daf1d94b",
   "metadata": {},
   "source": [
    "This file contains genetic variant data used in a study investigating 94 complex diseases and traits from the UK Biobank. Each row represents a variant with columns detailing characteristics such as its genomic location, allele details, association statistics, and more. It also includes indicators for linkage disequilibrium with variants failing Hardy Weinberg equilibrium or with common structural variants. This file is particularly valuable for those interested in the genetic association results and the fine-mapping of these traits and diseases.\n",
    "\n",
    "Columns:\n",
    "\n",
    "1. Chromosome: hg19 autosomes only\n",
    "2. Start: 0-indexed hg19 start position\n",
    "3. End: 0-indexed hg19 end position\n",
    "4. Variant: unique variant identifier (chr:pos:ref:alt)\n",
    "5. rsid: rsid identifier\n",
    "6. Allele1: reference allele in hg19\n",
    "7. Allele2: alternative allele in hg19\n",
    "8. Minor allele: minor allele in cohort\n",
    "9. Cohort: GWAS cohort\n",
    "10. Model_marginal: type of regression model used\n",
    "11. Method: fine-mapping method used\n",
    "12. Trait: abbreviation for phenotype in genetic association tests\n",
    "13. Region: fine-mapping region in hg19\n",
    "14. MAF: minor allele frequency in cohort\n",
    "15. Beta_marginal: marginal association effect size (effect allele: alternative)\n",
    "16. SE_marginal: standard error on marginal association effect size\n",
    "17. Chisq_marginal: test statistic for marginal association\n",
    "18. PIP: posterior probability of association from fine-mapping\n",
    "19. CS_ID: ID of 95% credible set (-1 if variant not in 95% CS)\n",
    "20. Beta_posterior: posterior expectation of true effect size (effect allele: alternative)\n",
    "21. SD_posterior: posterior standard deviation of true effect size\n",
    "22. LD_HWE: indicator for LD (R^2 > 0.6) with a variant that failed HWE (p < 10^-12) in UK10K LD\n",
    "23. LD_SV: indicator for LD (R^2 > 0.8) with a common structural variant in gnomAD European samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b033d-95f5-4584-b10c-72969a166612",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4345459-b1ef-477c-8f06-c8f54c194af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "\n",
    "import networkx as nx\n",
    "from ogb.io import DatasetSaver\n",
    "from ogb.linkproppred import LinkPropPredDataset\n",
    "\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f7ab7-4bf0-4dba-9428-9580338d9aa7",
   "metadata": {},
   "source": [
    "## Perform checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b729b64d-2166-4dbb-9c4c-4173e0c9e807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu118\n",
      "PyTorch Geometric version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f213c8b-5dc0-468b-b7d0-72c08a6e5282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce RTX 3060 Ti (cuda)\n",
      "CUDA version: 11.8\n",
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a754a-7836-439e-801c-7efca6d2dfc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05fe5b06-7392-4d62-a1e8-af081cdf3e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/gwas-graph/UKBB-fine-mapping/data/UKBB_94traits_release1.csv')\n",
    "hg19_gene_positions = pd.read_csv(\"~/Desktop/gwas-graph/UKBB-fine-mapping/data/hg19-gene-positions.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3de12a0-5352-4bbc-9d24-baf89c6b6570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['position'] = data['variant'].str.split(':').str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e3e7c-413a-4014-a103-1762a804bc50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get geneSymbol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e80872-03c8-4ab3-9a8c-7f702ec23a8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "- The `%%time` command at the start is a magic command in Jupyter notebooks. It times the execution of the entire cell.\n",
    "\n",
    "- The dataframes `data` and `hg19_gene_positions` are sorted by chromosome and start position. Chromosome columns are converted to string type for both dataframes.\n",
    "\n",
    "- A variable `leniency` is defined and set to 100000. This will be used later to find nearby genes within this distance.\n",
    "\n",
    "- The 'chromosome' column in the `data` dataframe and the 'chrom' column in the `hg19_gene_positions` dataframe are converted to a 'category' data type. This is done to reduce memory usage and improve performance.\n",
    "\n",
    "- An empty dictionary `gene_symbols_dict` is created. This will be used to store gene symbols corresponding to each row in the `data` dataframe.\n",
    "\n",
    "- The script then loops over each unique chromosome.\n",
    "\n",
    "  - For each chromosome, subsets of `data` and `hg19_gene_positions` are created that include only the rows corresponding to the current chromosome.\n",
    "  \n",
    "  - A KDTree is built using the start positions (`txStart`) of genes in the `hg19_gene_positions_chromosome` dataframe. KDTree is a space-partitioning data structure that allows for efficient nearest-neighbor searches.\n",
    "  \n",
    "  - The KDTree is queried for each position in the `data_chromosome` dataframe to find the nearest gene within the specified leniency. The function returns two arrays: `distances`, which holds the distances to the nearest neighbors, and `indices`, which holds the indices of these neighbors in the `hg19_gene_positions_chromosome` dataframe.\n",
    "  \n",
    "  - A list `gene_symbols` is created to store the gene symbols of the nearest genes. If no gene is found within the leniency, 'N/A' is added to the list.\n",
    "  \n",
    "  - The `gene_symbols` list is then used to populate the `gene_symbols_dict` dictionary with the index from `data_chromosome` as the key and the corresponding gene symbol as the value.\n",
    "\n",
    "- Finally, the `gene_symbols_dict` dictionary is converted to a Pandas Series and added as a new column 'geneSymbol' to the `data` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d4d183-cc94-4d72-9c95-e5347d43f760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 17s\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Sort the dataframes and convert columns to string type\n",
    "data = data.sort_values(by=['chromosome', 'start'])\n",
    "data['chromosome'] = data['chromosome'].astype(str)\n",
    "\n",
    "hg19_gene_positions = hg19_gene_positions.sort_values(by=['chrom', 'txStart'])\n",
    "hg19_gene_positions['chrom'] = hg19_gene_positions['chrom'].astype(str)\n",
    "\n",
    "# Define leniency\n",
    "leniency = 100000\n",
    "\n",
    "# Convert the 'chrom' column to category type for efficient memory usage\n",
    "data['chromosome'] = data['chromosome'].astype('category')\n",
    "hg19_gene_positions['chrom'] = hg19_gene_positions['chrom'].astype('category')\n",
    "\n",
    "# Create an empty dictionary to store geneSymbols\n",
    "gene_symbols_dict = {}\n",
    "\n",
    "# Iterate over unique chromosome\n",
    "for chromosome in data['chromosome'].cat.categories:\n",
    "    # Subset data for current chromosome\n",
    "    data_chromosome = data[data['chromosome'] == chromosome]\n",
    "    hg19_gene_positions_chromosome = hg19_gene_positions[hg19_gene_positions['chrom'] == chromosome]\n",
    "\n",
    "    # Build KDTree for efficient nearest-neighbor search\n",
    "    tree = cKDTree(np.expand_dims(hg19_gene_positions_chromosome['txStart'].values, axis=1))\n",
    "\n",
    "    # Query the KDTree for nearest neighbors within the leniency\n",
    "    distances, indices = tree.query(np.expand_dims(data_chromosome['start'].values, axis=1), distance_upper_bound=leniency)\n",
    "\n",
    "    # Create a list of gene symbols\n",
    "    gene_symbols = []\n",
    "    for idx, distance in zip(indices, distances):\n",
    "        if distance == np.inf:\n",
    "            gene_symbols.append('N/A')  # or any other default value you want\n",
    "        else:\n",
    "            gene_symbols.append(hg19_gene_positions_chromosome.iloc[idx]['geneSymbol'])\n",
    "\n",
    "    # Assign geneSymbols to data dictionary\n",
    "    for idx, gene_symbol in zip(data_chromosome.index, gene_symbols):\n",
    "        gene_symbols_dict[idx] = gene_symbol\n",
    "\n",
    "# Convert the dictionary to a Series and assign it to a new column in 'data'\n",
    "data['geneSymbol'] = pd.Series(gene_symbols_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2594b60-01fa-49ad-86b0-b38c0ee4c80f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in data['geneSymbol']:  0\n",
      "Number of unique elements in data['geneSymbol']:  24464\n",
      "Number of unique elements in hg19_gene_positions['geneSymbol']:  29014\n"
     ]
    }
   ],
   "source": [
    "null_values = data['geneSymbol'].isnull().sum()\n",
    "print(\"Number of null values in data['geneSymbol']: \", null_values)\n",
    "\n",
    "unique_elements1 = data['geneSymbol'].nunique()\n",
    "print(\"Number of unique elements in data['geneSymbol']: \", unique_elements1)\n",
    "\n",
    "unique_elements2 = hg19_gene_positions['geneSymbol'].nunique()\n",
    "print(\"Number of unique elements in hg19_gene_positions['geneSymbol']: \", unique_elements2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eddaed-2f48-4440-b6d6-0dc247f23ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Proposed graph features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe89142-2b65-469b-b330-1620d303312b",
   "metadata": {},
   "source": [
    "All columns from `data` dataframe:\n",
    "\n",
    "Phenotype nodes features:\n",
    "- `trait` column\n",
    "\n",
    "Gene nodes features:\n",
    "- `geneSymbol` column\n",
    "- `chromosome` column\n",
    "- `start` column\n",
    "- `end` column\n",
    "\n",
    "SNP node features:\n",
    "- `rsid` column\n",
    "- `chromosome` column\n",
    "- `position` column\n",
    "- `allele1` column\n",
    "- `allele2` column\n",
    "\n",
    "Edge features:\n",
    "- undirected\n",
    "- unweighted \n",
    "- positive if associations exist in graph\n",
    "- negative if not (100 random negative edges for every positive edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abe533-6610-4f82-b8d6-533eb010858d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf981ea3-0b4b-437f-9fc2-1210050d1ce1",
   "metadata": {},
   "source": [
    "- The `%%time` magic command is used at the start of the code block to track the execution time of the code.\n",
    "\n",
    "- The `random` library is imported, which will be used to generate random integers for creating negative edges later in the code.\n",
    "\n",
    "- Unique phenotypes, genes, and SNPs (Single Nucleotide Polymorphisms) are extracted from the given data and assigned to respective variables.\n",
    "\n",
    "- Integer indices are assigned to phenotypes, genes, and SNPs, and mappings are created in the form of dictionaries (e.g., `phenotype_to_idx`).\n",
    "\n",
    "- The node feature vectors for phenotypes, genes, and SNPs are created using the original data, by filtering, dropping duplicates, sorting values, and resetting indices.\n",
    "\n",
    "- Node type labels are created using the PyTorch tensor, where phenotypes, genes, and SNPs are marked as 0, 1, and 2 respectively.\n",
    "\n",
    "- Positive edges are created between SNPs and genes, and between genes and phenotypes. Here, an edge represents a connection or relationship between two entities (nodes). The mappings created earlier are used to convert rsid and geneSymbol to their respective indices.\n",
    "\n",
    "- Negative edges are created for SNP-Gene and Gene-Phenotype pairs. A negative edge represents a non-existing connection between two entities. Negative edges are generated randomly while ensuring that they don't coincide with the positive edges.\n",
    "\n",
    "- All positive and negative edges are combined together into a single PyTorch tensor.\n",
    "\n",
    "- Edge attributes are created as a tensor of ones with the same size as the number of edges.\n",
    "\n",
    "- The feature vectors of phenotypes, genes, and SNPs are combined together. NaN values are filled with suitable replacements, and Label Encoding is applied to categorical columns.\n",
    "\n",
    "- Numerical features are standardized using the `StandardScaler` from sklearn, and categorical columns are converted to category codes.\n",
    "\n",
    "- A PyTorch Geometric graph is created with the combined feature vectors as node features, the combined edges as the graph structure, and the tensor of ones as edge attributes.\n",
    "\n",
    "- Lastly, summary statistics about the created graph are printed, including the number of nodes, the number of positive and negative edges for SNP-Gene and Gene-Phenotype pairs, the total number of edges, node feature dimension, and node types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "849b5a45-34bc-441b-a20d-c78ff8a92d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4099617\n",
      "Number of positive edges between SNPs and genes: 2049441\n",
      "Number of positive edges between genes and phenotypes: 248952\n",
      "Number of negative edges for SNPs and genes: 204944100\n",
      "Number of negative edges for genes and phenotypes: 24895200\n",
      "Number of edges: 232137693\n",
      "Node feature dimension: 6\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'node_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\data\\storage.py:79\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\data\\storage.py:104\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'node_types'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:100\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\data\\data.py:441\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store, key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\data\\storage.py:81\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'node_types'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "\n",
    "# Create mappings for phenotypes, genes, and SNPs to integer indices\n",
    "phenotypes = data['trait'].unique()\n",
    "genes = data['geneSymbol'].unique()\n",
    "snps = data['rsid'].unique()\n",
    "phenotype_to_idx = {phenotype: idx for idx, phenotype in enumerate(phenotypes)}\n",
    "gene_to_idx = {gene: idx + len(phenotypes) for idx, gene in enumerate(genes)}\n",
    "snp_to_idx = {snp: idx + len(phenotypes) + len(genes) for idx, snp in enumerate(snps)}\n",
    "\n",
    "\n",
    "# Create node feature vectors for phenotypes, genes, and SNPs\n",
    "phenotype_features = data.loc[data['trait'].isin(phenotypes)][['trait']].drop_duplicates().sort_values(by='trait').reset_index(drop=True)\n",
    "gene_features = data.loc[data['geneSymbol'].isin(genes)][['geneSymbol', 'chromosome', 'start', 'end']].drop_duplicates().sort_values(by='geneSymbol').reset_index(drop=True)\n",
    "snp_features = data.loc[data['rsid'].isin(snps)][['rsid', 'chromosome', 'position', 'allele1', 'allele2']].drop_duplicates().sort_values(by='rsid').reset_index(drop=True)\n",
    "\n",
    "# Create node type labels\n",
    "node_types = torch.tensor([0] * len(phenotypes) + [1] * len(genes) + [2] * len(snps), dtype=torch.long)\n",
    "\n",
    "# Create positive edges between SNPs and genes\n",
    "positive_edges_snp_gene = data.loc[:, ['rsid', 'geneSymbol']].drop_duplicates()\n",
    "positive_edges_snp_gene['snp_idx'] = positive_edges_snp_gene['rsid'].map(snp_to_idx)\n",
    "positive_edges_snp_gene['gene_idx'] = positive_edges_snp_gene['geneSymbol'].map(gene_to_idx)\n",
    "positive_edges_snp_gene = positive_edges_snp_gene[['snp_idx', 'gene_idx']].values\n",
    "positive_edges_snp_gene = torch.tensor(positive_edges_snp_gene, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create positive edges between genes and phenotypes\n",
    "positive_edges_gene_phenotype = data.loc[:, ['geneSymbol', 'trait']].drop_duplicates()\n",
    "positive_edges_gene_phenotype['gene_idx'] = positive_edges_gene_phenotype['geneSymbol'].map(gene_to_idx)\n",
    "positive_edges_gene_phenotype['phenotype_idx'] = positive_edges_gene_phenotype['trait'].map(phenotype_to_idx)\n",
    "positive_edges_gene_phenotype = positive_edges_gene_phenotype[['gene_idx', 'phenotype_idx']].values\n",
    "positive_edges_gene_phenotype = torch.tensor(positive_edges_gene_phenotype, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create negative edges for SNP-Gene\n",
    "negative_edges_snp_gene = []\n",
    "positive_edges_set = set([tuple(x) for x in positive_edges_snp_gene.t().tolist()])\n",
    "for _ in range(100 * len(positive_edges_snp_gene[0])):\n",
    "    while True:\n",
    "        random_snp = random.randint(0, len(snps) - 1)\n",
    "        random_gene = random.randint(0, len(genes) - 1)\n",
    "        negative_edge = (random_snp, random_gene)\n",
    "        if negative_edge not in positive_edges_set:\n",
    "            negative_edges_snp_gene.append(negative_edge)\n",
    "            break\n",
    "negative_edges_snp_gene = torch.tensor(negative_edges_snp_gene, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create negative edges for Gene-Phenotype\n",
    "negative_edges_gene_phenotype = []\n",
    "positive_edges_set = set([tuple(x) for x in positive_edges_gene_phenotype.t().tolist()])\n",
    "for _ in range(100 * len(positive_edges_gene_phenotype[0])):\n",
    "    while True:\n",
    "        random_gene = random.randint(0, len(genes) - 1)\n",
    "        random_phenotype = random.randint(0, len(phenotypes) - 1)\n",
    "        negative_edge = (random_gene, random_phenotype)\n",
    "        if negative_edge not in positive_edges_set:\n",
    "            negative_edges_gene_phenotype.append(negative_edge)\n",
    "            break\n",
    "negative_edges_gene_phenotype = torch.tensor(negative_edges_gene_phenotype, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Combine positive and negative edges\n",
    "edges = torch.cat([positive_edges_snp_gene, positive_edges_gene_phenotype, negative_edges_snp_gene, negative_edges_gene_phenotype], dim=1)\n",
    "\n",
    "# Create edge attributes\n",
    "edge_attr = torch.ones(edges.size(1), dtype=torch.float)\n",
    "\n",
    "# Combine the feature vectors\n",
    "combined_features = pd.concat([phenotype_features, gene_features, snp_features], ignore_index=True).drop(['trait', 'geneSymbol', 'rsid'], axis=1)\n",
    "\n",
    "# Now you can fill NaNs with 'N/A'\n",
    "nan_replacements = {'chromosome': 'N/A', 'start': 0, 'end': 0, 'position': 0, 'allele1': 'N/A', 'allele2': 'N/A'}\n",
    "for col, replacement in nan_replacements.items():\n",
    "    if col in combined_features:\n",
    "        if combined_features[col].dtype.name == 'category' and replacement not in combined_features[col].cat.categories:\n",
    "            combined_features[col] = combined_features[col].cat.add_categories([replacement])\n",
    "        combined_features[col].fillna(replacement, inplace=True)\n",
    "\n",
    "# Label encoding for categorical columns\n",
    "le = LabelEncoder()\n",
    "combined_features = combined_features.apply(lambda col: le.fit_transform(col.astype(str)) if col.dtype == 'object' else col)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = ['start', 'end', 'position']\n",
    "categorical_columns = ['chromosome', 'allele1', 'allele2']\n",
    "for col in categorical_columns:\n",
    "    combined_features[col] = combined_features[col].astype('category').cat.codes\n",
    "\n",
    "features = torch.tensor(combined_features.values, dtype=torch.float)\n",
    "\n",
    "# Create the PyTorch Geometric graph\n",
    "graph = Data(x=features, edge_index=edges, edge_attr=edge_attr)\n",
    "\n",
    "print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "print(f\"Number of positive edges between SNPs and genes: {positive_edges_snp_gene.size(1)}\")\n",
    "print(f\"Number of positive edges between genes and phenotypes: {positive_edges_gene_phenotype.size(1)}\")\n",
    "print(f\"Number of negative edges for SNPs and genes: {negative_edges_snp_gene.size(1)}\")\n",
    "print(f\"Number of negative edges for genes and phenotypes: {negative_edges_gene_phenotype.size(1)}\")\n",
    "print(f\"Number of edges: {graph.num_edges}\")\n",
    "print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "print(f\"Node types: {graph.node_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60cae52-2493-43ae-9e27-e7dc67c3a7f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d7d0e2-80bf-4a82-9c1c-6aac6307aab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any NaN values in features? False\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in features\n",
    "nan_in_features = torch.isnan(graph.x).any().item()\n",
    "print(f\"Are there any NaN values in features? {nan_in_features}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2a08f05-3012-4d85-85eb-3f5cb6a6955c",
   "metadata": {
    "tags": []
   },
   "source": [
    "def print_graph_stats(graph, phenotypes, snps):\n",
    "    G = nx.Graph()\n",
    "    edge_weights = graph.edge_attr.view(-1)  # ensure that edge_attr is a 1D tensor\n",
    "    for edge, weight in zip(graph.edge_index.t().numpy(), edge_weights):\n",
    "        G.add_edge(edge[0], edge[1], weight=weight.item())  # use the pip value as the edge weight\n",
    "\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_phenotypes = len(phenotypes)\n",
    "    num_genes = len(genes)\n",
    "    num_snps = len(snps)\n",
    "    num_positive_edges = sum(weight > 0 for weight in edge_weights)\n",
    "    num_negative_edges = sum(weight == 0 for weight in edge_weights)\n",
    "    num_edges = G.number_of_edges()\n",
    "    num_connected_components = nx.number_connected_components(G)\n",
    "    average_degree = np.mean([degree for _, degree in G.degree()])\n",
    "    median_degree = np.median([degree for _, degree in G.degree()])\n",
    "    std_degree = np.std([degree for _, degree in G.degree()])\n",
    "    density = nx.density(G)\n",
    "    assortativity = nx.degree_assortativity_coefficient(G)\n",
    "    edge_weights = [data[\"weight\"] for _, _, data in G.edges(data=True)]\n",
    "    average_weight = np.mean(edge_weights)\n",
    "    median_weight = np.median(edge_weights)\n",
    "    std_weight = np.std(edge_weights)\n",
    "\n",
    "    print(f\"Number of nodes: {num_nodes}\")\n",
    "    print(\"Number of SNP nodes:\", num_snps)\n",
    "    print(\"Number of Gene nodes:\", num_genes)\n",
    "    print(\"Number of Phenotype nodes:\", num_phenotypes)\n",
    "    print(f\"Number of positive edges: {num_positive_edges}\")\n",
    "    print(f\"Number of negative edges: {num_negative_edges}\")\n",
    "    print(f\"Number of edges: {num_edges}\")\n",
    "    print(f\"Number of connected components: {num_connected_components}\")\n",
    "    print(f\"Average degree: {average_degree:.2f}\")\n",
    "    print(f\"Median degree: {median_degree}\")\n",
    "    print(f\"Standard deviation of degree: {std_degree:.2f}\")\n",
    "    print(f\"Density: {density:.10f}\")\n",
    "    print(f\"Assortativity: {assortativity:.10f}\")\n",
    "    print(f\"Average edge weight: {average_weight:.2f}\")\n",
    "    print(f\"Median edge weight: {median_weight}\")\n",
    "    print(f\"Standard deviation of edge weight: {std_weight:.2f}\")\n",
    "\n",
    "# Print\n",
    "print(\"Graph stats:\")\n",
    "print_graph_stats(graph, phenotypes, snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ab9a9e-7a28-4d0e-b17f-05a64f58e3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum degree: 1.0\n",
      "Maximum degree: 1352.0\n",
      "Average degree: 111.9275894165039\n",
      "Number of nodes with degree 1: 24558\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree\n",
    "\n",
    "# Compute the degree of each node\n",
    "degrees = degree(graph.edge_index[0])\n",
    "\n",
    "# Print statistics about the degrees\n",
    "print(f\"Minimum degree: {degrees.min().item()}\")\n",
    "print(f\"Maximum degree: {degrees.max().item()}\")\n",
    "print(f\"Average degree: {degrees.float().mean().item()}\")\n",
    "\n",
    "# Count the number of nodes with degree 1\n",
    "num_nodes_degree_1 = (degrees == 1).sum().item()\n",
    "print(f\"Number of nodes with degree 1: {num_nodes_degree_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51e96d-660c-4b4f-8ac4-9a07dba5bcc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4c39c22-7925-4a6d-a3a5-8266e617dbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4099617, 6], edge_index=[2, 232137693], edge_attr=[232137693])\n",
      "tensor([[2.2000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4900e+03, 6.4700e+03],\n",
      "        [2.2000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4900e+03, 6.4700e+03],\n",
      "        [2.2000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4900e+03, 6.4700e+03],\n",
      "        ...,\n",
      "        [1.6000e+01, 0.0000e+00, 0.0000e+00, 1.9136e+06, 0.0000e+00, 2.3920e+03],\n",
      "        [1.6000e+01, 0.0000e+00, 0.0000e+00, 4.9400e+03, 9.4910e+03, 2.3920e+03],\n",
      "        [1.6000e+01, 0.0000e+00, 0.0000e+00, 2.6145e+05, 6.4910e+03, 0.0000e+00]])\n",
      "tensor([[24558, 24559, 24560,  ..., 19591, 20124, 12476],\n",
      "        [   94,    94,    95,  ...,    61,    18,    55]])\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print(graph)\n",
    "print(graph.x)\n",
    "print(graph.edge_index)\n",
    "print(graph.edge_attr.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d110955-0ad0-41d7-81fc-e41226316964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4099617, 6], edge_index=[2, 1532838], edge_attr=[1532838], edge_label=[1532838], edge_label_index=[2, 1532838])\n",
      "Data(x=[4099617, 6], edge_index=[2, 1532838], edge_attr=[1532838], edge_label=[510946], edge_label_index=[2, 510946])\n",
      "Data(x=[4099617, 6], edge_index=[2, 2043784], edge_attr=[2043784], edge_label=[510946], edge_label_index=[2, 510946])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit \n",
    "\n",
    "transform = RandomLinkSplit(num_val=0.2, num_test=0.2, is_undirected=True)\n",
    "graph_train, graph_val, graph_test = transform(graph)\n",
    "\n",
    "print(graph_train)\n",
    "print(graph_val)\n",
    "print(graph_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8eaae7-0ff7-4ce7-bb7c-7fffc8632d00",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc897c35-4b85-4a9a-8b02-e6553f6bb264",
   "metadata": {
    "tags": []
   },
   "source": [
    "- The script begins with a comment stating the task (Link Prediction) and providing information about node types and the dimension of the node feature vector.\n",
    "\n",
    "- PyTorch's GPU memory cache is emptied using `torch.cuda.empty_cache()` to free up space for computation.\n",
    "\n",
    "- A Graph Convolutional Network (GCN) model is defined as a subclass of `torch.nn.Module`. This network consists of two convolutional layers (`GCNConv`). The `forward` method defines how input data passes through these layers, which includes a ReLU activation function and a dropout layer for regularization.\n",
    "\n",
    "- The script checks if CUDA is available for GPU computation. If it is, the device is set to \"cuda\"; otherwise, it's set to \"cpu\".\n",
    "\n",
    "- An instance of the GCN model is created with 16 hidden channels and is moved to the chosen device.\n",
    "\n",
    "- The training, validation, and test graphs are also moved to the chosen device.\n",
    "\n",
    "- An Adam optimizer is initialized with the model parameters, a learning rate of 0.01, and a weight decay of 5e-4.\n",
    "\n",
    "- A training function is defined, which trains the model on the training graph. It computes a binary cross-entropy loss based on the predictions for positive and negative edges and backpropagates the loss to update the model parameters.\n",
    "\n",
    "- An evaluation function is defined, which evaluates the model on a given graph. It computes the ROC-AUC, Mean Reciprocal Rank (MRR), and Hits@5 metrics based on the model's predictions.\n",
    "\n",
    "- The MRR and Hits@5 computation functions are also defined. They compute these metrics based on the model's predictions and the true labels.\n",
    "\n",
    "- Maximum values for ROC-AUC, MRR, and Hits@5 on both validation and test sets are initialized to negative infinity.\n",
    "\n",
    "- The model is then trained for 150 epochs. In each epoch, the training function is called to train the model, and the evaluation function is called to evaluate it on the validation graph. The maximum ROC-AUC, MRR, and Hits@5 on the validation set are updated if the current epoch's scores are higher.\n",
    "\n",
    "- The loss, ROC-AUC, MRR, and Hits@5 for each epoch are printed for tracking the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744860e-e107-4495-9e88-79fe72ac7db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task: Link prediction: does an edge exist between two nodes?\n",
    "# Node Types: 0 = phenotypes, 1 = gene, 2 = snps\n",
    "# Node Feature Vector: 6-dimensional\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(6, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Train and evaluate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GCN(hidden_channels=16).to(device)\n",
    "\n",
    "graph_train = graph_train.to(device)\n",
    "graph_val = graph_val.to(device)\n",
    "graph_test = graph_test.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Train function\n",
    "from torch_geometric.utils import negative_sampling\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model(graph_train.x.float(), graph_train.edge_index)\n",
    "\n",
    "    # Only consider positive edges for the positive score calculation\n",
    "    pos_edge_index = graph_train.edge_index\n",
    "    pos = (z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    # Use negative_sampling to generate negative edges\n",
    "    neg_edge_index = negative_sampling(edge_index=pos_edge_index, num_nodes=z.size(0), num_neg_samples=pos_edge_index.size(1))\n",
    "    neg = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    logits = torch.cat([pos, neg], dim=0)\n",
    "    targets = torch.tensor([1] * pos.size(0) + [0] * neg.size(0), dtype=torch.float32).to(device)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(edge_index, graph):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(graph.x.float(), graph.edge_index)\n",
    "        pos = torch.sigmoid((z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)).view(-1)\n",
    "        neg_edge_index = negative_sampling(edge_index, num_nodes=graph.num_nodes, num_neg_samples=edge_index.size(1))\n",
    "        neg = torch.sigmoid((z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=-1)).view(-1)\n",
    "\n",
    "        preds = np.concatenate([pos.cpu().numpy(), neg.cpu().numpy()])\n",
    "        true_labels = np.concatenate([np.ones_like(pos.cpu().numpy()), np.zeros_like(neg.cpu().numpy())])\n",
    "\n",
    "        roc_auc = roc_auc_score(true_labels, preds)\n",
    "        mrr = compute_mrr(preds, true_labels)\n",
    "        hits_at_5 = compute_hits_at_k(preds, true_labels, k=5)\n",
    "\n",
    "        return roc_auc, mrr, hits_at_5\n",
    "\n",
    "def compute_mrr(preds, true_labels):\n",
    "    # Find the predicted scores for positive examples\n",
    "    pos_preds = preds[:len(true_labels)]\n",
    "    # Rank the positive examples by predicted score in descending order\n",
    "    sorted_idx = np.argsort(pos_preds)[::-1]\n",
    "    # Find the rank of the first true positive\n",
    "    for i, idx in enumerate(sorted_idx):\n",
    "        if true_labels[idx] == 1:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0.0\n",
    "\n",
    "def compute_hits_at_k(preds, true_labels, k=5):\n",
    "    # Find the predicted scores for positive examples\n",
    "    pos_preds = preds[:len(true_labels)]\n",
    "    # Rank the positive examples by predicted score in descending order\n",
    "    sorted_idx = np.argsort(pos_preds)[::-1]\n",
    "    # Check if the first k predictions contain at least one true positive\n",
    "    hits = 0\n",
    "    for idx in sorted_idx[:k]:\n",
    "        if true_labels[idx] == 1:\n",
    "            hits = 1\n",
    "            break\n",
    "    return hits\n",
    "\n",
    "max_val_roc_auc = -np.inf\n",
    "max_val_mrr = -np.inf\n",
    "max_val_hits5 = -np.inf\n",
    "\n",
    "max_test_roc_auc = -np.inf\n",
    "max_test_mrr = -np.inf\n",
    "max_test_hits5 = -np.inf\n",
    "\n",
    "for epoch in range(150):\n",
    "    loss = train()\n",
    "    val_roc_auc, val_mrr, val_hits_at_5 = evaluate(graph_val.edge_index, graph_val)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss:.4f}, Val ROC-AUC: {val_roc_auc:.10f}, Val MRR: {val_mrr:.10f}, Val Hits@5: {val_hits_at_5}\")\n",
    "    max_val_roc_auc = max(max_val_roc_auc, val_roc_auc)\n",
    "    max_val_mrr = max(max_val_mrr, val_mrr)\n",
    "    max_val_hits5 = max(max_val_hits5, val_hits_at_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d432600-1aa5-41ac-9c0d-a6d833acf505",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55930699-10ed-4220-8144-139098ecf0f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_roc_auc, val_mrr, val_hits5 = evaluate(graph_val.edge_index, graph_val)\n",
    "test_roc_auc, test_mrr, test_hits5 = evaluate(graph_test.edge_index, graph_test)\n",
    "\n",
    "max_test_roc_auc = max(max_test_roc_auc, test_roc_auc)\n",
    "max_test_mrr = max(max_test_mrr, test_mrr)\n",
    "max_test_hits5 = max(max_test_hits5, test_hits5)\n",
    "\n",
    "print(f\"Maximum Validation ROC-AUC: {max_val_roc_auc:.10f}\")\n",
    "print(f\"Maximum Validation MRR: {max_val_mrr:.10f}\")\n",
    "print(f\"Maximum Validation Hits@5: {max_val_hits5:.10f}\")\n",
    "\n",
    "print(f\"Maximum Test ROC-AUC: {max_test_roc_auc:.10f}\")\n",
    "print(f\"Maximum Test MRR: {max_test_mrr:.10f}\")\n",
    "print(f\"Maximum Test Hits@5: {max_test_hits5:.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
