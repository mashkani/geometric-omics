{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8856a85c-cc6c-4e9c-9466-fafee6338628",
   "metadata": {
    "tags": []
   },
   "source": [
    "## README \n",
    "Website: https://www.eqtlgen.org/phase1.html\n",
    "\n",
    "Paper: https://www.nature.com/articles/s41588-021-00913-zhttps://www.nature.com/articles/s41588-021-00913-z\n",
    "\n",
    "This Jupyter notebook README covers cis-eQTL and trans-eQTL results from the eQTLGen project. The dataset includes significant files for both cis-eQTL and trans-eQTL analyses. \n",
    "\n",
    "Files contain various columns with information on P-value, SNP rs ID, SNP chromosome, SNP position, assessed and not assessed alleles, Z-score, ENSG and HGNC names of eQTL genes, gene chromosome, gene position, number of cohorts, number of samples, false discovery rate, and Bonferroni-corrected P-value.\n",
    "\n",
    "The cis-eQTL analysis includes 19,250 genes expressed in blood, with SNP-gene combinations within 1Mb from the gene center and tested in at least 2 cohorts. The trans-eQTL analysis tests 19,960 genes expressed in blood and 10,317 trait-associated SNPs based on GWAS Catalog, Immunobase, and Astle et al. study. Trans-eQTL combinations have a distance of >5Mb and were tested in at least 2 cohorts.\n",
    "\n",
    "The FDR calculation uses a pruned set of SNPs for trans-eQTL mapping and permutation-based FDR calculation. Crossmapping filters are applied to identify and remove potential artifacts in trans-eQTL results, recalculating the FDR afterward. Note that the full results file has not been filtered for cross-mapping effects, which may lead to artifacts in the data.\n",
    "\n",
    "The code below demonstrates the process of creating a graph-based representation of the combined cis and trans-eQTL data using PyTorch Geometric. This process can be broken down into several steps:\n",
    "\n",
    "1. Combine cis and trans dataframes: The code begins by concatenating the cis and trans dataframes into a single dataframe named 'data', which contains information on both cis-eQTL and trans-eQTL results. This combined dataset simplifies the process of working with the data and ensures that all relevant information is contained within a single data structure.\n",
    "\n",
    "2. Create mappings for genes and SNPs: To represent the genes and SNPs as nodes in the graph, integer indices are assigned to each unique gene and SNP. This is done using dictionaries called 'gene_to_idx' and 'snp_to_idx', which map the gene and SNP identifiers to their corresponding integer indices.\n",
    "\n",
    "3. Generate node type labels: Node type labels are created using PyTorch tensors, distinguishing between gene nodes (assigned a label of 0) and SNP nodes (assigned a label of 1). This differentiation is useful for various graph-based analyses and machine learning tasks that require knowledge of node types.\n",
    "\n",
    "4. Create edges based on gene and SNP indices: Edges in the graph represent the relationships between genes and SNPs. These edges are created by iterating over the 'data' dataframe and extracting the corresponding gene and SNP indices from the previously created mappings. The edges are then represented as a PyTorch tensor with a long data type.\n",
    "\n",
    "5. Convert edges to undirected: Since the relationships between genes and SNPs are undirected, the edges in the graph should also be undirected. This is achieved using the 'to_undirected()' function from PyTorch Geometric, which ensures that the graph correctly represents the underlying biology.\n",
    "\n",
    "6. Create a PyTorch Geometric graph: Finally, the graph is created using the PyTorch Geometric 'Data' class. The node types and edge indices are used as inputs to instantiate the graph object, which can then be utilized for further analysis and visualization.\n",
    "\n",
    "The resulting 'graph' object is a PyTorch Geometric representation of the combined cis and trans-eQTL data. The prediction task is to predict new association edges given the training edges, with the task type being link prediction. Below are a few important graph statistics:\n",
    "\n",
    "- Number of nodes: 3681495\n",
    "- Number of SNP nodes: 3664025\n",
    "- Number of Gene nodes: 17470\n",
    "- Number of edges: 10567450\n",
    "- Number of connected components: 424\n",
    "- Average degree: 5.74\n",
    "- Median degree: 2.0\n",
    "- Standard deviation of degree: 69.81\n",
    "- Density: 0.0000015594\n",
    "- Assortativity: -0.2267915607\n",
    "\n",
    "The prediction task is to predict new association edges given the training edges, with the task type being link prediction. The data splitting is random while maintaining an equal proportion of cis- and trans- associations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814724f-367b-414b-87e2-a2ca0f4d3dab",
   "metadata": {},
   "source": [
    "- The model is predicting whether an edge exists between nodes: -1 for no edge and +1 for an edge. It knows whether nodes are genes (0) or snps (1). It has no notion of cis or trans apart from differences in node features vectors:\n",
    "\n",
    "- Gene Node Features: 'GenePos': float, 'GeneChr': str, GeneStart': float, 'GeneEnd': float\n",
    "\n",
    "- SNP Node Features: 'SNPChr': str, 'SNPPos': float, 'AssessedAllele': str, 'OtherAllele': str\n",
    "\n",
    "- Input: feature vectors for and edges between all training nodes\n",
    "\n",
    "- Output: edges between all nodes in test/validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae5b6c8-9ccf-4c35-b6dc-e8755e8c251e",
   "metadata": {},
   "source": [
    "## Data Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c312ac4-08e0-46ae-b18a-10f81e6b2ddb",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f0bf7f-91fc-4010-bb06-e5e4434c3c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torch_sparse\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling, subgraph\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "import networkx as nx\n",
    "from ogb.io import DatasetSaver\n",
    "from ogb.linkproppred import LinkPropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c398fa63-4d51-40a5-baab-d085d2beaf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu118\n",
      "PyTorch Geometric version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95bdb806-8661-4798-93a7-85e08eff2304",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce RTX 3060 Ti (cuda)\n",
      "CUDA version: 11.8\n",
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757b0ab8-7b52-4cd9-b0e0-77d0c2dc3b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_types = {'Pvalue': float, 'SNP': str, 'SNPChr': str, 'SNPPos': float,\n",
    "              'AssessedAllele': str, 'OtherAllele': str, 'Zscore': float,\n",
    "              'Gene': str, 'GeneSymbol': str, 'GeneChr': str, 'GenePos': float,\n",
    "              'NrCohorts': int, 'NrSamples': int, 'FDR': float,\n",
    "              'BonferroniP': float, 'GeneStart': float, 'GeneEnd': float, 'Sig':int}\n",
    "\n",
    "cis = pd.read_csv(\"cis-genes.csv\", dtype=data_types)\n",
    "trans = pd.read_csv(\"trans-genes.csv\", dtype=data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb69c8a8-38f2-40f2-885e-f5106d8b6240",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e9d95dd-71d8-4a32-9606-94e15c6bb51d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.concat([cis, trans], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdee40ba-792a-452f-b267-ffbe6920f4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6756193\n",
      "Number of edges: 114904434\n",
      "Node feature dimension: 8\n",
      "Node types: tensor([0, 0, 0,  ..., 1, 1, 1])\n",
      "Sum of edge_attr: 2154707\n"
     ]
    }
   ],
   "source": [
    "# Create mappings for genes and SNPs to integer indices\n",
    "genes = data['Gene'].unique()\n",
    "snps = data['SNP'].unique()\n",
    "gene_to_idx = {gene: idx for idx, gene in enumerate(genes)}\n",
    "snp_to_idx = {snp: idx + len(genes) for idx, snp in enumerate(snps)}\n",
    "\n",
    "# Create node feature vectors\n",
    "gene_features = data.loc[data['Gene'].isin(genes)][['Gene', 'GeneChr', 'GenePos', 'GeneStart', 'GeneEnd']].drop_duplicates().sort_values(by='Gene').reset_index(drop=True)\n",
    "snp_features = data.loc[data['SNP'].isin(snps)][['SNP', 'SNPChr', 'SNPPos', 'AssessedAllele', 'OtherAllele']].drop_duplicates().sort_values(by='SNP').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Create node type labels\n",
    "node_types = torch.tensor([0] * len(genes) + [1] * len(snps), dtype=torch.long)\n",
    "\n",
    "# Filter the data to create positive and negative edges\n",
    "sig = data[data['Sig'] == 1]\n",
    "unsig = data[data['Sig'] != 1]\n",
    "\n",
    "# Create positive and negative edges\n",
    "positive_edges = sig.apply(lambda row: (gene_to_idx[row['Gene']], snp_to_idx[row['SNP']]), axis=1)\n",
    "negative_edges = unsig.apply(lambda row: (gene_to_idx[row['Gene']], snp_to_idx[row['SNP']]), axis=1)\n",
    "\n",
    "positive_edges = torch.tensor(list(positive_edges), dtype=torch.long).t().contiguous()\n",
    "negative_edges = torch.tensor(list(negative_edges), dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Combine positive and negative edges\n",
    "edges = torch.cat([positive_edges, negative_edges], dim=1)\n",
    "\n",
    "# Create edge labels\n",
    "edge_labels = torch.tensor([1] * positive_edges.size(1) + [0] * negative_edges.size(1), dtype=torch.long)\n",
    "\n",
    "# Convert edges to undirected\n",
    "edges = to_undirected(edges)\n",
    "\n",
    "# Combine the feature vectors\n",
    "combined_features = pd.concat([gene_features, snp_features], ignore_index=True).drop(['Gene', 'SNP'], axis=1)\n",
    "\n",
    "# Replace NaN and empty strings with \"N/A\"\n",
    "combined_features.fillna({'GeneChr': 'N/A', 'GenePos': 0, 'GeneStart': 0, 'GeneEnd': 0,\n",
    "                          'SNPChr': 'N/A', 'SNPPos': 0, 'AssessedAllele': 'N/A', 'OtherAllele': 'N/A'}, inplace=True)\n",
    "combined_features.replace({'GeneChr': {'': 'N/A'}, 'SNPChr': {'': 'N/A'},\n",
    "                           'AssessedAllele': {'': 'N/A'}, 'OtherAllele': {'': 'N/A'}}, inplace=True)\n",
    "\n",
    "\n",
    "# Label encoding for categorical columns\n",
    "categorical_columns = ['GeneChr', 'SNPChr', 'AssessedAllele', 'OtherAllele']\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    combined_features[column] = le.fit_transform(combined_features[column])\n",
    "\n",
    "# Standardize numerical features\n",
    "numerical_columns = ['GenePos', 'GeneStart', 'GeneEnd', 'SNPPos']\n",
    "scaler = StandardScaler()\n",
    "combined_features[numerical_columns] = scaler.fit_transform(combined_features[numerical_columns])\n",
    "\n",
    "# Create the PyTorch tensor\n",
    "features = torch.tensor(combined_features.values, dtype=torch.float)\n",
    "\n",
    "# Create the PyTorch Geometric graph\n",
    "graph = Data(x=features, edge_index=edges, edge_attr=edge_labels)\n",
    "graph.node_types = node_types\n",
    "#graph.x = F.normalize(graph.x, p=2, dim=-1)\n",
    "print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "print(f\"Number of edges: {graph.num_edges}\")\n",
    "print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "print(f\"Node types: {graph.node_types}\")\n",
    "\n",
    "edge_attr_sum = torch.sum(graph.edge_attr)\n",
    "print(f\"Sum of edge_attr: {edge_attr_sum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aadf68-9a33-4a1e-a3fc-d544c7bc3811",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d906e58b-723f-47d7-8160-9e9135e21e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 'Sig' values: 2154707\n",
      "Count of 'Sig' values not equal to 1: 55297510\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of 'Sig' values:\", len(data[data['Sig'] == 1]))\n",
    "print(\"Count of 'Sig' values not equal to 1:\", len(data[data['Sig'] != 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b9481a-59ce-4609-8570-e567be6e0b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any NaN values in features? False\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in features\n",
    "nan_in_features = torch.isnan(graph.x).any().item()\n",
    "print(f\"Are there any NaN values in features? {nan_in_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355916c8-695e-40ed-b943-d547ffc0fa75",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187e286f-691a-4c43-8d50-54960becda8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph stats:\n",
      "Number of nodes: 6755968\n",
      "Number of SNP nodes: 6742475\n",
      "Number of Gene nodes: 13493\n",
      "Number of edges: 57452217\n",
      "Number of connected components: 1\n",
      "Average degree: 17.01\n",
      "Median degree: 2.0\n",
      "Standard deviation of degree: 231.95\n",
      "Density: 0.0000025175\n",
      "Assortativity: -0.5145749464\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_graph_stats(graph, genes, snps):\n",
    "    G = nx.Graph()\n",
    "    for edge in graph.edge_index.t().numpy():\n",
    "        G.add_edge(edge[0], edge[1])\n",
    "\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_genes = len(genes)\n",
    "    num_snps = len(snps)\n",
    "    num_edges = G.number_of_edges()\n",
    "    num_connected_components = nx.number_connected_components(G)\n",
    "    average_degree = np.mean([degree for _, degree in G.degree()])\n",
    "    median_degree = np.median([degree for _, degree in G.degree()])\n",
    "    std_degree = np.std([degree for _, degree in G.degree()])\n",
    "    density = nx.density(G)\n",
    "    assortativity = nx.degree_assortativity_coefficient(G)\n",
    "\n",
    "    print(f\"Number of nodes: {num_nodes}\")\n",
    "    print(\"Number of SNP nodes:\", num_snps)\n",
    "    print(\"Number of Gene nodes:\", num_genes)\n",
    "    print(f\"Number of edges: {num_edges}\")\n",
    "    print(f\"Number of connected components: {num_connected_components}\")\n",
    "    print(f\"Average degree: {average_degree:.2f}\")\n",
    "    print(f\"Median degree: {median_degree}\")\n",
    "    print(f\"Standard deviation of degree: {std_degree:.2f}\")\n",
    "    print(f\"Density: {density:.10f}\")\n",
    "    print(f\"Assortativity: {assortativity:.10f}\")\n",
    "\n",
    "# For the graph\n",
    "print(\"Graph stats:\")\n",
    "print_graph_stats(graph, genes, snps)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e2e18-acf9-4b79-a611-ce5e0d178a21",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc44238c-7139-459a-a68d-522cdafc6bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[6756193, 8], edge_index=[2, 1149046], edge_attr=[57452217], node_types=[6755968], edge_label=[1149046], edge_label_index=[2, 1149046])\n",
      "Data(x=[6756193, 8], edge_index=[2, 1149046], edge_attr=[57452217], node_types=[6755968], edge_label=[56877694], edge_label_index=[2, 56877694])\n",
      "Data(x=[6756193, 8], edge_index=[2, 58026740], edge_attr=[57452217], node_types=[6755968], edge_label=[56877694], edge_label_index=[2, 56877694])\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv(\"sig-combined-with-genes.csv\", dtype=data_types)\n",
    "# graph = Data(x=features, edge_index=edges)\n",
    "\n",
    "transform = RandomLinkSplit(num_val=0.495, num_test=0.495, is_undirected=True)\n",
    "graph_train, graph_val, graph_test = transform(graph)\n",
    "\n",
    "print(graph_train)\n",
    "print(graph_val)\n",
    "print(graph_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be4956-cc71-4ff8-acdb-4548416fd7f9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "918bb6cb-25fc-4d09-b0c0-4a925020349e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 27.8539, Val ROC-AUC: 0.5858050532, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 2, Loss: 24.7141, Val ROC-AUC: 0.6218579157, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 3, Loss: 21.7310, Val ROC-AUC: 0.6596783845, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 4, Loss: 18.9926, Val ROC-AUC: 0.6976678727, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 5, Loss: 16.4977, Val ROC-AUC: 0.7321675456, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 6, Loss: 14.3812, Val ROC-AUC: 0.7624780581, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 7, Loss: 12.4413, Val ROC-AUC: 0.7866461134, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 8, Loss: 10.8368, Val ROC-AUC: 0.8049677219, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 9, Loss: 9.3769, Val ROC-AUC: 0.8175267307, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 10, Loss: 8.1590, Val ROC-AUC: 0.8279033779, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 11, Loss: 7.1001, Val ROC-AUC: 0.8364182953, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 12, Loss: 6.2507, Val ROC-AUC: 0.8434733942, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 13, Loss: 5.5169, Val ROC-AUC: 0.8494885379, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 14, Loss: 4.9223, Val ROC-AUC: 0.8540424032, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 15, Loss: 4.4161, Val ROC-AUC: 0.8575642330, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 16, Loss: 3.9331, Val ROC-AUC: 0.8597529962, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 17, Loss: 3.5543, Val ROC-AUC: 0.8580632804, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 18, Loss: 3.2022, Val ROC-AUC: 0.8498580127, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 19, Loss: 2.9292, Val ROC-AUC: 0.8366255325, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 20, Loss: 2.6959, Val ROC-AUC: 0.8222120630, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 21, Loss: 2.4715, Val ROC-AUC: 0.8087027423, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 22, Loss: 2.3040, Val ROC-AUC: 0.7945989531, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 23, Loss: 2.1328, Val ROC-AUC: 0.7820329421, Val MRR: 0.1666666667, Val Hits@5: 0\n",
      "Epoch: 24, Loss: 1.9898, Val ROC-AUC: 0.7696735899, Val MRR: 0.1250000000, Val Hits@5: 0\n",
      "Epoch: 25, Loss: 1.8764, Val ROC-AUC: 0.7587996812, Val MRR: 0.0714285714, Val Hits@5: 0\n",
      "Epoch: 26, Loss: 1.7690, Val ROC-AUC: 0.7499125977, Val MRR: 0.0454545455, Val Hits@5: 0\n",
      "Epoch: 27, Loss: 1.6817, Val ROC-AUC: 0.7419637534, Val MRR: 0.0107526882, Val Hits@5: 0\n",
      "Epoch: 28, Loss: 1.6108, Val ROC-AUC: 0.7372657476, Val MRR: 0.0049751244, Val Hits@5: 0\n",
      "Epoch: 29, Loss: 1.5531, Val ROC-AUC: 0.7329778982, Val MRR: 0.0090909091, Val Hits@5: 0\n",
      "Epoch: 30, Loss: 1.4858, Val ROC-AUC: 0.7299706431, Val MRR: 0.0019267823, Val Hits@5: 0\n",
      "Epoch: 31, Loss: 1.4413, Val ROC-AUC: 0.7268565906, Val MRR: 0.0007662835, Val Hits@5: 0\n",
      "Epoch: 32, Loss: 1.3902, Val ROC-AUC: 0.7245190418, Val MRR: 0.0454545455, Val Hits@5: 0\n",
      "Epoch: 33, Loss: 1.3531, Val ROC-AUC: 0.7230210601, Val MRR: 0.0019047619, Val Hits@5: 0\n",
      "Epoch: 34, Loss: 1.3133, Val ROC-AUC: 0.7205280906, Val MRR: 0.0204081633, Val Hits@5: 0\n",
      "Epoch: 35, Loss: 1.2641, Val ROC-AUC: 0.7163561401, Val MRR: 0.2000000000, Val Hits@5: 1\n",
      "Epoch: 36, Loss: 1.2265, Val ROC-AUC: 0.7113249665, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 37, Loss: 1.1891, Val ROC-AUC: 0.7027063059, Val MRR: 0.5000000000, Val Hits@5: 1\n",
      "Epoch: 38, Loss: 1.1486, Val ROC-AUC: 0.6872457264, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 39, Loss: 1.1221, Val ROC-AUC: 0.6650380069, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 40, Loss: 1.0937, Val ROC-AUC: 0.6257825599, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 41, Loss: 1.0990, Val ROC-AUC: 0.5797503174, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 42, Loss: 1.1126, Val ROC-AUC: 0.5806762433, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 43, Loss: 1.0975, Val ROC-AUC: 0.5911960778, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 44, Loss: 1.0798, Val ROC-AUC: 0.5948423273, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 45, Loss: 1.0646, Val ROC-AUC: 0.5920945225, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 46, Loss: 1.0446, Val ROC-AUC: 0.5895416054, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 47, Loss: 1.0488, Val ROC-AUC: 0.5865977499, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 48, Loss: 1.0446, Val ROC-AUC: 0.5828198590, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 49, Loss: 1.0396, Val ROC-AUC: 0.5796243070, Val MRR: 1.0000000000, Val Hits@5: 1\n",
      "Epoch: 50, Loss: 1.0388, Val ROC-AUC: 0.5768068888, Val MRR: 1.0000000000, Val Hits@5: 1\n"
     ]
    }
   ],
   "source": [
    "# Task: Link prediction: does an edge exist between two nodes?\n",
    "# Node Types: 0 = Gene, 1 = SNP\n",
    "# Node Feature Vector: 8-dimensional\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(8, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Train and evaluate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GCN(hidden_channels=2).to(device)\n",
    "\n",
    "graph_train = graph_train.to(device)\n",
    "graph_val = graph_val.to(device)\n",
    "graph_test = graph_test.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Train function\n",
    "from torch_geometric.utils import negative_sampling\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model(graph_train.x.float(), graph_train.edge_index)\n",
    "\n",
    "    # Only consider positive edges for the positive score calculation\n",
    "    pos_edge_index = graph_train.edge_index\n",
    "    pos = (z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    # Use negative_sampling to generate negative edges\n",
    "    neg_edge_index = negative_sampling(edge_index=pos_edge_index, num_nodes=z.size(0), num_neg_samples=pos_edge_index.size(1))\n",
    "    neg = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    logits = torch.cat([pos, neg], dim=0)\n",
    "    targets = torch.tensor([1] * pos.size(0) + [0] * neg.size(0), dtype=torch.float32).to(device)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(edge_index, graph):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(graph.x.float(), graph.edge_index)\n",
    "        pos = torch.sigmoid((z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)).view(-1)\n",
    "        neg_edge_index = negative_sampling(edge_index, num_nodes=graph.num_nodes, num_neg_samples=edge_index.size(1))\n",
    "        neg = torch.sigmoid((z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=-1)).view(-1)\n",
    "\n",
    "        preds = np.concatenate([pos.cpu().numpy(), neg.cpu().numpy()])\n",
    "        true_labels = np.concatenate([np.ones_like(pos.cpu().numpy()), np.zeros_like(neg.cpu().numpy())])\n",
    "\n",
    "        roc_auc = roc_auc_score(true_labels, preds)\n",
    "        mrr = compute_mrr(preds, true_labels)\n",
    "        hits_at_5 = compute_hits_at_k(preds, true_labels, k=5)\n",
    "\n",
    "        return roc_auc, mrr, hits_at_5\n",
    "\n",
    "def compute_mrr(preds, true_labels):\n",
    "    # Find the predicted scores for positive examples\n",
    "    pos_preds = preds[:len(true_labels)]\n",
    "    # Rank the positive examples by predicted score in descending order\n",
    "    sorted_idx = np.argsort(pos_preds)[::-1]\n",
    "    # Find the rank of the first true positive\n",
    "    for i, idx in enumerate(sorted_idx):\n",
    "        if true_labels[idx] == 1:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0.0\n",
    "\n",
    "def compute_hits_at_k(preds, true_labels, k=5):\n",
    "    # Find the predicted scores for positive examples\n",
    "    pos_preds = preds[:len(true_labels)]\n",
    "    # Rank the positive examples by predicted score in descending order\n",
    "    sorted_idx = np.argsort(pos_preds)[::-1]\n",
    "    # Check if the first k predictions contain at least one true positive\n",
    "    hits = 0\n",
    "    for idx in sorted_idx[:k]:\n",
    "        if true_labels[idx] == 1:\n",
    "            hits = 1\n",
    "            break\n",
    "    return hits\n",
    "\n",
    "for epoch in range(50):\n",
    "    loss = train()\n",
    "    val_roc_auc, val_mrr, val_hits_at_5 = evaluate(graph_val.edge_index, graph_val)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss:.4f}, Val ROC-AUC: {val_roc_auc:.10f}, Val MRR: {val_mrr:.10f}, Val Hits@5: {val_hits_at_5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1804599a-9388-4d4c-9931-54b428e68edc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 496.00 MiB (GPU 0; 8.00 GiB total capacity; 6.84 GiB already allocated; 0 bytes free; 7.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m val_roc_auc, val_mrr, val_hits5 \u001b[38;5;241m=\u001b[39m evaluate(graph_val\u001b[38;5;241m.\u001b[39medge_index, graph_val)\n\u001b[1;32m----> 2\u001b[0m test_roc_auc, test_mrr, test_hits5 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation ROC-AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_roc_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.10f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation MRR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_mrr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.10f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 59\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(edge_index, graph)\u001b[0m\n\u001b[0;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 59\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid((z[edge_index[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m*\u001b[39m z[edge_index[\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     61\u001b[0m     neg_edge_index \u001b[38;5;241m=\u001b[39m negative_sampling(edge_index, num_nodes\u001b[38;5;241m=\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnum_nodes, num_neg_samples\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[1;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:232\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:467\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[1;32m--> 467\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m    469\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.message\u001b[1;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, edge_weight: OptTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_j \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 496.00 MiB (GPU 0; 8.00 GiB total capacity; 6.84 GiB already allocated; 0 bytes free; 7.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "val_roc_auc, val_mrr, val_hits5 = evaluate(graph_val.edge_index, graph_val)\n",
    "test_roc_auc, test_mrr, test_hits5 = evaluate(graph_test.edge_index, graph_test)\n",
    "\n",
    "print(f\"Validation ROC-AUC: {val_roc_auc:.10f}\")\n",
    "print(f\"Validation MRR: {val_mrr:.10f}\")\n",
    "print(f\"Validation Hits@5: {val_hits5:.10f}\")\n",
    "\n",
    "print(f\"Test ROC-AUC: {test_roc_auc:.10f}\")\n",
    "print(f\"Test MRR: {test_mrr:.10f}\")\n",
    "print(f\"Test Hits@5: {test_hits5:.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
