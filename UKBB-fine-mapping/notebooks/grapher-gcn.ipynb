{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00910a35-ffbc-4497-bcc8-21f008c326fb",
   "metadata": {},
   "source": [
    "# Grapher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd8be8-14cc-4d80-a944-76c5235c078b",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99bc773-edf8-4567-8767-a742662cb8ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### UKBB_94traits_release1.{tsv|bed}.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef1038-e49a-4607-9c7d-5ce6daf1d94b",
   "metadata": {},
   "source": [
    "This file contains genetic variant data used in a study investigating 94 complex diseases and traits from the UK Biobank. Each row represents a variant with columns detailing characteristics such as its genomic location, allele details, association statistics, and more. It also includes indicators for linkage disequilibrium with variants failing Hardy Weinberg equilibrium or with common structural variants. This file is particularly valuable for those interested in the genetic association results and the fine-mapping of these traits and diseases.\n",
    "\n",
    "Columns:\n",
    "\n",
    "1. Chromosome: hg19 autosomes only\n",
    "2. Start: 0-indexed hg19 start position\n",
    "3. End: 0-indexed hg19 end position\n",
    "4. Variant: unique variant identifier (chr:pos:ref:alt)\n",
    "5. rsid: rsid identifier\n",
    "6. Allele1: reference allele in hg19\n",
    "7. Allele2: alternative allele in hg19\n",
    "8. Minor allele: minor allele in cohort\n",
    "9. Cohort: GWAS cohort\n",
    "10. Model_marginal: type of regression model used\n",
    "11. Method: fine-mapping method used\n",
    "12. Trait: abbreviation for phenotype in genetic association tests\n",
    "13. Region: fine-mapping region in hg19\n",
    "14. MAF: minor allele frequency in cohort\n",
    "15. Beta_marginal: marginal association effect size (effect allele: alternative)\n",
    "16. SE_marginal: standard error on marginal association effect size\n",
    "17. Chisq_marginal: test statistic for marginal association\n",
    "18. PIP: posterior probability of association from fine-mapping\n",
    "19. CS_ID: ID of 95% credible set (-1 if variant not in 95% CS)\n",
    "20. Beta_posterior: posterior expectation of true effect size (effect allele: alternative)\n",
    "21. SD_posterior: posterior standard deviation of true effect size\n",
    "22. LD_HWE: indicator for LD (R^2 > 0.6) with a variant that failed HWE (p < 10^-12) in UK10K LD\n",
    "23. LD_SV: indicator for LD (R^2 > 0.8) with a common structural variant in gnomAD European samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b033d-95f5-4584-b10c-72969a166612",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4345459-b1ef-477c-8f06-c8f54c194af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandoc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "\n",
    "import networkx as nx\n",
    "from ogb.io import DatasetSaver\n",
    "from ogb.linkproppred import LinkPropPredDataset\n",
    "\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f7ab7-4bf0-4dba-9428-9580338d9aa7",
   "metadata": {},
   "source": [
    "## Perform checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729b64d-2166-4dbb-9c4c-4173e0c9e807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f213c8b-5dc0-468b-b7d0-72c08a6e5282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a754a-7836-439e-801c-7efca6d2dfc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe5b06-7392-4d62-a1e8-af081cdf3e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/geometric-omics/UKBB-fine-mapping/data/UKBB_94traits_release1.csv')\n",
    "hg19_gene_positions = pd.read_csv(\"~/Desktop/geometric-omics/UKBB-fine-mapping/data/hg19-gene-positions.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de12a0-5352-4bbc-9d24-baf89c6b6570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['position'] = data['variant'].str.split(':').str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e3e7c-413a-4014-a103-1762a804bc50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get geneSymbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4d183-cc94-4d72-9c95-e5347d43f760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Sort the dataframes and convert columns to string type\n",
    "data = data.sort_values(by=['chromosome', 'start'])\n",
    "data['chromosome'] = data['chromosome'].astype(str)\n",
    "\n",
    "hg19_gene_positions = hg19_gene_positions.sort_values(by=['chrom', 'txStart'])\n",
    "hg19_gene_positions['chrom'] = hg19_gene_positions['chrom'].astype(str)\n",
    "\n",
    "# Define leniency\n",
    "leniency = 100000\n",
    "\n",
    "# Convert the 'chrom' column to category type for efficient memory usage\n",
    "data['chromosome'] = data['chromosome'].astype('category')\n",
    "hg19_gene_positions['chrom'] = hg19_gene_positions['chrom'].astype('category')\n",
    "\n",
    "# Create an empty dictionary to store geneSymbols\n",
    "gene_symbols_dict = {}\n",
    "\n",
    "# Iterate over unique chromosome\n",
    "for chromosome in data['chromosome'].cat.categories:\n",
    "    # Subset data for current chromosome\n",
    "    data_chromosome = data[data['chromosome'] == chromosome]\n",
    "    hg19_gene_positions_chromosome = hg19_gene_positions[hg19_gene_positions['chrom'] == chromosome]\n",
    "\n",
    "    # Build KDTree for efficient nearest-neighbor search\n",
    "    tree = cKDTree(np.expand_dims(hg19_gene_positions_chromosome['txStart'].values, axis=1))\n",
    "\n",
    "    # Query the KDTree for nearest neighbors within the leniency\n",
    "    distances, indices = tree.query(np.expand_dims(data_chromosome['start'].values, axis=1), distance_upper_bound=leniency)\n",
    "\n",
    "    # Create a list of gene symbols\n",
    "    gene_symbols = []\n",
    "    for idx, distance in zip(indices, distances):\n",
    "        if distance == np.inf:\n",
    "            gene_symbols.append('N/A')  # or any other default value you want\n",
    "        else:\n",
    "            gene_symbols.append(hg19_gene_positions_chromosome.iloc[idx]['geneSymbol'])\n",
    "\n",
    "    # Assign geneSymbols to data dictionary\n",
    "    for idx, gene_symbol in zip(data_chromosome.index, gene_symbols):\n",
    "        gene_symbols_dict[idx] = gene_symbol\n",
    "\n",
    "# Convert the dictionary to a Series and assign it to a new column in 'data'\n",
    "data['geneSymbol'] = pd.Series(gene_symbols_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2594b60-01fa-49ad-86b0-b38c0ee4c80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_values = data['geneSymbol'].isnull().sum()\n",
    "print(\"Number of null values in data['geneSymbol']: \", null_values)\n",
    "\n",
    "unique_elements1 = data['geneSymbol'].nunique()\n",
    "print(\"Number of unique elements in data['geneSymbol']: \", unique_elements1)\n",
    "\n",
    "unique_elements2 = hg19_gene_positions['geneSymbol'].nunique()\n",
    "print(\"Number of unique elements in hg19_gene_positions['geneSymbol']: \", unique_elements2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909d6f3-c521-4367-8941-6cec56b48eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.sample(frac=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eddaed-2f48-4440-b6d6-0dc247f23ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Proposed graph features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe89142-2b65-469b-b330-1620d303312b",
   "metadata": {},
   "source": [
    "All columns from `data` dataframe:\n",
    "\n",
    "Phenotype nodes features:\n",
    "- `trait` column\n",
    "\n",
    "Gene nodes features:\n",
    "- `geneSymbol` column\n",
    "- `chromosome` column\n",
    "- `start` column\n",
    "- `end` column\n",
    "\n",
    "SNP node features:\n",
    "- `rsid` column\n",
    "- `chromosome` column\n",
    "- `position` column\n",
    "- `allele1` column\n",
    "- `allele2` column\n",
    "\n",
    "Edge features:\n",
    "- undirected\n",
    "- unweighted \n",
    "- positive if associations exist in graph\n",
    "- negative if not (100 random negative edges for every positive edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abe533-6610-4f82-b8d6-533eb010858d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b5a45-34bc-441b-a20d-c78ff8a92d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "\n",
    "# Create mappings for phenotypes, genes, and SNPs to integer indices\n",
    "phenotypes = data['trait'].unique()\n",
    "genes = data['geneSymbol'].unique()\n",
    "snps = data['rsid'].unique()\n",
    "phenotype_to_idx = {phenotype: idx for idx, phenotype in enumerate(phenotypes)}\n",
    "gene_to_idx = {gene: idx + len(phenotypes) for idx, gene in enumerate(genes)}\n",
    "snp_to_idx = {snp: idx + len(phenotypes) + len(genes) for idx, snp in enumerate(snps)}\n",
    "\n",
    "\n",
    "# Create node feature vectors for phenotypes, genes, and SNPs\n",
    "phenotype_features = data.loc[data['trait'].isin(phenotypes)][['trait']].drop_duplicates().sort_values(by='trait').reset_index(drop=True)\n",
    "gene_features = data.loc[data['geneSymbol'].isin(genes)][['geneSymbol', 'chromosome', 'start', 'end']].drop_duplicates().sort_values(by='geneSymbol').reset_index(drop=True)\n",
    "snp_features = data.loc[data['rsid'].isin(snps)][['rsid', 'chromosome', 'position', 'allele1', 'allele2']].drop_duplicates().sort_values(by='rsid').reset_index(drop=True)\n",
    "\n",
    "# Create node type labels\n",
    "node_types = torch.tensor([0] * len(phenotypes) + [1] * len(genes) + [2] * len(snps), dtype=torch.long)\n",
    "\n",
    "# Create positive edges between SNPs and genes\n",
    "positive_edges_snp_gene = data.loc[:, ['rsid', 'geneSymbol']].drop_duplicates()\n",
    "positive_edges_snp_gene['snp_idx'] = positive_edges_snp_gene['rsid'].map(snp_to_idx)\n",
    "positive_edges_snp_gene['gene_idx'] = positive_edges_snp_gene['geneSymbol'].map(gene_to_idx)\n",
    "positive_edges_snp_gene = positive_edges_snp_gene[['snp_idx', 'gene_idx']].values\n",
    "positive_edges_snp_gene = torch.tensor(positive_edges_snp_gene, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create positive edges between genes and phenotypes\n",
    "positive_edges_gene_phenotype = data.loc[:, ['geneSymbol', 'trait']].drop_duplicates()\n",
    "positive_edges_gene_phenotype['gene_idx'] = positive_edges_gene_phenotype['geneSymbol'].map(gene_to_idx)\n",
    "positive_edges_gene_phenotype['phenotype_idx'] = positive_edges_gene_phenotype['trait'].map(phenotype_to_idx)\n",
    "positive_edges_gene_phenotype = positive_edges_gene_phenotype[['gene_idx', 'phenotype_idx']].values\n",
    "positive_edges_gene_phenotype = torch.tensor(positive_edges_gene_phenotype, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create negative edges for SNP-Gene\n",
    "negative_edges_snp_gene = []\n",
    "positive_edges_set = set([tuple(x) for x in positive_edges_snp_gene.t().tolist()])\n",
    "for _ in range(100_000 * len(positive_edges_snp_gene[0])):\n",
    "    while True:\n",
    "        random_snp = random.randint(0, len(snps) - 1)\n",
    "        random_gene = random.randint(0, len(genes) - 1)\n",
    "        negative_edge = (random_snp, random_gene)\n",
    "        if negative_edge not in positive_edges_set:\n",
    "            negative_edges_snp_gene.append(negative_edge)\n",
    "            break\n",
    "negative_edges_snp_gene = torch.tensor(negative_edges_snp_gene, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create negative edges for Gene-Phenotype\n",
    "negative_edges_gene_phenotype = []\n",
    "positive_edges_set = set([tuple(x) for x in positive_edges_gene_phenotype.t().tolist()])\n",
    "for _ in range(100 * len(positive_edges_gene_phenotype[0])):\n",
    "    while True:\n",
    "        random_gene = random.randint(0, len(genes) - 1)\n",
    "        random_phenotype = random.randint(0, len(phenotypes) - 1)\n",
    "        negative_edge = (random_gene, random_phenotype)\n",
    "        if negative_edge not in positive_edges_set:\n",
    "            negative_edges_gene_phenotype.append(negative_edge)\n",
    "            break\n",
    "negative_edges_gene_phenotype = torch.tensor(negative_edges_gene_phenotype, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Combine positive and negative edges\n",
    "edges = torch.cat([positive_edges_snp_gene, positive_edges_gene_phenotype, negative_edges_snp_gene, negative_edges_gene_phenotype], dim=1)\n",
    "\n",
    "# Create edge attributes\n",
    "edge_attr = torch.ones(edges.size(1), dtype=torch.float)\n",
    "\n",
    "# Combine the feature vectors\n",
    "combined_features = pd.concat([phenotype_features, gene_features, snp_features], ignore_index=True).drop(['trait', 'geneSymbol', 'rsid'], axis=1)\n",
    "\n",
    "# Now you can fill NaNs with 'N/A'\n",
    "nan_replacements = {'chromosome': 'N/A', 'start': 0, 'end': 0, 'position': 0, 'allele1': 'N/A', 'allele2': 'N/A'}\n",
    "for col, replacement in nan_replacements.items():\n",
    "    if col in combined_features:\n",
    "        if combined_features[col].dtype.name == 'category' and replacement not in combined_features[col].cat.categories:\n",
    "            combined_features[col] = combined_features[col].cat.add_categories([replacement])\n",
    "        combined_features[col].fillna(replacement, inplace=True)\n",
    "\n",
    "# Label encoding for categorical columns\n",
    "le = LabelEncoder()\n",
    "combined_features = combined_features.apply(lambda col: le.fit_transform(col.astype(str)) if col.dtype == 'object' else col)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = ['start', 'end', 'position']\n",
    "categorical_columns = ['chromosome', 'allele1', 'allele2']\n",
    "for col in categorical_columns:\n",
    "    combined_features[col] = combined_features[col].astype('category').cat.codes\n",
    "\n",
    "features = torch.tensor(combined_features.values, dtype=torch.float)\n",
    "\n",
    "# Create the PyTorch Geometric graph\n",
    "graph = Data(x=features, edge_index=edges, edge_attr=edge_attr)\n",
    "graph.node_types = node_types\n",
    "\n",
    "print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "print(f\"Number of positive edges between SNPs and genes: {positive_edges_snp_gene.size(1)}\")\n",
    "print(f\"Number of positive edges between genes and phenotypes: {positive_edges_gene_phenotype.size(1)}\")\n",
    "print(f\"Number of negative edges for SNPs and genes: {negative_edges_snp_gene.size(1)}\")\n",
    "print(f\"Number of negative edges for genes and phenotypes: {negative_edges_gene_phenotype.size(1)}\")\n",
    "print(f\"Number of edges: {graph.num_edges}\")\n",
    "print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "print(f\"Node types: {graph.node_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60cae52-2493-43ae-9e27-e7dc67c3a7f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7d0e2-80bf-4a82-9c1c-6aac6307aab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for NaN values in features\n",
    "nan_in_features = torch.isnan(graph.x).any().item()\n",
    "print(f\"Are there any NaN values in features? {nan_in_features}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2a08f05-3012-4d85-85eb-3f5cb6a6955c",
   "metadata": {
    "tags": []
   },
   "source": [
    "def print_graph_stats(graph, phenotypes, snps):\n",
    "    G = nx.Graph()\n",
    "    edge_weights = graph.edge_attr.view(-1)  # ensure that edge_attr is a 1D tensor\n",
    "    for edge, weight in zip(graph.edge_index.t().numpy(), edge_weights):\n",
    "        G.add_edge(edge[0], edge[1], weight=weight.item())  # use the pip value as the edge weight\n",
    "\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_phenotypes = len(phenotypes)\n",
    "    num_genes = len(genes)\n",
    "    num_snps = len(snps)\n",
    "    num_positive_edges = sum(weight > 0 for weight in edge_weights)\n",
    "    num_negative_edges = sum(weight == 0 for weight in edge_weights)\n",
    "    num_edges = G.number_of_edges()\n",
    "    num_connected_components = nx.number_connected_components(G)\n",
    "    average_degree = np.mean([degree for _, degree in G.degree()])\n",
    "    median_degree = np.median([degree for _, degree in G.degree()])\n",
    "    std_degree = np.std([degree for _, degree in G.degree()])\n",
    "    density = nx.density(G)\n",
    "    assortativity = nx.degree_assortativity_coefficient(G)\n",
    "    edge_weights = [data[\"weight\"] for _, _, data in G.edges(data=True)]\n",
    "    average_weight = np.mean(edge_weights)\n",
    "    median_weight = np.median(edge_weights)\n",
    "    std_weight = np.std(edge_weights)\n",
    "\n",
    "    print(f\"Number of nodes: {num_nodes}\")\n",
    "    print(\"Number of SNP nodes:\", num_snps)\n",
    "    print(\"Number of Gene nodes:\", num_genes)\n",
    "    print(\"Number of Phenotype nodes:\", num_phenotypes)\n",
    "    print(f\"Number of positive edges: {num_positive_edges}\")\n",
    "    print(f\"Number of negative edges: {num_negative_edges}\")\n",
    "    print(f\"Number of edges: {num_edges}\")\n",
    "    print(f\"Number of connected components: {num_connected_components}\")\n",
    "    print(f\"Average degree: {average_degree:.2f}\")\n",
    "    print(f\"Median degree: {median_degree}\")\n",
    "    print(f\"Standard deviation of degree: {std_degree:.2f}\")\n",
    "    print(f\"Density: {density:.10f}\")\n",
    "    print(f\"Assortativity: {assortativity:.10f}\")\n",
    "    print(f\"Average edge weight: {average_weight:.2f}\")\n",
    "    print(f\"Median edge weight: {median_weight}\")\n",
    "    print(f\"Standard deviation of edge weight: {std_weight:.2f}\")\n",
    "\n",
    "# Print\n",
    "print(\"Graph stats:\")\n",
    "print_graph_stats(graph, phenotypes, snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab9a9e-7a28-4d0e-b17f-05a64f58e3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import degree\n",
    "\n",
    "# Compute the degree of each node\n",
    "degrees = degree(graph.edge_index[0])\n",
    "\n",
    "# Print statistics about the degrees\n",
    "print(f\"Minimum degree: {degrees.min().item()}\")\n",
    "print(f\"Maximum degree: {degrees.max().item()}\")\n",
    "print(f\"Average degree: {degrees.float().mean().item()}\")\n",
    "\n",
    "# Count the number of nodes with degree 1\n",
    "num_nodes_degree_1 = (degrees == 1).sum().item()\n",
    "print(f\"Number of nodes with degree 1: {num_nodes_degree_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51e96d-660c-4b4f-8ac4-9a07dba5bcc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d110955-0ad0-41d7-81fc-e41226316964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit \n",
    "\n",
    "transform = RandomLinkSplit(num_val=0.2, num_test=0.2, is_undirected=True)\n",
    "graph_train, graph_val, graph_test = transform(graph)\n",
    "\n",
    "print(graph_train)\n",
    "print(graph_val)\n",
    "print(graph_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8eaae7-0ff7-4ce7-bb7c-7fffc8632d00",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744860e-e107-4495-9e88-79fe72ac7db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task: Link prediction: does an edge exist between two nodes?\n",
    "# Node Types: 0 = phenotypes, 1 = gene, 2 = snps\n",
    "# Node Feature Vector: 6-dimensional\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(6, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Train and evaluate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GCN(hidden_channels=16).to(device)\n",
    "\n",
    "graph_train = graph_train.to(device)\n",
    "graph_val = graph_val.to(device)\n",
    "graph_test = graph_test.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Train function\n",
    "from torch_geometric.utils import negative_sampling\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model(graph_train.x.float(), graph_train.edge_index)\n",
    "\n",
    "    # Only consider positive edges for the positive score calculation\n",
    "    pos_edge_index = graph_train.edge_index\n",
    "    pos = (z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    # Use negative_sampling to generate negative edges\n",
    "    neg_edge_index = negative_sampling(edge_index=pos_edge_index, num_nodes=z.size(0), num_neg_samples=pos_edge_index.size(1))\n",
    "    neg = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    logits = torch.cat([pos, neg], dim=0)\n",
    "    targets = torch.tensor([1] * pos.size(0) + [0] * neg.size(0), dtype=torch.float32).to(device)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(edge_index, graph):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(graph.x.float(), graph.edge_index)\n",
    "        pos = torch.sigmoid((z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)).view(-1)\n",
    "        neg_edge_index = negative_sampling(edge_index, num_nodes=graph.num_nodes, num_neg_samples=edge_index.size(1))\n",
    "        neg = torch.sigmoid((z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=-1)).view(-1)\n",
    "\n",
    "        preds = np.concatenate([pos.cpu().numpy(), neg.cpu().numpy()])\n",
    "        true_labels = np.concatenate([np.ones_like(pos.cpu().numpy()), np.zeros_like(neg.cpu().numpy())])\n",
    "\n",
    "        roc_auc = roc_auc_score(true_labels, preds)\n",
    "        mrr = compute_mrr(preds, true_labels)\n",
    "        hits_at_5 = compute_hits_at_k(preds, true_labels, k=5)\n",
    "\n",
    "        return roc_auc, mrr, hits_at_5\n",
    "\n",
    "def compute_mrr(preds, true_labels):\n",
    "    # Find the predicted scores for positive examples\n",
    "    pos_preds = preds[:len(true_labels)]\n",
    "    # Rank the positive examples by predicted score in descending order\n",
    "    sorted_idx = np.argsort(pos_preds)[::-1]\n",
    "    # Find the rank of the first true positive\n",
    "    for i, idx in enumerate(sorted_idx):\n",
    "        if true_labels[idx] == 1:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0.0\n",
    "\n",
    "def compute_hits_at_k(preds, true_labels, k=5):\n",
    "    # Find the predicted scores for positive examples\n",
    "    pos_preds = preds[:len(true_labels)]\n",
    "    # Rank the positive examples by predicted score in descending order\n",
    "    sorted_idx = np.argsort(pos_preds)[::-1]\n",
    "    # Check if the first k predictions contain at least one true positive\n",
    "    hits = 0\n",
    "    for idx in sorted_idx[:k]:\n",
    "        if true_labels[idx] == 1:\n",
    "            hits = 1\n",
    "            break\n",
    "    return hits\n",
    "\n",
    "max_val_roc_auc = -np.inf\n",
    "max_val_mrr = -np.inf\n",
    "max_val_hits5 = -np.inf\n",
    "\n",
    "max_test_roc_auc = -np.inf\n",
    "max_test_mrr = -np.inf\n",
    "max_test_hits5 = -np.inf\n",
    "\n",
    "for epoch in range(150):\n",
    "    loss = train()\n",
    "    val_roc_auc, val_mrr, val_hits_at_5 = evaluate(graph_val.edge_index, graph_val)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss:.4f}, Val ROC-AUC: {val_roc_auc:.10f}, Val MRR: {val_mrr:.10f}, Val Hits@5: {val_hits_at_5}\")\n",
    "    max_val_roc_auc = max(max_val_roc_auc, val_roc_auc)\n",
    "    max_val_mrr = max(max_val_mrr, val_mrr)\n",
    "    max_val_hits5 = max(max_val_hits5, val_hits_at_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d432600-1aa5-41ac-9c0d-a6d833acf505",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55930699-10ed-4220-8144-139098ecf0f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_roc_auc, val_mrr, val_hits5 = evaluate(graph_val.edge_index, graph_val)\n",
    "test_roc_auc, test_mrr, test_hits5 = evaluate(graph_test.edge_index, graph_test)\n",
    "\n",
    "max_test_roc_auc = max(max_test_roc_auc, test_roc_auc)\n",
    "max_test_mrr = max(max_test_mrr, test_mrr)\n",
    "max_test_hits5 = max(max_test_hits5, test_hits5)\n",
    "\n",
    "print(f\"Maximum Validation ROC-AUC: {max_val_roc_auc:.10f}\")\n",
    "print(f\"Maximum Validation MRR: {max_val_mrr:.10f}\")\n",
    "print(f\"Maximum Validation Hits@5: {max_val_hits5:.10f}\")\n",
    "\n",
    "print(f\"Maximum Test ROC-AUC: {max_test_roc_auc:.10f}\")\n",
    "print(f\"Maximum Test MRR: {max_test_mrr:.10f}\")\n",
    "print(f\"Maximum Test Hits@5: {max_test_hits5:.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
