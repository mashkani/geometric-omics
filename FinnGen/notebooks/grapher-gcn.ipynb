{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00910a35-ffbc-4497-bcc8-21f008c326fb",
   "metadata": {},
   "source": [
    "# Grapher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd8be8-14cc-4d80-a944-76c5235c078b",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99bc773-edf8-4567-8767-a742662cb8ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [FinnGen](https://finngen.gitbook.io/documentation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef1038-e49a-4607-9c7d-5ce6daf1d94b",
   "metadata": {},
   "source": [
    "Any large Canadian GWAS-related clinical trials?\n",
    "\n",
    "- The FinnGen research project is an expedition to the frontier of genomics and medicine, with significant discoveries potentially arising from any one of Finland’s 500,000 biomedical pioneers.\n",
    "- The project brings together a nation-wide network of Finnish biobanks, with every Finn able to participate in the study by giving biobank consent.\n",
    "- As of the last update, there were 589,000 samples available, with a goal to reach 520,000 by 2023. The latest data freeze included combined genotype and health registry data from 473,681 individuals.\n",
    "- The study utilizes samples collected by a nationwide network of Finnish biobanks and combines genome information with digital health care data from national health registries【8†source】.\n",
    "- There's a need for samples from all over Finland as solutions in the field of personalized healthcare can be found only by looking at large populations. Every Finn can be a part of the FinnGen study by giving a biobank consent.\n",
    "- The genome data produced during the project is owned by the Finnish biobanks and remains available for research purposes. The medical breakthroughs that arise from the project are expected to benefit health care systems and patients globally.\n",
    "- The FinnGen research project is collaborative, involving all the same actors as drug development, with the aim to speed up the emergence of new innovations.\n",
    "- The project's data freeze 9 results and summary statistics are now available, consisting of over 377,200 individuals, almost 20.2 M variants, and 2,272 disease endpoints. Results can be browsed online using the FinnGen web browser, and the summary statistics downloaded.\n",
    "- The University of Helsinki is the organization responsible for the study, and the nationwide network of Finnish biobanks is participating in the study, thus covering the whole of Finland. The Helsinki Biobank coordinates the sample collection.\n",
    "- For more information, the project can be contacted at finngen-info@helsinki.fi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1805a-55dc-409c-9ccf-512eb1f88667",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8ec1d-73be-4b8c-95dc-79489e84998b",
   "metadata": {},
   "source": [
    "Here's the summary documentation for the DataFrame in bullet format:\n",
    "\n",
    "- `#chrom`: This column represents the chromosome number where the genetic variant is located.\n",
    "\n",
    "- `pos`: This is the position of the genetic variant on the chromosome.\n",
    "\n",
    "- `ref`: This column represents the reference allele (or variant) at the genomic position.\n",
    "\n",
    "- `alt`: This is the alternate allele observed at this position.\n",
    "\n",
    "- `rsids`: This stands for reference SNP cluster ID. It's a unique identifier for each variant used in the dbSNP database.\n",
    "\n",
    "- `nearest_genes`: This column represents the gene which is nearest to the variant.\n",
    "\n",
    "- `pval`: This represents the p-value, which is a statistical measure for the strength of evidence against the null hypothesis.\n",
    "\n",
    "- `mlogp`: This represents the minus log of the p-value, commonly used in genomic studies.\n",
    "\n",
    "- `beta`: The beta coefficient represents the effect size of the variant.\n",
    "\n",
    "- `sebeta`: This is the standard error of the beta coefficient.\n",
    "\n",
    "- `af_alt`: This is the allele frequency of the alternate variant in the general population.\n",
    "\n",
    "- `af_alt_cases`: This is the allele frequency of the alternate variant in the cases group.\n",
    "\n",
    "- `af_alt_controls`: This is the allele frequency of the alternate variant in the control group.\n",
    "\n",
    "- `causal`: This binary column indicates whether the variant is determined to be causal (1) or not (0).\n",
    "\n",
    "- `trait`: This column represents the trait associated with the variant. In this dataset, it is the response to the drug paracetamol and NSAIDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b033d-95f5-4584-b10c-72969a166612",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4345459-b1ef-477c-8f06-c8f54c194af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "\n",
    "import networkx as nx\n",
    "from ogb.io import DatasetSaver\n",
    "from ogb.linkproppred import LinkPropPredDataset\n",
    "\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f7ab7-4bf0-4dba-9428-9580338d9aa7",
   "metadata": {},
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b729b64d-2166-4dbb-9c4c-4173e0c9e807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu118\n",
      "PyTorch Geometric version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f213c8b-5dc0-468b-b7d0-72c08a6e5282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce RTX 3060 Ti (cuda)\n",
      "CUDA version: 11.8\n",
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a754a-7836-439e-801c-7efca6d2dfc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data and create new rows for each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05fe5b06-7392-4d62-a1e8-af081cdf3e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes={\n",
    "    '#chrom': 'string',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'causal':'int64',\n",
    "    'LD': 'int64',\n",
    "    'lead': 'string',\n",
    "    'trait': 'string'\n",
    "}\n",
    "data = pd.read_csv('~/Desktop/gwas-graph/FinnGen/data/gwas-causal.csv', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b729972-b0d7-4e38-b8e2-aedd07506c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['nearest_genes'] = data['nearest_genes'].astype(str)\n",
    "\n",
    "# Assuming your DataFrame is called data and the relevant column is 'nearest_genes'\n",
    "# First, let's split the gene names in the 'nearest_genes' column\n",
    "split_genes = data['nearest_genes'].str.split(',')\n",
    "\n",
    "# Flatten the list of split gene names\n",
    "flat_genes = [item for sublist in split_genes for item in sublist]\n",
    "\n",
    "# Then, we create a new DataFrame by repeating rows and substituting the gene names\n",
    "data_new = (data.loc[data.index.repeat(split_genes.str.len())]\n",
    "            .assign(nearest_genes=flat_genes))\n",
    "\n",
    "# Reset index to have a standard index\n",
    "data = data_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "513cafa0-f3f8-47b5-9d22-96062449edde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>rsids</th>\n",
       "      <th>nearest_genes</th>\n",
       "      <th>pval</th>\n",
       "      <th>mlogp</th>\n",
       "      <th>beta</th>\n",
       "      <th>sebeta</th>\n",
       "      <th>af_alt</th>\n",
       "      <th>af_alt_cases</th>\n",
       "      <th>af_alt_controls</th>\n",
       "      <th>causal</th>\n",
       "      <th>LD</th>\n",
       "      <th>lead</th>\n",
       "      <th>trait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13668</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>rs2691328</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.024860</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>0.084918</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14773</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>rs878915777</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.844305</td>\n",
       "      <td>0.073501</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>0.013485</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15585</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>rs533630043</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.841908</td>\n",
       "      <td>0.074735</td>\n",
       "      <td>0.031464</td>\n",
       "      <td>0.157751</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16549</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>rs1262014613</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.343308</td>\n",
       "      <td>0.464316</td>\n",
       "      <td>0.241377</td>\n",
       "      <td>0.254711</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16567</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>rs1194064194</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.130736</td>\n",
       "      <td>0.086319</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565622</th>\n",
       "      <td>23</td>\n",
       "      <td>155697920</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.027115</td>\n",
       "      <td>1.566790</td>\n",
       "      <td>-0.013475</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.290961</td>\n",
       "      <td>0.286054</td>\n",
       "      <td>0.291879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565623</th>\n",
       "      <td>23</td>\n",
       "      <td>155698443</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.178417</td>\n",
       "      <td>0.748564</td>\n",
       "      <td>-0.069907</td>\n",
       "      <td>0.051951</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565624</th>\n",
       "      <td>23</td>\n",
       "      <td>155698490</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.279640</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>-0.020245</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>0.024312</td>\n",
       "      <td>0.024423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565625</th>\n",
       "      <td>23</td>\n",
       "      <td>155699751</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.078864</td>\n",
       "      <td>1.103120</td>\n",
       "      <td>-0.011284</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.244829</td>\n",
       "      <td>0.241257</td>\n",
       "      <td>0.245498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565626</th>\n",
       "      <td>23</td>\n",
       "      <td>155700291</td>\n",
       "      <td>CAA</td>\n",
       "      <td>C</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.071590</td>\n",
       "      <td>1.145150</td>\n",
       "      <td>-0.011563</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.245328</td>\n",
       "      <td>0.241724</td>\n",
       "      <td>0.246003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20565627 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         #chrom        pos  ref alt         rsids nearest_genes      pval   \n",
       "0             1      13668    G   A     rs2691328         OR4F5  0.944365  \\\n",
       "1             1      14773    C   T   rs878915777         OR4F5  0.844305   \n",
       "2             1      15585    G   A   rs533630043         OR4F5  0.841908   \n",
       "3             1      16549    T   C  rs1262014613         OR4F5  0.343308   \n",
       "4             1      16567    G   C  rs1194064194         OR4F5  0.129883   \n",
       "...         ...        ...  ...  ..           ...           ...       ...   \n",
       "20565622     23  155697920    G   A          <NA>          <NA>  0.027115   \n",
       "20565623     23  155698443    C   A          <NA>          <NA>  0.178417   \n",
       "20565624     23  155698490    C   T          <NA>          <NA>  0.279640   \n",
       "20565625     23  155699751    C   T          <NA>          <NA>  0.078864   \n",
       "20565626     23  155700291  CAA   C          <NA>          <NA>  0.071590   \n",
       "\n",
       "             mlogp      beta    sebeta    af_alt  af_alt_cases   \n",
       "0         0.024860 -0.005926  0.084918  0.005842      0.005729  \\\n",
       "1         0.073501  0.010088  0.051369  0.013495      0.013547   \n",
       "2         0.074735  0.031464  0.157751  0.001113      0.001125   \n",
       "3         0.464316  0.241377  0.254711  0.000561      0.000620   \n",
       "4         0.886447  0.130736  0.086319  0.004170      0.004250   \n",
       "...            ...       ...       ...       ...           ...   \n",
       "20565622  1.566790 -0.013475  0.006097  0.290961      0.286054   \n",
       "20565623  0.748564 -0.069907  0.051951  0.003259      0.003022   \n",
       "20565624  0.553400 -0.020245  0.018725  0.024406      0.024312   \n",
       "20565625  1.103120 -0.011284  0.006421  0.244829      0.241257   \n",
       "20565626  1.145150 -0.011563  0.006418  0.245328      0.241724   \n",
       "\n",
       "          af_alt_controls  causal  LD  lead trait  \n",
       "0                0.005863       0   0  <NA>   T2D  \n",
       "1                0.013485       0   0  <NA>   T2D  \n",
       "2                0.001110       0   0  <NA>   T2D  \n",
       "3                0.000550       0   0  <NA>   T2D  \n",
       "4                0.004154       0   0  <NA>   T2D  \n",
       "...                   ...     ...  ..   ...   ...  \n",
       "20565622         0.291879       0   0  <NA>   T2D  \n",
       "20565623         0.003304       0   0  <NA>   T2D  \n",
       "20565624         0.024423       0   0  <NA>   T2D  \n",
       "20565625         0.245498       0   0  <NA>   T2D  \n",
       "20565626         0.246003       0   0  <NA>   T2D  \n",
       "\n",
       "[20565627 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e14ab37-9bcf-458b-882d-94604efbc5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in 'rsids' column\n",
    "data.dropna(subset=['rsids'], inplace=True)\n",
    "\n",
    "# Keep only rows with unique values in 'rsids' column\n",
    "data = data[data.duplicated(subset='rsids', keep=False) == False]\n",
    "\n",
    "# Adjust the index if necessary\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "011a6c79-4026-4e07-a032-0042f21e9a21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18295392"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eddaed-2f48-4440-b6d6-0dc247f23ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe89142-2b65-469b-b330-1620d303312b",
   "metadata": {},
   "source": [
    "**Task Overview**\n",
    "- The objective is to design and implement a link prediction deep neural network model for analyzing relationships between SNP nodes and Phenotype nodes.\n",
    "\n",
    "**Nodes and Their Features**\n",
    "- There are two types of nodes: SNP Nodes and Phenotype Nodes.\n",
    "- *Phenotype Nodes*: Each Phenotype Node represents a particular trait. This information comes from the `trait` column in the data.\n",
    "- *SNP Nodes*: Each SNP Node is characterized by various features, including `rsids`, `nearest_genes`, `#chrom`, `pos`, `ref`, `alt`, `beta`, `sebeta`, `af_alt`, and `af_alt_cases` columns.\n",
    "\n",
    "**Edges, Their Features, and Labels**\n",
    "- Edges represent relationships between nodes. There are two types of edges: SNP-Phenotype and SNP-SNP.\n",
    "- *SNP-Phenotype Edges*:\n",
    "  - These edges are undirected, linking SNP Nodes and Phenotype Nodes.\n",
    "  - The label for each edge is determined by the `causal` column in the data:\n",
    "    - A label of +1 is assigned when `data['causal']` is 1, indicating a causal relationship.\n",
    "    - A label of -1 is assigned when `data['causal']` is 0, indicating the absence of a causal relationship.\n",
    "- *SNP-SNP Edges*:\n",
    "  - These edges are undirected, linking an SNP Node (as identified by the `rsids` column) to another SNP Node (as identified by the `lead` column) in the same data row.\n",
    "  - The label for each edge is determined by the `LD` column in the data:\n",
    "    - A label of +1 is assigned when `data['LD']` is 1, signifying that the two SNPs are in linkage disequilibrium.\n",
    "    - A label of -1 is assigned when `data['LD']` is 0, indicating that the two SNPs are not in linkage disequilibrium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abe533-6610-4f82-b8d6-533eb010858d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f0a2540-a59c-4869-a2f2-f2f93c3e4ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted to tensor!\n",
      "Number of nodes: 18295393\n",
      "Number of positive SNP-Phenotype edges: 37\n",
      "Number of negative SNP-Phenotype edges: 18295355\n",
      "Number of positive SNP-SNP edges: 3787\n",
      "Number of negative SNP-SNP edges: 18291605\n",
      "Number of edges: 3824\n",
      "Node feature dimension: 9\n",
      "Node types: tensor([0, 1, 1,  ..., 1, 1, 1])\n",
      "CPU times: total: 1min 38s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "\n",
    "# Create mappings for phenotypes and SNPs to integer indices\n",
    "phenotypes = data['trait'].unique()\n",
    "snps = data['rsids'].unique()\n",
    "phenotype_to_idx = {phenotype: idx for idx, phenotype in enumerate(phenotypes)}\n",
    "snp_to_idx = {snp: idx + len(phenotypes) for idx, snp in enumerate(snps)}\n",
    "\n",
    "# Create node feature vectors for phenotypes and SNPs\n",
    "phenotype_features = data.loc[data['trait'].isin(phenotypes)][['trait']].drop_duplicates().sort_values(by='trait').reset_index(drop=True)\n",
    "snp_features = data.loc[data['rsids'].isin(snps)][['rsids', 'nearest_genes', '#chrom', 'pos', 'ref', 'alt', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']].drop_duplicates().sort_values(by='rsids').reset_index(drop=True)\n",
    "\n",
    "# Create node type labels\n",
    "node_types = torch.tensor([0] * len(phenotypes) + [1] * len(snps), dtype=torch.long)\n",
    "\n",
    "# Create positive edges between SNPs and Phenotypes (Causal Edges)\n",
    "positive_edges_snp_phenotype = data.loc[data['causal'] == 1, ['rsids', 'trait']].drop_duplicates()\n",
    "positive_edges_snp_phenotype['snp_idx'] = positive_edges_snp_phenotype['rsids'].map(snp_to_idx)\n",
    "positive_edges_snp_phenotype['phenotype_idx'] = positive_edges_snp_phenotype['trait'].map(phenotype_to_idx)\n",
    "positive_edges_snp_phenotype = positive_edges_snp_phenotype[['snp_idx', 'phenotype_idx']].values\n",
    "positive_edges_snp_phenotype = torch.tensor(positive_edges_snp_phenotype, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create negative edges between SNPs and Phenotypes (Non-Causal Edges)\n",
    "negative_edges_snp_phenotype = data.loc[data['causal'] == 0, ['rsids', 'trait']].drop_duplicates()\n",
    "negative_edges_snp_phenotype['snp_idx'] = negative_edges_snp_phenotype['rsids'].map(snp_to_idx)\n",
    "negative_edges_snp_phenotype['phenotype_idx'] = negative_edges_snp_phenotype['trait'].map(phenotype_to_idx)\n",
    "negative_edges_snp_phenotype = negative_edges_snp_phenotype[['snp_idx', 'phenotype_idx']].values\n",
    "negative_edges_snp_phenotype = torch.tensor(negative_edges_snp_phenotype, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create positive SNP-SNP edges (SNPs in LD)\n",
    "positive_edges_snp_snp = data.loc[data['LD'] == 1, ['rsids', 'lead']].drop_duplicates()\n",
    "positive_edges_snp_snp['snp_idx'] = positive_edges_snp_snp['rsids'].map(snp_to_idx)\n",
    "positive_edges_snp_snp['lead_idx'] = positive_edges_snp_snp['lead'].map(snp_to_idx)\n",
    "positive_edges_snp_snp = positive_edges_snp_snp[['snp_idx', 'lead_idx']].values\n",
    "positive_edges_snp_snp = torch.tensor(positive_edges_snp_snp, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create negative SNP-SNP edges (SNPs not in LD)\n",
    "negative_edges_snp_snp = data.loc[data['LD'] == 0, ['rsids', 'lead']].drop_duplicates()\n",
    "negative_edges_snp_snp['snp_idx'] = negative_edges_snp_snp['rsids'].map(snp_to_idx)\n",
    "negative_edges_snp_snp['lead_idx'] = negative_edges_snp_snp['lead'].map(snp_to_idx)\n",
    "negative_edges_snp_snp = negative_edges_snp_snp[['snp_idx', 'lead_idx']].values\n",
    "negative_edges_snp_snp = torch.tensor(negative_edges_snp_snp, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Combine positive and negative edges\n",
    "#edges = torch.cat([positive_edges_snp_phenotype, negative_edges_snp_phenotype, positive_edges_snp_snp, negative_edges_snp_snp], dim=1)\n",
    "\n",
    "# Create edge attributes\n",
    "#edge_attr = torch.tensor([1] * positive_edges_snp_phenotype.size(1) + [-1] * negative_edges_snp_phenotype.size(1) + [1] * positive_edges_snp_snp.size(1) + [-1] * negative_edges_snp_snp.size(1), dtype=torch.float)\n",
    "\n",
    "# Combine the feature vectors\n",
    "combined_features = pd.concat([phenotype_features, snp_features], ignore_index=True).drop(['trait', 'rsids'], axis=1)\n",
    "\n",
    "# Fill NaNs with appropriate replacements\n",
    "nan_replacements = {'nearest_genes': 'N/A', '#chrom': 'N/A', 'pos': 0, 'ref': 'N/A', 'alt': 'N/A', 'beta': 0, 'sebeta': 0, 'af_alt': 0, 'af_alt_cases': 0}\n",
    "for col, replacement in nan_replacements.items():\n",
    "    if col in combined_features:\n",
    "        if combined_features[col].dtype.name == 'category' and replacement not in combined_features[col].cat.categories:\n",
    "            combined_features[col] = combined_features[col].cat.add_categories([replacement])\n",
    "        combined_features[col].fillna(replacement, inplace=True)\n",
    "\n",
    "# Label encoding for categorical columns\n",
    "le = LabelEncoder()\n",
    "categorical_columns = ['ref', 'alt', 'nearest_genes', '#chrom']\n",
    "for column in categorical_columns:\n",
    "    combined_features[column] = le.fit_transform(combined_features[column].astype(str))\n",
    "\n",
    "# Check if problem solved\n",
    "try:\n",
    "    features = torch.tensor(combined_features.values, dtype=torch.float)\n",
    "    print(\"Successfully converted to tensor!\")\n",
    "except TypeError as e:\n",
    "    print(\"Still a problem: \", e)\n",
    "\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = ['pos', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']\n",
    "for col in numerical_columns:\n",
    "    combined_features[col] = scaler.fit_transform(combined_features[[col]])\n",
    "\n",
    "features = torch.tensor(combined_features.values, dtype=torch.float)\n",
    "\n",
    "#### Combine positive edges only\n",
    "edges = torch.cat([positive_edges_snp_phenotype, positive_edges_snp_snp], dim=1)\n",
    "edge_attr = torch.tensor([0] * positive_edges_snp_phenotype.size(1) + [0] * positive_edges_snp_snp.size(1), dtype=torch.float)\n",
    "\n",
    "# Create the PyTorch Geometric graph\n",
    "graph = Data(x=features, edge_index=edges, edge_attr=edge_attr)\n",
    "graph.node_types = node_types\n",
    "graph.y = torch.ones(positive_edges_snp_phenotype.size(1) + positive_edges_snp_snp.size(1), dtype=torch.long)\n",
    "\n",
    "\n",
    "print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "print(f\"Number of positive SNP-Phenotype edges: {positive_edges_snp_phenotype.size(1)}\")\n",
    "print(f\"Number of negative SNP-Phenotype edges: {negative_edges_snp_phenotype.size(1)}\")\n",
    "print(f\"Number of positive SNP-SNP edges: {positive_edges_snp_snp.size(1)}\")\n",
    "print(f\"Number of negative SNP-SNP edges: {negative_edges_snp_snp.size(1)}\")\n",
    "print(f\"Number of edges: {graph.num_edges}\")\n",
    "print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "print(f\"Node types: {graph.node_types}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46839e39-2318-42f1-a1fa-6bf98ac54bd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1572767c-fd84-40b9-a802-9ba3e9689cf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "def fill_na(df, fill_values):\n",
    "    return df.fillna(fill_values)\n",
    "\n",
    "def encode_columns(df, columns):\n",
    "    le = LabelEncoder()\n",
    "    return df[columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "def scale_columns(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    return df[columns].apply(lambda x: pd.Series(scaler.fit_transform(x.values.reshape(-1, 1)).flatten(), index=x.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ec3d1-1893-41cc-a68d-b4977dd8d1b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Node Data Preprocessing "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d35b0680-ae70-40e1-a573-3df6ec7575ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep copy the dataframe to avoid modifying the original data\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Convert columns into categorical data type initially to reduce redundancy\n",
    "categorical_columns = ['trait', 'rsids', 'lead']\n",
    "for col in categorical_columns:\n",
    "    data_copy[col] = data_copy[col].astype('category')\n",
    "    if 'N/A' not in data_copy[col].cat.categories:\n",
    "        data_copy[col] = data_copy[col].cat.add_categories('N/A')\n",
    "\n",
    "# Fill NaNs for 'lead' column\n",
    "data_copy['lead'] = data_copy['lead'].fillna('N/A')\n",
    "\n",
    "# Mapping traits and rsids to integers\n",
    "data_copy['trait_codes'] = data_copy['trait'].cat.codes\n",
    "data_copy['rsids_codes'] = data_copy['rsids'].cat.codes \n",
    "\n",
    "# Get unique traits and rsids\n",
    "unique_traits = data_copy['trait'].unique()\n",
    "unique_rsids = data_copy['rsids'].unique()\n",
    "\n",
    "assert len(unique_traits) == data_copy['trait'].nunique(), \"Mismatch in the number of unique traits\"\n",
    "assert len(unique_rsids) == data_copy['rsids'].nunique(), \"Mismatch in the number of unique rsids\"\n",
    "\n",
    "# Define node features and types\n",
    "node_features_columns = ['trait', 'rsids', 'nearest_genes', '#chrom', 'pos', 'ref', 'alt', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']\n",
    "node_features = data_copy[node_features_columns]\n",
    "\n",
    "# Keep the rows where either trait or rsid is unique\n",
    "node_features = node_features[node_features['trait'].isin(unique_traits) | node_features['rsids'].isin(unique_rsids)]\n",
    "\n",
    "# Create a new row with only 'trait' value and NaNs for all other cols\n",
    "new_row = pd.DataFrame([['trait'] + [np.nan] * (node_features.shape[1] - 1)], columns=node_features.columns)\n",
    "node_features = pd.concat([node_features, new_row], ignore_index=True)\n",
    "\n",
    "print(\"Node feature shape\", node_features.shape[0])\n",
    "print(\"Number of unique traits:\", len(unique_traits))\n",
    "print(\"Number of unique rsids:\", len(unique_rsids))\n",
    "\n",
    "# The node_features should not double the sum of unique traits and rsids\n",
    "assert node_features.shape[0] == len(unique_traits) + len(unique_rsids), \"Mismatch in the number of nodes and unique traits/rsids\"\n",
    "\n",
    "# Define node types separately for traits and unique rsids values\n",
    "trait_nodes = len(unique_traits)\n",
    "rsids_nodes = len(unique_rsids)\n",
    "total_nodes = trait_nodes + rsids_nodes\n",
    "node_types = torch.tensor([0] * trait_nodes + [1] * rsids_nodes, dtype=torch.long)\n",
    "\n",
    "print(\"Total number of nodes:\", total_nodes)\n",
    "print(\"Number of node types:\", len(node_types))\n",
    "\n",
    "assert len(node_types) == total_nodes, \"Mismatch in the number of nodes and node types\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d489a3-d3d3-4ed4-8c2b-59c86f165f6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Edge Data Processing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b71e619-0319-446a-9b08-93ebaea8c008",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing edge data\n",
    "data_copy['lead'] = data_copy['lead'].fillna('N/A')  # Fill NaNs for 'lead' column\n",
    "data_copy['lead_codes'] = data_copy['lead'].cat.codes  # Now you can do the mapping\n",
    "\n",
    "edge_columns = ['rsids_codes', 'trait_codes', 'lead_codes', 'causal', 'LD']\n",
    "edges = data_copy[edge_columns]\n",
    "\n",
    "# Create edges based on 'causal' and 'LD' conditions\n",
    "positive_edges_snp_phenotype = edges[edges['causal'] == 1][['rsids_codes', 'trait_codes']].values.T\n",
    "negative_edges_snp_phenotype = edges[edges['causal'] == 0][['rsids_codes', 'trait_codes']].values.T\n",
    "positive_edges_snp_snp = edges[edges['LD'] == 1][['rsids_codes', 'lead_codes']].values.T\n",
    "negative_edges_snp_snp = edges[edges['LD'] == 0][['rsids_codes', 'lead_codes']].values.T\n",
    "\n",
    "# Combine all edges and their labels\n",
    "edges = np.concatenate([positive_edges_snp_phenotype, negative_edges_snp_phenotype, positive_edges_snp_snp, negative_edges_snp_snp], axis=1)\n",
    "edge_labels = np.concatenate([\n",
    "    np.full(positive_edges_snp_phenotype.shape[1], +1), # Label +1 for causal relationships in SNP-Phenotype edges\n",
    "    np.full(negative_edges_snp_phenotype.shape[1], -1), # Label -1 for non-causal relationships in SNP-Phenotype edges\n",
    "    np.full(positive_edges_snp_snp.shape[1], +1),       # Label +1 for linkage disequilibrium in SNP-SNP edges\n",
    "    np.full(negative_edges_snp_snp.shape[1], -1)        # Label -1 for non-linkage disequilibrium in SNP-SNP edges\n",
    "])\n",
    "\n",
    "edges = torch.from_numpy(edges)\n",
    "edge_labels = torch.from_numpy(edge_labels)\n",
    "\n",
    "# Print relevant information\n",
    "print(\"Positive SNP-Phenotype edges:\", positive_edges_snp_phenotype.shape[1])\n",
    "print(\"Negative SNP-Phenotype edges:\", negative_edges_snp_phenotype.shape[1])\n",
    "print(\"Positive SNP-SNP edges:\", positive_edges_snp_snp.shape[1])\n",
    "print(\"Negative SNP-SNP edges:\", negative_edges_snp_snp.shape[1])\n",
    "print(\"Final edges tensor:\", edges.size())\n",
    "print(\"Edge labels tensor:\", edge_labels.size())\n",
    "\n",
    "# Assertions\n",
    "assert edges.shape[0] == 2, \"Edges tensor should have shape (2, num_edges)\"\n",
    "assert edge_labels.ndim == 1, \"Edge labels tensor should be 1-dimensional\"\n",
    "assert edges.shape[1] == edge_labels.shape[0], \"Edges and edge_labels should have the same number of columns\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341537f-dc0c-4465-9ad3-79e5889fb972",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Edge Attributes and Node Feature Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e68652f-4367-40dd-97f1-0354dd7a4bc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to encode and scale columns\n",
    "def process_columns(df, encode_cols, scale_cols):\n",
    "    # Encode columns\n",
    "    for col in encode_cols:\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "    # Scale columns\n",
    "    scaler = StandardScaler()\n",
    "    for col in scale_cols:\n",
    "        df[col] = scaler.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    return df\n",
    "\n",
    "# Preprocessing node features\n",
    "fill_values = {'nearest_genes': 'N/A', '#chrom': 'N/A', 'pos': 0, 'ref': 'N/A', 'alt': 'N/A', 'beta': 0, 'sebeta': 0, 'af_alt': 0, 'af_alt_cases': 0}\n",
    "node_features = fill_na(node_features, fill_values)\n",
    "\n",
    "# Define columns to be encoded and scaled\n",
    "categorical_columns = ['trait', 'rsids', 'nearest_genes', '#chrom', 'ref', 'alt']\n",
    "numerical_columns = ['pos', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']\n",
    "\n",
    "# Process node features\n",
    "node_features = process_columns(node_features, categorical_columns, numerical_columns)\n",
    "\n",
    "# Convert to tensor\n",
    "node_features = torch.tensor(node_features.values, dtype=torch.float)\n",
    "\n",
    "# Compute edge attributes\n",
    "edge_attr = torch.tensor([0] * positive_edges_snp_phenotype.shape[1] + [0] * negative_edges_snp_phenotype.shape[1] + [1] * positive_edges_snp_snp.shape[1] + [1] * negative_edges_snp_snp.shape[1], dtype=torch.float)\n",
    "\n",
    "# Assertions\n",
    "assert node_features.ndim == 2, \"Node features tensor should have 2 dimensions\"\n",
    "assert edge_attr.ndim == 1, \"Edge attribute tensor should be 1-dimensional\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8bbff-cba1-47c0-8ea2-f13c0d03250e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Construct Graph Data Object"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55788dd6-84e2-43ef-9c84-64105f8a01a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert node features to tensor\n",
    "if isinstance(node_features, pd.DataFrame):\n",
    "    node_features_tensor = torch.tensor(node_features.values(), dtype=torch.float)\n",
    "else:\n",
    "    node_features_tensor = node_features\n",
    "\n",
    "# Create the PyTorch Geometric data object\n",
    "graph = Data(x=node_features_tensor, edge_index=edges, edge_attr=edge_attr)\n",
    "\n",
    "# Truncate the node_types tensor to match the adjusted number of nodes\n",
    "graph.node_types = node_types\n",
    "\n",
    "# Assertions\n",
    "assert graph.x.ndim == 2, \"Node features tensor should have 2 dimensions\"\n",
    "assert graph.edge_index.ndim == 2, \"Edge index tensor should have 2 dimensions\"\n",
    "assert graph.edge_attr.ndim == 1, \"Edge attribute tensor should be 1-dimensional\"\n",
    "assert graph.num_nodes == total_nodes, \"Number of nodes in the graph should match the total number of nodes\"\n",
    "assert graph.num_node_features == node_features_tensor.shape[1], \"Number of node features in the graph should match the number of columns in node_features\"\n",
    "assert graph.edge_index.size(1) == edges.shape[1], \"Number of edges in the graph should match the number of columns in edges\"\n",
    "assert graph.edge_attr.size(0) == graph.edge_index.size(1), \"Number of edge attributes should match the number of edges\"\n",
    "\n",
    "print(graph)\n",
    "print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "print(f\"Number of positive edges between SNPs and SNPs: {positive_edges_snp_snp.shape[1]}\")\n",
    "print(f\"Number of positive edges between SNPs and phenotypes: {positive_edges_snp_phenotype.shape[1]}\")\n",
    "print(f\"Number of negative edges for SNPs and SNPs: {negative_edges_snp_snp.shape[1]}\")\n",
    "print(f\"Number of negative edges for SNPs and phenotypes: {negative_edges_snp_phenotype.shape[1]}\")\n",
    "print(f\"Number of edges: {graph.num_edges}\")\n",
    "print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "print(f\"Node types: {graph.node_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60cae52-2493-43ae-9e27-e7dc67c3a7f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0709aa36-0d8a-45de-b5c5-1b287fad15ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph stats:\n",
      "Number of nodes: 18295393\n",
      "Number of 0 nodes: 1\n",
      "Number of 1 nodes: 18295392\n",
      "Number of positive edges between SNPs and phenotypes: 37\n",
      "Number of negative edges between SNPs and phenotypes: 18295355\n",
      "Number of positive edges between SNPs: 3787\n",
      "Number of negative edges between SNPs: 18291605\n",
      "Number of edges: 3824\n",
      "Node feature dimension: 9\n",
      "\n",
      "0 node stats:\n",
      "Average degree: 0.00\n",
      "Median degree: 0.00\n",
      "Standard deviation of degree: nan\n",
      "\n",
      "1 node stats:\n",
      "Average degree: 0.00\n",
      "Median degree: 0.00\n",
      "Standard deviation of degree: 0.01\n",
      "Density: 0.0000000000\n",
      "Are there any NaN values in features? False\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree\n",
    "\n",
    "def print_graph_stats(graph, positive_edges_snp_phenotype, negative_edges_snp_phenotype, positive_edges_snp_snp, negative_edges_snp_snp):\n",
    "    node_types = np.unique(graph.node_types.numpy(), return_counts=True)\n",
    "\n",
    "    print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "    for node_type, count in zip(*node_types):\n",
    "        print(f\"Number of {node_type} nodes: {count}\")\n",
    "    print(f\"Number of positive edges between SNPs and phenotypes: {positive_edges_snp_phenotype.shape[1]}\")\n",
    "    print(f\"Number of negative edges between SNPs and phenotypes: {negative_edges_snp_phenotype.shape[1]}\")\n",
    "    print(f\"Number of positive edges between SNPs: {positive_edges_snp_snp.shape[1]}\")\n",
    "    print(f\"Number of negative edges between SNPs: {negative_edges_snp_snp.shape[1]}\")\n",
    "    print(f\"Number of edges: {graph.num_edges}\")\n",
    "    print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "\n",
    "    # Compute and print degree-related stats for each node type\n",
    "    for node_type in node_types[0]:\n",
    "        node_indices = np.where(graph.node_types.numpy() == node_type)[0]\n",
    "        degrees = degree(graph.edge_index[0].long(), num_nodes=graph.num_nodes)[node_indices]\n",
    "        average_degree = degrees.float().mean().item()\n",
    "        median_degree = np.median(degrees.numpy())\n",
    "        std_degree = degrees.float().std().item()\n",
    "\n",
    "        print(f\"\\n{node_type} node stats:\")\n",
    "        print(f\"Average degree: {average_degree:.2f}\")\n",
    "        print(f\"Median degree: {median_degree:.2f}\")\n",
    "        print(f\"Standard deviation of degree: {std_degree:.2f}\")\n",
    "\n",
    "    # Density is the ratio of actual edges to the maximum number of possible edges\n",
    "    num_possible_edges = graph.num_nodes * (graph.num_nodes - 1) / 2\n",
    "    density = graph.num_edges / num_possible_edges\n",
    "    print(f\"Density: {density:.10f}\")\n",
    "\n",
    "    # Check for NaN values in features\n",
    "    nan_in_features = torch.isnan(graph.x).any().item()\n",
    "    print(f\"Are there any NaN values in features? {nan_in_features}\")\n",
    "\n",
    "# Print\n",
    "print(\"Graph stats:\")\n",
    "print_graph_stats(graph, positive_edges_snp_phenotype, negative_edges_snp_phenotype, positive_edges_snp_snp, negative_edges_snp_snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51e96d-660c-4b4f-8ac4-9a07dba5bcc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34e19b40-09e4-42cb-907e-3829c51066f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[18295393, 9], edge_index=[2, 3824], edge_attr=[3824], y=[3824], node_types=[18295393])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a5650ea-db41-4f17-8599-86b148482867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Insufficient number of edges for training",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomLinkSplit\n\u001b[0;32m      3\u001b[0m transform \u001b[38;5;241m=\u001b[39m RandomLinkSplit(num_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, num_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, is_undirected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m graph_train, graph_val, graph_test \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(graph_train)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(graph_val)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\transforms\\random_link_split.py:177\u001b[0m, in \u001b[0;36mRandomLinkSplit.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    174\u001b[0m num_train \u001b[38;5;241m=\u001b[39m perm\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m-\u001b[39m num_val \u001b[38;5;241m-\u001b[39m num_test\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_train \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient number of edges for training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    179\u001b[0m train_edges \u001b[38;5;241m=\u001b[39m perm[:num_train]\n\u001b[0;32m    180\u001b[0m val_edges \u001b[38;5;241m=\u001b[39m perm[num_train:num_train \u001b[38;5;241m+\u001b[39m num_val]\n",
      "\u001b[1;31mValueError\u001b[0m: Insufficient number of edges for training"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "transform = RandomLinkSplit(num_val=0.1, num_test=0.1, key=\"y\", is_undirected=True)\n",
    "\n",
    "graph_train, graph_val, graph_test = transform(graph)\n",
    "\n",
    "print(graph_train)\n",
    "print(graph_val)\n",
    "print(graph_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51df928f-ec8c-42f6-9bf9-f9e0b599af33",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the proportion of data to be used for validation and test\n",
    "val_prop = 0.3  # validation set proportion\n",
    "test_prop = 0.3  # test set proportion\n",
    "\n",
    "# Define the seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# Function to split edges\n",
    "def split_edges(edges, val_prop, test_prop, seed):\n",
    "    # Split into training and test+val sets\n",
    "    edges_train, edges_test_val = train_test_split(edges.T, test_size=val_prop+test_prop, random_state=seed, stratify=edges[1])\n",
    "    \n",
    "    # Further split test+val set into separate test and validation sets\n",
    "    edges_val, edges_test = train_test_split(edges_test_val, test_size=test_prop/(val_prop+test_prop), random_state=seed, stratify=edges_test_val[:, 1])\n",
    "    \n",
    "    return edges_train.T, edges_val.T, edges_test.T\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object\n",
    "def create_data_object(x, edge_index, pos_edge_index, neg_edge_index, edge_attr):\n",
    "    return Data(x=x, edge_index=edge_index, pos_edge_index=pos_edge_index, neg_edge_index=neg_edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Split SNP-Phenotype edges\n",
    "positive_edges_snp_phenotype_train, positive_edges_snp_phenotype_val, positive_edges_snp_phenotype_test = split_edges(positive_edges_snp_phenotype, val_prop, test_prop, seed)\n",
    "negative_edges_snp_phenotype_train, negative_edges_snp_phenotype_val, negative_edges_snp_phenotype_test = split_edges(negative_edges_snp_phenotype, val_prop, test_prop, seed)\n",
    "\n",
    "# Split SNP-SNP edges\n",
    "positive_edges_snp_snp_train, positive_edges_snp_snp_val, positive_edges_snp_snp_test = split_edges(positive_edges_snp_snp, val_prop, test_prop, seed)\n",
    "negative_edges_snp_snp_train, negative_edges_snp_snp_val, negative_edges_snp_snp_test = split_edges(negative_edges_snp_snp, val_prop, test_prop, seed)\n",
    "\n",
    "\n",
    "# Prepare the training data\n",
    "train_edges = torch.cat([positive_edges_snp_phenotype_train, negative_edges_snp_phenotype_train, positive_edges_snp_snp_train, negative_edges_snp_snp_train], dim=1)\n",
    "train_edge_attr = torch.tensor([1]*positive_edges_snp_phenotype_train.size(1) + [-1]*negative_edges_snp_phenotype_train.size(1) + [1]*positive_edges_snp_snp_train.size(1) + [-1]*negative_edges_snp_snp_train.size(1), dtype=torch.float)\n",
    "graph_train = create_data_object(features, train_edges, positive_edges_snp_phenotype_train, negative_edges_snp_phenotype_train, train_edge_attr)\n",
    "\n",
    "# Prepare the validation data\n",
    "val_edges = torch.cat([positive_edges_snp_phenotype_val, negative_edges_snp_phenotype_val, positive_edges_snp_snp_val, negative_edges_snp_snp_val], dim=1)\n",
    "val_edge_attr = torch.tensor([1]*positive_edges_snp_phenotype_val.size(1) + [-1]*negative_edges_snp_phenotype_val.size(1) + [1]*positive_edges_snp_snp_val.size(1) + [-1]*negative_edges_snp_snp_val.size(1), dtype=torch.float)\n",
    "graph_val = create_data_object(features, val_edges, positive_edges_snp_phenotype_val, negative_edges_snp_phenotype_val, val_edge_attr)\n",
    "\n",
    "# Prepare the test data\n",
    "test_edges = torch.cat([positive_edges_snp_phenotype_test, negative_edges_snp_phenotype_test, positive_edges_snp_snp_test, negative_edges_snp_snp_test], dim=1)\n",
    "test_edge_attr = torch.tensor([1]*positive_edges_snp_phenotype_test.size(1) + [-1]*negative_edges_snp_phenotype_test.size(1) + [1]*positive_edges_snp_snp_test.size(1) + [-1]*negative_edges_snp_snp_test.size(1), dtype=torch.float)\n",
    "graph_test = create_data_object(features, test_edges, positive_edges_snp_phenotype_test, negative_edges_snp_phenotype_test, test_edge_attr)\n",
    "\n",
    "print(graph_train)\n",
    "print(graph_val)\n",
    "print(graph_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665050a-5cd9-4960-a2ef-8a4cf2cb5e40",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2557f-d84e-4a1b-bda8-7b26620f526b",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ae175ab-f1da-4ac9-bd1c-f180eb8e2313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index -9223372036854775808 is out of bounds for dimension 0 with size 18295393",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m     53\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m---> 55\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation and test sets\u001b[39;00m\n\u001b[0;32m     58\u001b[0m evaluate(model, graph_val)\n",
      "Cell \u001b[1;32mIn[26], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out[data\u001b[38;5;241m.\u001b[39mpos_edge_index], out[data\u001b[38;5;241m.\u001b[39mneg_edge_index])\n\u001b[0;32m     27\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[26], line 15\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[1;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:210\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    208\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:100\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m     98\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     99\u001b[0m idx \u001b[38;5;241m=\u001b[39m col \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[1;32m--> 100\u001b[0m deg \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    102\u001b[0m deg_inv_sqrt\u001b[38;5;241m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\utils\\scatter.py:74\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     73\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     77\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: index -9223372036854775808 is out of bounds for dimension 0 with size 18295393"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Define the training loop\n",
    "def train(model, data, optimizer, criterion, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.pos_edge_index], out[data.neg_edge_index])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        y_pred[y_pred >= 0.5] = 1\n",
    "        y_pred[y_pred < 0.5] = -1\n",
    "        correct = (y_pred == data.edge_attr).sum().item()\n",
    "        total = data.edge_attr.size(0)\n",
    "        accuracy = correct / total\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Initialize and train the GCN model\n",
    "num_features = graph_train.x.size(1)\n",
    "hidden_size = 64\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "model = GCN(num_features, hidden_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train(model, graph_train, optimizer, criterion, num_epochs)\n",
    "\n",
    "# Evaluate the model on the validation and test sets\n",
    "evaluate(model, graph_val)\n",
    "evaluate(model, graph_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5b599-cfa8-40eb-9a9e-ff5ab40e1745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
