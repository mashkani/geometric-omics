{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00910a35-ffbc-4497-bcc8-21f008c326fb",
   "metadata": {},
   "source": [
    "# Grapher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd8be8-14cc-4d80-a944-76c5235c078b",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99bc773-edf8-4567-8767-a742662cb8ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [FinnGen](https://finngen.gitbook.io/documentation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef1038-e49a-4607-9c7d-5ce6daf1d94b",
   "metadata": {},
   "source": [
    "Any large Canadian GWAS-related clinical trials?\n",
    "\n",
    "- The FinnGen research project is an expedition to the frontier of genomics and medicine, with significant discoveries potentially arising from any one of Finland’s 500,000 biomedical pioneers.\n",
    "- The project brings together a nation-wide network of Finnish biobanks, with every Finn able to participate in the study by giving biobank consent.\n",
    "- As of the last update, there were 589,000 samples available, with a goal to reach 520,000 by 2023. The latest data freeze included combined genotype and health registry data from 473,681 individuals.\n",
    "- The study utilizes samples collected by a nationwide network of Finnish biobanks and combines genome information with digital health care data from national health registries【8†source】.\n",
    "- There's a need for samples from all over Finland as solutions in the field of personalized healthcare can be found only by looking at large populations. Every Finn can be a part of the FinnGen study by giving a biobank consent.\n",
    "- The genome data produced during the project is owned by the Finnish biobanks and remains available for research purposes. The medical breakthroughs that arise from the project are expected to benefit health care systems and patients globally.\n",
    "- The FinnGen research project is collaborative, involving all the same actors as drug development, with the aim to speed up the emergence of new innovations.\n",
    "- The project's data freeze 9 results and summary statistics are now available, consisting of over 377,200 individuals, almost 20.2 M variants, and 2,272 disease endpoints. Results can be browsed online using the FinnGen web browser, and the summary statistics downloaded.\n",
    "- The University of Helsinki is the organization responsible for the study, and the nationwide network of Finnish biobanks is participating in the study, thus covering the whole of Finland. The Helsinki Biobank coordinates the sample collection.\n",
    "- For more information, the project can be contacted at finngen-info@helsinki.fi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1805a-55dc-409c-9ccf-512eb1f88667",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8ec1d-73be-4b8c-95dc-79489e84998b",
   "metadata": {},
   "source": [
    "Here's the summary documentation for the DataFrame in bullet format:\n",
    "\n",
    "- `#chrom`: This column represents the chromosome number where the genetic variant is located.\n",
    "\n",
    "- `pos`: This is the position of the genetic variant on the chromosome.\n",
    "\n",
    "- `ref`: This column represents the reference allele (or variant) at the genomic position.\n",
    "\n",
    "- `alt`: This is the alternate allele observed at this position.\n",
    "\n",
    "- `rsids`: This stands for reference SNP cluster ID. It's a unique identifier for each variant used in the dbSNP database.\n",
    "\n",
    "- `nearest_genes`: This column represents the gene which is nearest to the variant.\n",
    "\n",
    "- `pval`: This represents the p-value, which is a statistical measure for the strength of evidence against the null hypothesis.\n",
    "\n",
    "- `mlogp`: This represents the minus log of the p-value, commonly used in genomic studies.\n",
    "\n",
    "- `beta`: The beta coefficient represents the effect size of the variant.\n",
    "\n",
    "- `sebeta`: This is the standard error of the beta coefficient.\n",
    "\n",
    "- `af_alt`: This is the allele frequency of the alternate variant in the general population.\n",
    "\n",
    "- `af_alt_cases`: This is the allele frequency of the alternate variant in the cases group.\n",
    "\n",
    "- `af_alt_controls`: This is the allele frequency of the alternate variant in the control group.\n",
    "\n",
    "- `causal`: This binary column indicates whether the variant is determined to be causal (1) or not (0).\n",
    "\n",
    "- `trait`: This column represents the trait associated with the variant. In this dataset, it is the response to the drug paracetamol and NSAIDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b033d-95f5-4584-b10c-72969a166612",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4345459-b1ef-477c-8f06-c8f54c194af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "\n",
    "import networkx as nx\n",
    "from ogb.io import DatasetSaver\n",
    "from ogb.linkproppred import LinkPropPredDataset\n",
    "\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f7ab7-4bf0-4dba-9428-9580338d9aa7",
   "metadata": {},
   "source": [
    "## Perform checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b729b64d-2166-4dbb-9c4c-4173e0c9e807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu118\n",
      "PyTorch Geometric version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f213c8b-5dc0-468b-b7d0-72c08a6e5282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce RTX 3060 Ti (cuda)\n",
      "CUDA version: 11.8\n",
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a754a-7836-439e-801c-7efca6d2dfc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data and create new rows for each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05fe5b06-7392-4d62-a1e8-af081cdf3e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes={\n",
    "    '#chrom': 'int64',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'causal':'int64',\n",
    "    'LD': 'int64',\n",
    "    'lead': 'string',\n",
    "    'trait': 'string'\n",
    "}\n",
    "data = pd.read_csv('~/Desktop/gwas-graph/FinnGen/data/gwas-causal.csv', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b729972-b0d7-4e38-b8e2-aedd07506c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['nearest_genes'] = data['nearest_genes'].astype(str)\n",
    "\n",
    "# Assuming your DataFrame is called data and the relevant column is 'nearest_genes'\n",
    "# First, let's split the gene names in the 'nearest_genes' column\n",
    "split_genes = data['nearest_genes'].str.split(',')\n",
    "\n",
    "# Flatten the list of split gene names\n",
    "flat_genes = [item for sublist in split_genes for item in sublist]\n",
    "\n",
    "# Then, we create a new DataFrame by repeating rows and substituting the gene names\n",
    "data_new = (data.loc[data.index.repeat(split_genes.str.len())]\n",
    "            .assign(nearest_genes=flat_genes))\n",
    "\n",
    "# Reset index to have a standard index\n",
    "data = data_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "513cafa0-f3f8-47b5-9d22-96062449edde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>rsids</th>\n",
       "      <th>nearest_genes</th>\n",
       "      <th>pval</th>\n",
       "      <th>mlogp</th>\n",
       "      <th>beta</th>\n",
       "      <th>sebeta</th>\n",
       "      <th>af_alt</th>\n",
       "      <th>af_alt_cases</th>\n",
       "      <th>af_alt_controls</th>\n",
       "      <th>causal</th>\n",
       "      <th>LD</th>\n",
       "      <th>lead</th>\n",
       "      <th>trait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13668</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>rs2691328</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.024860</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>0.084918</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14773</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>rs878915777</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.844305</td>\n",
       "      <td>0.073501</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>0.013485</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15585</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>rs533630043</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.841908</td>\n",
       "      <td>0.074735</td>\n",
       "      <td>0.031464</td>\n",
       "      <td>0.157751</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16549</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>rs1262014613</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.343308</td>\n",
       "      <td>0.464316</td>\n",
       "      <td>0.241377</td>\n",
       "      <td>0.254711</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16567</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>rs1194064194</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.130736</td>\n",
       "      <td>0.086319</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565622</th>\n",
       "      <td>23</td>\n",
       "      <td>155697920</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.027115</td>\n",
       "      <td>1.566790</td>\n",
       "      <td>-0.013475</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.290961</td>\n",
       "      <td>0.286054</td>\n",
       "      <td>0.291879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565623</th>\n",
       "      <td>23</td>\n",
       "      <td>155698443</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.178417</td>\n",
       "      <td>0.748564</td>\n",
       "      <td>-0.069907</td>\n",
       "      <td>0.051951</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565624</th>\n",
       "      <td>23</td>\n",
       "      <td>155698490</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.279640</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>-0.020245</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>0.024312</td>\n",
       "      <td>0.024423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565625</th>\n",
       "      <td>23</td>\n",
       "      <td>155699751</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.078864</td>\n",
       "      <td>1.103120</td>\n",
       "      <td>-0.011284</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.244829</td>\n",
       "      <td>0.241257</td>\n",
       "      <td>0.245498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565626</th>\n",
       "      <td>23</td>\n",
       "      <td>155700291</td>\n",
       "      <td>CAA</td>\n",
       "      <td>C</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.071590</td>\n",
       "      <td>1.145150</td>\n",
       "      <td>-0.011563</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.245328</td>\n",
       "      <td>0.241724</td>\n",
       "      <td>0.246003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20565627 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          #chrom        pos  ref alt         rsids nearest_genes      pval   \n",
       "0              1      13668    G   A     rs2691328         OR4F5  0.944365  \\\n",
       "1              1      14773    C   T   rs878915777         OR4F5  0.844305   \n",
       "2              1      15585    G   A   rs533630043         OR4F5  0.841908   \n",
       "3              1      16549    T   C  rs1262014613         OR4F5  0.343308   \n",
       "4              1      16567    G   C  rs1194064194         OR4F5  0.129883   \n",
       "...          ...        ...  ...  ..           ...           ...       ...   \n",
       "20565622      23  155697920    G   A          <NA>          <NA>  0.027115   \n",
       "20565623      23  155698443    C   A          <NA>          <NA>  0.178417   \n",
       "20565624      23  155698490    C   T          <NA>          <NA>  0.279640   \n",
       "20565625      23  155699751    C   T          <NA>          <NA>  0.078864   \n",
       "20565626      23  155700291  CAA   C          <NA>          <NA>  0.071590   \n",
       "\n",
       "             mlogp      beta    sebeta    af_alt  af_alt_cases   \n",
       "0         0.024860 -0.005926  0.084918  0.005842      0.005729  \\\n",
       "1         0.073501  0.010088  0.051369  0.013495      0.013547   \n",
       "2         0.074735  0.031464  0.157751  0.001113      0.001125   \n",
       "3         0.464316  0.241377  0.254711  0.000561      0.000620   \n",
       "4         0.886447  0.130736  0.086319  0.004170      0.004250   \n",
       "...            ...       ...       ...       ...           ...   \n",
       "20565622  1.566790 -0.013475  0.006097  0.290961      0.286054   \n",
       "20565623  0.748564 -0.069907  0.051951  0.003259      0.003022   \n",
       "20565624  0.553400 -0.020245  0.018725  0.024406      0.024312   \n",
       "20565625  1.103120 -0.011284  0.006421  0.244829      0.241257   \n",
       "20565626  1.145150 -0.011563  0.006418  0.245328      0.241724   \n",
       "\n",
       "          af_alt_controls  causal  LD  lead trait  \n",
       "0                0.005863       0   0  <NA>   T2D  \n",
       "1                0.013485       0   0  <NA>   T2D  \n",
       "2                0.001110       0   0  <NA>   T2D  \n",
       "3                0.000550       0   0  <NA>   T2D  \n",
       "4                0.004154       0   0  <NA>   T2D  \n",
       "...                   ...     ...  ..   ...   ...  \n",
       "20565622         0.291879       0   0  <NA>   T2D  \n",
       "20565623         0.003304       0   0  <NA>   T2D  \n",
       "20565624         0.024423       0   0  <NA>   T2D  \n",
       "20565625         0.245498       0   0  <NA>   T2D  \n",
       "20565626         0.246003       0   0  <NA>   T2D  \n",
       "\n",
       "[20565627 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e14ab37-9bcf-458b-882d-94604efbc5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in 'rsids' column\n",
    "data.dropna(subset=['rsids'], inplace=True)\n",
    "\n",
    "# Keep only rows with unique values in 'rsids' column\n",
    "data = data[data.duplicated(subset='rsids', keep=False) == False]\n",
    "\n",
    "# Adjust the index if necessary\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e5455c6-766b-4e26-85ae-360763a8ad55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in rsids column: 1\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique values in rsids col\n",
    "num_unique_rsids = data['trait'].nunique()\n",
    "print(\"Number of unique values in rsids column:\", num_unique_rsids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98204592-1cf4-4692-9158-a61e5dcfcdfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T2D\n"
     ]
    }
   ],
   "source": [
    "# Get unique elements of the 'trait' column\n",
    "unique_traits = data['trait'].unique()\n",
    "\n",
    "# Print the unique elements\n",
    "for trait in unique_traits:\n",
    "    print(trait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fecab70-8442-4b17-89ad-bfb21b086a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where data['rsids'] is <NA>:  0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows where data['lead'] is <NA>\n",
    "na_count = data['trait'].isna().sum()\n",
    "\n",
    "print(\"Number of rows where data['rsids'] is <NA>: \", na_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011a6c79-4026-4e07-a032-0042f21e9a21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18295392"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eddaed-2f48-4440-b6d6-0dc247f23ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe89142-2b65-469b-b330-1620d303312b",
   "metadata": {},
   "source": [
    "**Task Overview**\n",
    "- The objective is to design and implement a multi-class link prediction model for analyzing relationships between SNP nodes and Phenotype nodes.\n",
    "\n",
    "**Nodes and Their Features**\n",
    "- There are two types of nodes: SNP Nodes and Phenotype Nodes.\n",
    "- *Phenotype Nodes*: Each Phenotype Node represents a particular trait. This information comes from the `trait` column in the data.\n",
    "- *SNP Nodes*: Each SNP Node is characterized by various features, including `rsids`, `nearest_genes`, `#chrom`, `pos`, `ref`, `alt`, `beta`, `sebeta`, `af_alt`, and `af_alt_cases` columns.\n",
    "\n",
    "**Edges, Their Features, and Labels**\n",
    "- Edges represent relationships between nodes. There are two types of edges: SNP-Phenotype and SNP-SNP.\n",
    "- *SNP-Phenotype Edges*:\n",
    "  - These edges are undirected, linking SNP Nodes and Phenotype Nodes.\n",
    "  - The label for each edge is determined by the `causal` column in the data:\n",
    "    - A label of 0 is assigned when `data['causal']` is 1, indicating a causal relationship.\n",
    "    - A label of 1 is assigned when `data['causal']` is 0, indicating the absence of a causal relationship.\n",
    "- *SNP-SNP Edges*:\n",
    "  - These edges are undirected, linking an SNP Node (as identified by the `rsids` column) to another SNP Node (as identified by the `lead` column) in the same data row.\n",
    "  - The label for each edge is determined by the `LD` column in the data:\n",
    "    - A label of 2 is assigned when `data['LD']` is 1, signifying that the two SNPs are in linkage disequilibrium.\n",
    "    - A label of 3 is assigned when `data['LD']` is 0, indicating that the two SNPs are not in linkage disequilibrium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abe533-6610-4f82-b8d6-533eb010858d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46839e39-2318-42f1-a1fa-6bf98ac54bd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6aecc2f-1860-443b-9993-dfb1e15c586f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_na(df, fill_values):\n",
    "    return df.fillna(fill_values)\n",
    "\n",
    "def encode_columns(df, columns):\n",
    "    le = LabelEncoder()\n",
    "    return df[columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "def scale_columns(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    return df[columns].apply(lambda x: pd.Series(scaler.fit_transform(x.values.reshape(-1, 1)).flatten(), index=x.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ec3d1-1893-41cc-a68d-b4977dd8d1b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Node Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa652358-a478-4f86-a0f0-ee40d716eca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature shape 18295393\n",
      "Number of unique traits: 1\n",
      "Number of unique rsids: 18295392\n",
      "Total number of nodes: 18295393\n",
      "Number of node types: 18295393\n"
     ]
    }
   ],
   "source": [
    "# Deep copy the dataframe to avoid modifying the original data\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Convert columns into categorical data type initially to reduce redundancy\n",
    "categorical_columns = ['trait', 'rsids', 'lead']\n",
    "for col in categorical_columns:\n",
    "    data_copy[col] = data_copy[col].astype('category')\n",
    "    if 'N/A' not in data_copy[col].cat.categories:\n",
    "        data_copy[col] = data_copy[col].cat.add_categories('N/A')\n",
    "\n",
    "# Fill NaNs for 'lead' column\n",
    "data_copy['lead'] = data_copy['lead'].fillna('N/A')\n",
    "\n",
    "# Mapping traits and rsids to integers\n",
    "data_copy['trait_codes'] = data_copy['trait'].cat.codes\n",
    "data_copy['rsids_codes'] = data_copy['rsids'].cat.codes \n",
    "\n",
    "# Get unique traits and rsids\n",
    "unique_traits = data_copy['trait'].unique()\n",
    "unique_rsids = data_copy['rsids'].unique()\n",
    "\n",
    "assert len(unique_traits) == data_copy['trait'].nunique(), \"Mismatch in the number of unique traits\"\n",
    "assert len(unique_rsids) == data_copy['rsids'].nunique(), \"Mismatch in the number of unique rsids\"\n",
    "\n",
    "# Define node features and types\n",
    "node_features_columns = ['trait', 'rsids', 'nearest_genes', '#chrom', 'pos', 'ref', 'alt', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']\n",
    "node_features = data_copy[node_features_columns]\n",
    "\n",
    "# Keep the rows where either trait or rsid is unique\n",
    "node_features = node_features[node_features['trait'].isin(unique_traits) | node_features['rsids'].isin(unique_rsids)]\n",
    "\n",
    "# Create a new row with only 'trait' value and NaNs for all other cols\n",
    "new_row = pd.DataFrame([['trait'] + [np.nan] * (node_features.shape[1] - 1)], columns=node_features.columns)\n",
    "node_features = pd.concat([node_features, new_row], ignore_index=True)\n",
    "\n",
    "print(\"Node feature shape\", node_features.shape[0])\n",
    "print(\"Number of unique traits:\", len(unique_traits))\n",
    "print(\"Number of unique rsids:\", len(unique_rsids))\n",
    "\n",
    "# The node_features should not double the sum of unique traits and rsids\n",
    "assert node_features.shape[0] == len(unique_traits) + len(unique_rsids), \"Mismatch in the number of nodes and unique traits/rsids\"\n",
    "\n",
    "# Define node types separately for traits and unique rsids values\n",
    "trait_nodes = len(unique_traits)\n",
    "rsids_nodes = len(unique_rsids)\n",
    "total_nodes = trait_nodes + rsids_nodes\n",
    "node_types = torch.tensor([0] * trait_nodes + [1] * rsids_nodes, dtype=torch.long)\n",
    "\n",
    "print(\"Total number of nodes:\", total_nodes)\n",
    "print(\"Number of node types:\", len(node_types))\n",
    "\n",
    "assert len(node_types) == total_nodes, \"Mismatch in the number of nodes and node types\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d489a3-d3d3-4ed4-8c2b-59c86f165f6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Edge Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "849b5a45-34bc-441b-a20d-c78ff8a92d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive SNP-Phenotype edges: 37\n",
      "Negative SNP-Phenotype edges: 18295355\n",
      "Positive SNP-SNP edges: 3787\n",
      "Negative SNP-SNP edges: 18291605\n",
      "Final edges tensor: torch.Size([2, 36590784])\n",
      "Edge labels tensor: torch.Size([36590784])\n"
     ]
    }
   ],
   "source": [
    "# Processing edge data\n",
    "data_copy['lead'] = data_copy['lead'].fillna('N/A')  # Fill NaNs for 'lead' column\n",
    "data_copy['lead_codes'] = data_copy['lead'].cat.codes  # Now you can do the mapping\n",
    "\n",
    "edge_columns = ['rsids_codes', 'trait_codes', 'lead_codes', 'causal', 'LD']\n",
    "edges = data_copy[edge_columns]\n",
    "\n",
    "# Create edges based on 'causal' and 'LD' conditions\n",
    "positive_edges_snp_phenotype = edges[edges['causal'] == 1][['rsids_codes', 'trait_codes']].values.T\n",
    "negative_edges_snp_phenotype = edges[edges['causal'] == 0][['rsids_codes', 'trait_codes']].values.T\n",
    "positive_edges_snp_snp = edges[edges['LD'] == 1][['rsids_codes', 'lead_codes']].values.T\n",
    "negative_edges_snp_snp = edges[edges['LD'] == 0][['rsids_codes', 'lead_codes']].values.T\n",
    "\n",
    "# Combine all edges and their labels\n",
    "edges = np.concatenate([positive_edges_snp_phenotype, negative_edges_snp_phenotype, positive_edges_snp_snp, negative_edges_snp_snp], axis=1)\n",
    "edge_labels = np.concatenate([\n",
    "    np.full(positive_edges_snp_phenotype.shape[1], 0), # Label 0 for causal relationships in SNP-Phenotype edges\n",
    "    np.full(negative_edges_snp_phenotype.shape[1], 1), # Label 1 for non-causal relationships in SNP-Phenotype edges\n",
    "    np.full(positive_edges_snp_snp.shape[1], 2),       # Label 2 for linkage disequilibrium in SNP-SNP edges\n",
    "    np.full(negative_edges_snp_snp.shape[1], 3)        # Label 3 for non-linkage disequilibrium in SNP-SNP edges\n",
    "])\n",
    "\n",
    "edges = torch.from_numpy(edges)\n",
    "edge_labels = torch.from_numpy(edge_labels)\n",
    "\n",
    "# Print relevant information\n",
    "print(\"Positive SNP-Phenotype edges:\", positive_edges_snp_phenotype.shape[1])\n",
    "print(\"Negative SNP-Phenotype edges:\", negative_edges_snp_phenotype.shape[1])\n",
    "print(\"Positive SNP-SNP edges:\", positive_edges_snp_snp.shape[1])\n",
    "print(\"Negative SNP-SNP edges:\", negative_edges_snp_snp.shape[1])\n",
    "print(\"Final edges tensor:\", edges.size())\n",
    "print(\"Edge labels tensor:\", edge_labels.size())\n",
    "\n",
    "# Assertions\n",
    "assert edges.shape[0] == 2, \"Edges tensor should have shape (2, num_edges)\"\n",
    "assert edge_labels.ndim == 1, \"Edge labels tensor should be 1-dimensional\"\n",
    "assert edges.shape[1] == edge_labels.shape[0], \"Edges and edge_labels should have the same number of columns\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341537f-dc0c-4465-9ad3-79e5889fb972",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Edge Attributes and Node Feature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de014a3d-64b0-48b1-b2f8-5e5e42ecf063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge attribute tensor:\n",
      "tensor([0., 0., 0.,  ..., 3., 3., 3.])\n",
      "\n",
      "Node features after processing:\n",
      "tensor([[ 0.0000e+00,  9.3201e+06,  1.0744e+04,  ..., -6.4647e-02,\n",
      "         -5.2159e-01, -5.2213e-01],\n",
      "        [ 0.0000e+00,  1.7153e+07,  1.0744e+04,  ..., -3.0032e-01,\n",
      "         -4.8745e-01, -4.8724e-01],\n",
      "        [ 0.0000e+00,  1.1052e+07,  1.0744e+04,  ...,  4.4701e-01,\n",
      "         -5.4269e-01, -5.4267e-01],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  2.4669e+06,  1.2527e+04,  ..., -1.8717e-01,\n",
      "         -5.3397e-01, -5.3461e-01],\n",
      "        [ 0.0000e+00,  3.5383e+06,  1.2527e+04,  ...,  4.1164e-01,\n",
      "         -5.4174e-01, -5.4195e-01],\n",
      "        [ 1.0000e+00, -1.0000e+00,  9.7710e+03,  ..., -6.6119e-01,\n",
      "         -5.4766e-01, -5.4769e-01]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to encode and scale columns\n",
    "def process_columns(df, encode_cols, scale_cols):\n",
    "    # Encode columns\n",
    "    for col in encode_cols:\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "    # Scale columns\n",
    "    scaler = StandardScaler()\n",
    "    for col in scale_cols:\n",
    "        df[col] = scaler.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    return df\n",
    "\n",
    "# Preprocessing node features\n",
    "fill_values = {'nearest_genes': 'N/A', '#chrom': 'N/A', 'pos': 0, 'ref': 'N/A', 'alt': 'N/A', 'beta': 0, 'sebeta': 0, 'af_alt': 0, 'af_alt_cases': 0}\n",
    "node_features = fill_na(node_features, fill_values)\n",
    "\n",
    "# Define columns to be encoded and scaled\n",
    "categorical_columns = ['trait', 'rsids', 'nearest_genes', '#chrom', 'ref', 'alt']\n",
    "numerical_columns = ['pos', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']\n",
    "\n",
    "# Process node features\n",
    "node_features = process_columns(node_features, categorical_columns, numerical_columns)\n",
    "\n",
    "# Convert to tensor\n",
    "node_features = torch.tensor(node_features.values, dtype=torch.float)\n",
    "\n",
    "# Compute edge attributes\n",
    "edge_attr = torch.tensor([0] * positive_edges_snp_phenotype.shape[1] + [1] * negative_edges_snp_phenotype.shape[1] + [2] * positive_edges_snp_snp.shape[1] + [3] * negative_edges_snp_snp.shape[1], dtype=torch.float)\n",
    "\n",
    "# Print relevant information\n",
    "print(\"Edge attribute tensor:\")\n",
    "print(edge_attr)\n",
    "print()\n",
    "print(\"Node features after processing:\")\n",
    "print(node_features)\n",
    "\n",
    "# Assertions\n",
    "assert node_features.ndim == 2, \"Node features tensor should have 2 dimensions\"\n",
    "assert edge_attr.ndim == 1, \"Edge attribute tensor should be 1-dimensional\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8bbff-cba1-47c0-8ea2-f13c0d03250e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Construct Graph Data Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8191c4ff-f502-4d06-9eb5-fc536a923836",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[18295393, 11], edge_index=[2, 36590784], edge_attr=[36590784], y=[36590784], node_types=[18295393])\n"
     ]
    }
   ],
   "source": [
    "# Convert node features to tensor\n",
    "if isinstance(node_features, pd.DataFrame):\n",
    "    node_features_tensor = torch.tensor(node_features.values(), dtype=torch.float)\n",
    "else:\n",
    "    node_features_tensor = node_features\n",
    "\n",
    "# Create the PyTorch Geometric data object\n",
    "graph = Data(x=node_features_tensor, edge_index=edges, edge_attr=edge_attr)\n",
    "\n",
    "graph.y = torch.tensor(data['causal'].map({1: 0, 0: 1}).tolist() + data['LD'].map({1: 2, 0: 3}).tolist(), dtype=torch.long)\n",
    "\n",
    "# Truncate the node_types tensor to match the adjusted number of nodes\n",
    "graph.node_types = node_types\n",
    "\n",
    "# Assertions\n",
    "assert graph.x.ndim == 2, \"Node features tensor should have 2 dimensions\"\n",
    "assert graph.edge_index.ndim == 2, \"Edge index tensor should have 2 dimensions\"\n",
    "assert graph.edge_attr.ndim == 1, \"Edge attribute tensor should be 1-dimensional\"\n",
    "assert graph.num_nodes == total_nodes, \"Number of nodes in the graph should match the total number of nodes\"\n",
    "assert graph.num_node_features == node_features_tensor.shape[1], \"Number of node features in the graph should match the number of columns in node_features\"\n",
    "assert graph.edge_index.size(1) == edges.shape[1], \"Number of edges in the graph should match the number of columns in edges\"\n",
    "assert graph.edge_attr.size(0) == graph.edge_index.size(1), \"Number of edge attributes should match the number of edges\"\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60cae52-2493-43ae-9e27-e7dc67c3a7f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0709aa36-0d8a-45de-b5c5-1b287fad15ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph stats:\n",
      "Number of nodes: 18295393\n",
      "Number of 0 nodes: 1\n",
      "Number of 1 nodes: 18295392\n",
      "Number of positive edges between SNPs and phenotypes: 37\n",
      "Number of negative edges between SNPs and phenotypes: 18295355\n",
      "Number of positive edges between SNPs: 3787\n",
      "Number of negative edges between SNPs: 18291605\n",
      "Number of edges: 36590784\n",
      "Node feature dimension: 11\n",
      "\n",
      "0 node stats:\n",
      "Average degree: 2.00\n",
      "Median degree: 2.00\n",
      "Standard deviation of degree: nan\n",
      "\n",
      "1 node stats:\n",
      "Average degree: 2.00\n",
      "Median degree: 2.00\n",
      "Standard deviation of degree: 0.00\n",
      "Density: 0.0000002186\n",
      "Are there any NaN values in features? False\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree\n",
    "\n",
    "def print_graph_stats(graph, positive_edges_snp_phenotype, negative_edges_snp_phenotype, positive_edges_snp_snp, negative_edges_snp_snp):\n",
    "    node_types = np.unique(graph.node_types.numpy(), return_counts=True)\n",
    "\n",
    "    print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "    for node_type, count in zip(*node_types):\n",
    "        print(f\"Number of {node_type} nodes: {count}\")\n",
    "    print(f\"Number of positive edges between SNPs and phenotypes: {positive_edges_snp_phenotype.shape[1]}\")\n",
    "    print(f\"Number of negative edges between SNPs and phenotypes: {negative_edges_snp_phenotype.shape[1]}\")\n",
    "    print(f\"Number of positive edges between SNPs: {positive_edges_snp_snp.shape[1]}\")\n",
    "    print(f\"Number of negative edges between SNPs: {negative_edges_snp_snp.shape[1]}\")\n",
    "    print(f\"Number of edges: {graph.num_edges}\")\n",
    "    print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "\n",
    "    # Compute and print degree-related stats for each node type\n",
    "    for node_type in node_types[0]:\n",
    "        node_indices = np.where(graph.node_types.numpy() == node_type)[0]\n",
    "        degrees = degree(graph.edge_index[0].long(), num_nodes=graph.num_nodes)[node_indices]\n",
    "        average_degree = degrees.float().mean().item()\n",
    "        median_degree = np.median(degrees.numpy())\n",
    "        std_degree = degrees.float().std().item()\n",
    "\n",
    "        print(f\"\\n{node_type} node stats:\")\n",
    "        print(f\"Average degree: {average_degree:.2f}\")\n",
    "        print(f\"Median degree: {median_degree:.2f}\")\n",
    "        print(f\"Standard deviation of degree: {std_degree:.2f}\")\n",
    "\n",
    "    # Density is the ratio of actual edges to the maximum number of possible edges\n",
    "    num_possible_edges = graph.num_nodes * (graph.num_nodes - 1) / 2\n",
    "    density = graph.num_edges / num_possible_edges\n",
    "    print(f\"Density: {density:.10f}\")\n",
    "\n",
    "    # Check for NaN values in features\n",
    "    nan_in_features = torch.isnan(graph.x).any().item()\n",
    "    print(f\"Are there any NaN values in features? {nan_in_features}\")\n",
    "\n",
    "# Print\n",
    "print(\"Graph stats:\")\n",
    "print_graph_stats(graph, positive_edges_snp_phenotype, negative_edges_snp_phenotype, positive_edges_snp_snp, negative_edges_snp_snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51e96d-660c-4b4f-8ac4-9a07dba5bcc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d7d2733-2679-4800-9bdc-c42864c56429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation vector: tensor([ 4275234, 17743950,  4963753,  ..., 35549552,  9354397,  5111534])\n",
      "Train size: 21954470, Validation size: 7318157, Test size: 7318157\n",
      "Train edge index shape: torch.Size([2, 21954470])\n",
      "Validation edge index shape: torch.Size([2, 7318157])\n",
      "Test edge index shape: torch.Size([2, 7318157])\n",
      "Train labels shape: torch.Size([21954470])\n",
      "Validation labels shape: torch.Size([7318157])\n",
      "Test labels shape: torch.Size([7318157])\n",
      "Number of training edges: 21954470\n",
      "Number of validation edges: 7318157\n",
      "Number of test edges: 7318157\n"
     ]
    }
   ],
   "source": [
    "def shuffle_graph_data(data, seed=None):\n",
    "    \"\"\"Shuffle the edges of a graph along with their corresponding attributes.\"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    perm = torch.randperm(data.num_edges)\n",
    "    print(f\"Permutation vector: {perm}\")\n",
    "\n",
    "    # Shuffle edge_index\n",
    "    data.edge_index = data.edge_index[:, perm]\n",
    "\n",
    "    # Shuffle edge attributes\n",
    "    if data.edge_attr is not None:\n",
    "        data.edge_attr = data.edge_attr[perm]\n",
    "\n",
    "    # Shuffle edge labels\n",
    "    data.y = data.y[perm]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Shuffle the graph data\n",
    "graph = shuffle_graph_data(graph, seed=12345)\n",
    "\n",
    "# Compute the sizes of training, validation, and test sets\n",
    "train_size = int(graph.num_edges * 0.6)\n",
    "val_size = (graph.num_edges - train_size) // 2\n",
    "test_size = graph.num_edges - train_size - val_size\n",
    "\n",
    "print(f\"Train size: {train_size}, Validation size: {val_size}, Test size: {test_size}\")\n",
    "assert train_size + val_size + test_size == graph.num_edges, \"Sizes do not add up to total number of edges.\"\n",
    "\n",
    "# Create index for each set\n",
    "train_index = torch.arange(train_size)\n",
    "val_index = torch.arange(train_size, train_size + val_size)\n",
    "test_index = torch.arange(train_size + val_size, graph.num_edges)\n",
    "\n",
    "# Split edge_index\n",
    "train_edge_index = graph.edge_index[:, train_index]\n",
    "val_edge_index = graph.edge_index[:, val_index]\n",
    "test_edge_index = graph.edge_index[:, test_index]\n",
    "\n",
    "# Check edge indices\n",
    "print(f\"Train edge index shape: {train_edge_index.shape}\")\n",
    "print(f\"Validation edge index shape: {val_edge_index.shape}\")\n",
    "print(f\"Test edge index shape: {test_edge_index.shape}\")\n",
    "\n",
    "# Split edge attributes\n",
    "if graph.edge_attr is not None:\n",
    "    train_edge_attr = graph.edge_attr[train_index]\n",
    "    val_edge_attr = graph.edge_attr[val_index]\n",
    "    test_edge_attr = graph.edge_attr[test_index]\n",
    "else:\n",
    "    train_edge_attr, val_edge_attr, test_edge_attr = None, None, None\n",
    "\n",
    "# Split edge labels\n",
    "train_y = graph.y[train_index]\n",
    "val_y = graph.y[val_index]\n",
    "test_y = graph.y[test_index]\n",
    "\n",
    "# Check labels\n",
    "print(f\"Train labels shape: {train_y.shape}\")\n",
    "print(f\"Validation labels shape: {val_y.shape}\")\n",
    "print(f\"Test labels shape: {test_y.shape}\")\n",
    "\n",
    "# Create the data for each set\n",
    "train_data = Data(x=graph.x, edge_index=train_edge_index, edge_attr=train_edge_attr, y=train_y)\n",
    "val_data = Data(x=graph.x, edge_index=val_edge_index, edge_attr=val_edge_attr, y=val_y)\n",
    "test_data = Data(x=graph.x, edge_index=test_edge_index, edge_attr=test_edge_attr, y=test_y)\n",
    "\n",
    "print(f\"Number of training edges: {train_data.num_edges}\")\n",
    "print(f\"Number of validation edges: {val_data.num_edges}\")\n",
    "print(f\"Number of test edges: {test_data.num_edges}\")\n",
    "\n",
    "# Check that the sum of the edges in the split datasets equals the total number of edges\n",
    "assert train_data.num_edges + val_data.num_edges + test_data.num_edges == graph.num_edges, \"Split datasets do not add up to total number of edges.\"\n",
    "\n",
    "# Check the number of unique classes in the original graph data\n",
    "num_classes = torch.unique(graph.y).size(0)\n",
    "assert num_classes == 4, \"The original graph data does not have 4 classes.\"\n",
    "\n",
    "# Check the number of unique classes in the split datasets\n",
    "train_num_classes = torch.unique(train_data.y).size(0)\n",
    "val_num_classes = torch.unique(val_data.y).size(0)\n",
    "test_num_classes = torch.unique(test_data.y).size(0)\n",
    "assert train_num_classes == 4, \"The training data does not have 4 classes.\"\n",
    "assert val_num_classes == 4, \"The validation data does not have 4 classes.\"\n",
    "assert test_num_classes == 4, \"The test data does not have 4 classes.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665050a-5cd9-4960-a2ef-8a4cf2cb5e40",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2557f-d84e-4a1b-bda8-7b26620f526b",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ae175ab-f1da-4ac9-bd1c-f180eb8e2313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (18295393) to match target batch_size (21954470).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Train the model for a number of epochs\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m---> 50\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m evaluate_model(model, train_data)\n\u001b[0;32m     52\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m evaluate_model(model, val_data)\n",
      "Cell \u001b[1;32mIn[27], line 26\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, data, optimizer, criterion)\u001b[0m\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     25\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m---> 26\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (18295393) to match target batch_size (21954470)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.out = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(data.x, data.edge_index)\n",
    "        _, preds = preds.max(dim=1)\n",
    "        correct = float(preds.eq(data.y).sum().item())\n",
    "        acc = correct / data.num_nodes\n",
    "    return acc\n",
    "\n",
    "\n",
    "# Assuming train_data, val_data, test_data are defined elsewhere\n",
    "# Initialize the model and optimizer\n",
    "num_classes = torch.unique(train_data.y).size(0)\n",
    "model = GCN(num_features=train_data.num_node_features, hidden_channels=4, num_classes=num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model for a number of epochs\n",
    "for epoch in range(50):\n",
    "    loss = train_model(model, train_data, optimizer, criterion)\n",
    "    train_acc = evaluate_model(model, train_data)\n",
    "    val_acc = evaluate_model(model, val_data)\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# After training, evaluate the model on the test set\n",
    "test_acc = evaluate_model(model, test_data)\n",
    "print(f'Test Acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f18bc-533d-4abc-8f00-eefce465700e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
