{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00910a35-ffbc-4497-bcc8-21f008c326fb",
   "metadata": {},
   "source": [
    "# Point Cloud Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b033d-95f5-4584-b10c-72969a166612",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4345459-b1ef-477c-8f06-c8f54c194af0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "NumPy version: 1.24.1\n",
      "Pandas version: 1.5.3\n",
      "Matplotlib version: 3.7.1\n",
      "Scikit-learn version: 1.3.0\n",
      "Torch version: 2.0.1+cu117\n",
      "Torch Geometric version: 2.3.1\n",
      "NetworkX version: 3.0\n",
      "Using NVIDIA RTX A6000 (cuda)\n",
      "CUDA version: 11.7\n",
      "Number of CUDA devices: 2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from numba import jit, prange\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "import networkx as nx\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.special import expit\n",
    "from typing import List, Dict\n",
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "import category_encoders as ce\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import copy\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "# Print versions of imported libraries\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Torch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddfa8cb-01df-491f-94f0-c8c228256b4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fe5b06-7392-4d62-a1e8-af081cdf3e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'int64',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'finemapped': 'int64'\n",
    "}\n",
    "\n",
    "data = pd.read_csv('~/Desktop/GeoGWAS/FinnGen/data/gwas-finemap.csv', dtype=dtypes)\n",
    "\n",
    "# Assert column names\n",
    "expected_columns = ['#chrom', 'pos', 'ref', 'alt', 'rsids', 'nearest_genes', 'pval', 'mlogp', 'beta',\n",
    "                    'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls', 'finemapped',\n",
    "                    'id', 'trait']\n",
    "assert set(data.columns) == set(expected_columns), \"Unexpected columns in the data DataFrame.\"\n",
    "\n",
    "# Assert data types\n",
    "expected_dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'int64',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'finemapped': 'int64'\n",
    "}\n",
    "\n",
    "for col, expected_dtype in expected_dtypes.items():\n",
    "    assert data[col].dtype == expected_dtype, f\"Unexpected data type for column {col}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a754a-7836-439e-801c-7efca6d2dfc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513cafa0-f3f8-47b5-9d22-96062449edde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data = data.sample(frac=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5c76a8-a662-4ae0-8d00-c85b402fb120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SNPs per Chromosome:\n",
      "#chrom\n",
      "1     1527735\n",
      "2     1668096\n",
      "3     1395815\n",
      "4     1395767\n",
      "5     1264833\n",
      "6     1255027\n",
      "7     1135429\n",
      "8     1083225\n",
      "9      849406\n",
      "10     971906\n",
      "11     956229\n",
      "12     925156\n",
      "13     701351\n",
      "14     637320\n",
      "15     560161\n",
      "16     624439\n",
      "17     536114\n",
      "18     550566\n",
      "19     430361\n",
      "20     441761\n",
      "21     259164\n",
      "22     272290\n",
      "23     727855\n",
      "Name: id, dtype: int64\n",
      "\n",
      "Number of Finemapped SNPs per Chromosome:\n",
      "#chrom\n",
      "1     173381\n",
      "2     182870\n",
      "3     160831\n",
      "4     203738\n",
      "5      88348\n",
      "6     243622\n",
      "7     183372\n",
      "8     120372\n",
      "9     210862\n",
      "10    165926\n",
      "11    225123\n",
      "12    197761\n",
      "13    101524\n",
      "14     77829\n",
      "15     79464\n",
      "16    107026\n",
      "17    127416\n",
      "18    122219\n",
      "19     84577\n",
      "20     90008\n",
      "22     18619\n",
      "23     92959\n",
      "Name: id, dtype: int64\n",
      "\n",
      "Percentage of Finemapped SNPs per Chromosome:\n",
      "#chrom\n",
      "1     11.348892\n",
      "2     10.962798\n",
      "3     11.522372\n",
      "4     14.596849\n",
      "5      6.984954\n",
      "6     19.411694\n",
      "7     16.150019\n",
      "8     11.112373\n",
      "9     24.824642\n",
      "10    17.072227\n",
      "11    23.542792\n",
      "12    21.375963\n",
      "13    14.475491\n",
      "14    12.211919\n",
      "15    14.185922\n",
      "16    17.139544\n",
      "17    23.766587\n",
      "18    22.198792\n",
      "19    19.652571\n",
      "20    20.374818\n",
      "21     0.000000\n",
      "22     6.837930\n",
      "23    12.771637\n",
      "Name: id, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of SNPs per chromosome\n",
    "snps_per_chrom = data.groupby('#chrom')['id'].nunique()\n",
    "\n",
    "# Filter the data for finemapped variants\n",
    "finemapped_data = data[data['finemapped'] == 1]\n",
    "\n",
    "# Count the number of finemapped SNPs per chromosome\n",
    "finemapped_counts = finemapped_data.groupby('#chrom')['id'].nunique()\n",
    "\n",
    "# Calculate the percentage of finemapped SNPs per chromosome\n",
    "percentage_finemapped = (finemapped_counts / snps_per_chrom * 100).fillna(0)\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of SNPs per Chromosome:\")\n",
    "print(snps_per_chrom)\n",
    "print(\"\\nNumber of Finemapped SNPs per Chromosome:\")\n",
    "print(finemapped_counts)\n",
    "print(\"\\nPercentage of Finemapped SNPs per Chromosome:\")\n",
    "print(percentage_finemapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460fab1f-46fa-40a5-a8c5-aa746b1db7eb",
   "metadata": {},
   "source": [
    "### Find nearest gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b729972-b0d7-4e38-b8e2-aedd07506c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['nearest_genes'] = data['nearest_genes'].astype(str)\n",
    "\n",
    "# Assert column 'nearest_genes' is a string\n",
    "assert data['nearest_genes'].dtype == 'object', \"Column 'nearest_genes' is not of string type.\"\n",
    "\n",
    "# Get the length of the data before transformation\n",
    "original_length = len(data)\n",
    "\n",
    "# Extract the first gene name from the 'nearest_genes' column\n",
    "data['nearest_genes'] = data['nearest_genes'].str.split(',').str[0]\n",
    "\n",
    "# Reset index to have a standard index\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Assert the length of the data remains the same\n",
    "assert len(data) == original_length, \"Length of the data has changed after transformation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eddaed-2f48-4440-b6d6-0dc247f23ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe89142-2b65-469b-b330-1620d303312b",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The dataset is a Pandas DataFrame named `data`, which includes the following columns:\n",
    "\n",
    "- `id`: Unique ID of the variant in the format #chrom:pos:ref:alt (string).\n",
    "- `#chrom`: Chromosome number where the genetic variant is located.\n",
    "- `pos`: Position of the genetic variant on the chromosome (integer between 1 and 200,000).\n",
    "- `ref`: Reference allele (or variant) at the genomic position.\n",
    "- `alt`: Alternate allele observed at the genomic position.\n",
    "- `rsids`: Reference SNP cluster ID, a unique identifier for each variant used in the dbSNP database.\n",
    "- `nearest_genes`: Gene nearest to the variant (string).\n",
    "- `pval`: P-value, a statistical measure for the strength of evidence against the null hypothesis.\n",
    "- `mlogp`: Minus log of the p-value, commonly used in genomic studies.\n",
    "- `beta`: Beta coefficient, representing the effect size of the variant.\n",
    "- `sebeta`: Standard error of the beta coefficient.\n",
    "- `af_alt`: Allele frequency of the alternate variant in the general population (float between 0 and 1).\n",
    "- `af_alt_cases`: Allele frequency of the alternate variant in the cases group (float between 0 and 1).\n",
    "- `af_alt_controls`: Allele frequency of the alternate variant in the control group (float between 0 and 1).\n",
    "- `finemapped`: Indicator whether the variant is included in the post-finemapped dataset (1) or not (0) (integer).\n",
    "- `trait`: Trait associated with the variant. In this dataset, it refers to the response to the drug paracetamol and NSAIDs.\n",
    "\n",
    "### Task Overview\n",
    "\n",
    "The task is to predict whether variants are included in the post-finemapped dataset based on `finemapped` using point cloud data dimensionality reduction and clustering techniques in combination with machine learning techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d039953-efdd-44f9-b357-ba4710f700da",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e59902-a473-4f37-9d2b-25ffc671c45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>pval</th>\n",
       "      <th>mlogp</th>\n",
       "      <th>beta</th>\n",
       "      <th>sebeta</th>\n",
       "      <th>af_alt</th>\n",
       "      <th>af_alt_cases</th>\n",
       "      <th>af_alt_controls</th>\n",
       "      <th>finemapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.017001e+07</td>\n",
       "      <td>2.017001e+07</td>\n",
       "      <td>2.017001e+07</td>\n",
       "      <td>2.017001e+07</td>\n",
       "      <td>2.017001e+07</td>\n",
       "      <td>2.017001e+07</td>\n",
       "      <td>2.017001e+07</td>\n",
       "      <td>2.017001e+07</td>\n",
       "      <td>2.017001e+07</td>\n",
       "      <td>2.017001e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.158641e+00</td>\n",
       "      <td>7.859438e+07</td>\n",
       "      <td>4.544099e-01</td>\n",
       "      <td>5.596207e-01</td>\n",
       "      <td>9.619015e-05</td>\n",
       "      <td>1.052461e-01</td>\n",
       "      <td>1.175830e-01</td>\n",
       "      <td>1.175803e-01</td>\n",
       "      <td>1.175835e-01</td>\n",
       "      <td>1.516037e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.273152e+00</td>\n",
       "      <td>5.547648e+07</td>\n",
       "      <td>3.008589e-01</td>\n",
       "      <td>7.377075e-01</td>\n",
       "      <td>2.055397e-01</td>\n",
       "      <td>1.628265e-01</td>\n",
       "      <td>2.207685e-01</td>\n",
       "      <td>2.207494e-01</td>\n",
       "      <td>2.207725e-01</td>\n",
       "      <td>3.586363e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.025300e+04</td>\n",
       "      <td>4.570880e-208</td>\n",
       "      <td>4.549670e-09</td>\n",
       "      <td>-2.847310e+01</td>\n",
       "      <td>5.494070e-03</td>\n",
       "      <td>6.836890e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.793800e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.310701e+07</td>\n",
       "      <td>1.822730e-01</td>\n",
       "      <td>1.457850e-01</td>\n",
       "      <td>-2.763810e-02</td>\n",
       "      <td>1.148620e-02</td>\n",
       "      <td>6.442160e-04</td>\n",
       "      <td>6.489500e-04</td>\n",
       "      <td>6.434450e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>6.962611e+07</td>\n",
       "      <td>4.383840e-01</td>\n",
       "      <td>3.581450e-01</td>\n",
       "      <td>-1.961835e-04</td>\n",
       "      <td>4.409780e-02</td>\n",
       "      <td>6.267320e-03</td>\n",
       "      <td>6.275370e-03</td>\n",
       "      <td>6.265070e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>1.139343e+08</td>\n",
       "      <td>7.148500e-01</td>\n",
       "      <td>7.392780e-01</td>\n",
       "      <td>2.627730e-02</td>\n",
       "      <td>1.421070e-01</td>\n",
       "      <td>1.141450e-01</td>\n",
       "      <td>1.141540e-01</td>\n",
       "      <td>1.141570e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>2.489455e+08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.073400e+02</td>\n",
       "      <td>2.453920e+01</td>\n",
       "      <td>1.224700e+01</td>\n",
       "      <td>9.999930e-01</td>\n",
       "      <td>9.999990e-01</td>\n",
       "      <td>9.999960e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             #chrom           pos           pval         mlogp          beta  \\\n",
       "count  2.017001e+07  2.017001e+07   2.017001e+07  2.017001e+07  2.017001e+07   \n",
       "mean   9.158641e+00  7.859438e+07   4.544099e-01  5.596207e-01  9.619015e-05   \n",
       "std    6.273152e+00  5.547648e+07   3.008589e-01  7.377075e-01  2.055397e-01   \n",
       "min    1.000000e+00  1.025300e+04  4.570880e-208  4.549670e-09 -2.847310e+01   \n",
       "25%    4.000000e+00  3.310701e+07   1.822730e-01  1.457850e-01 -2.763810e-02   \n",
       "50%    8.000000e+00  6.962611e+07   4.383840e-01  3.581450e-01 -1.961835e-04   \n",
       "75%    1.300000e+01  1.139343e+08   7.148500e-01  7.392780e-01  2.627730e-02   \n",
       "max    2.300000e+01  2.489455e+08   1.000000e+00  2.073400e+02  2.453920e+01   \n",
       "\n",
       "             sebeta        af_alt  af_alt_cases  af_alt_controls    finemapped  \n",
       "count  2.017001e+07  2.017001e+07  2.017001e+07     2.017001e+07  2.017001e+07  \n",
       "mean   1.052461e-01  1.175830e-01  1.175803e-01     1.175835e-01  1.516037e-01  \n",
       "std    1.628265e-01  2.207685e-01  2.207494e-01     2.207725e-01  3.586363e-01  \n",
       "min    5.494070e-03  6.836890e-06  0.000000e+00     1.793800e-06  0.000000e+00  \n",
       "25%    1.148620e-02  6.442160e-04  6.489500e-04     6.434450e-04  0.000000e+00  \n",
       "50%    4.409780e-02  6.267320e-03  6.275370e-03     6.265070e-03  0.000000e+00  \n",
       "75%    1.421070e-01  1.141450e-01  1.141540e-01     1.141570e-01  0.000000e+00  \n",
       "max    1.224700e+01  9.999930e-01  9.999990e-01     9.999960e-01  1.000000e+00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b86733-093b-4a4e-bf58-61db5c68f6d2",
   "metadata": {},
   "source": [
    "### Mann-Whitney U test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b65df7ec-8bd2-4051-a15f-4c8019be4834",
   "metadata": {},
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# List of numerical columns\n",
    "numerical_columns = ['pos', 'pval', 'mlogp', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls']\n",
    "\n",
    "# List of chromosomes (convert to integers and sort)\n",
    "chromosomes = sorted(data['#chrom'].unique().astype(int))\n",
    "\n",
    "# Perform the Mann-Whitney U test for each numerical column for each chromosome\n",
    "for chrom in chromosomes:\n",
    "    data_finemapped = data[(data['finemapped'] == 1) & (data['#chrom'] == chrom)]\n",
    "    data_not_finemapped = data[(data['finemapped'] == 0) & (data['#chrom'] == chrom)]\n",
    "    \n",
    "    print(f'Chromosome: {chrom}')\n",
    "    \n",
    "    if len(data_finemapped) == 0 or len(data_not_finemapped) == 0:\n",
    "        print(\"One of the groups has zero size. Skipping this chromosome for the Mann-Whitney U test.\")\n",
    "        print('--------------------------')\n",
    "        continue\n",
    "    \n",
    "    for col in numerical_columns:\n",
    "        statistic, p_value = stats.mannwhitneyu(data_finemapped[col], data_not_finemapped[col])\n",
    "        print(f'Column: {col}')\n",
    "        print(f'Mann-Whitney U statistic: {statistic}')\n",
    "        print(f'P-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e606e887-eb85-4e36-ac7b-0c211c4fe61c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## TDA"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fe2c3a2-549d-4a0b-8544-6d464bbc2e4e",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "import gudhi as gd\n",
    "from gudhi.representations import PersistenceImage\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from persim import plot_diagrams\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "from importlib import reload\n",
    "\n",
    "# Filter data for chromosome \n",
    "data = data[data['#chrom'] == 22]\n",
    "data.sort_values(by='pos', inplace=True)\n",
    "data = data.head(10_000)\n",
    "\n",
    "# Select the features to be used in the point cloud\n",
    "features = ['pos', 'mlogp', 'af_alt_cases', 'af_alt_controls']\n",
    "X = data[features]\n",
    "\n",
    "# Standardize the features using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Assume you have already scaled the 'data' DataFrame as in previous code snippets\n",
    "\n",
    "# Compute Rips persistence diagram\n",
    "rips_complex = gd.RipsComplex(points=X_scaled, max_edge_length=0.5)\n",
    "simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "diag = simplex_tree.persistence()\n",
    "\n",
    "# Plot persistence diagram\n",
    "gd.plot_persistence_diagram(diag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09592173-09ed-46b0-9fa4-c0c4bdeb3282",
   "metadata": {},
   "source": [
    "# Create persistence images for each dimension\n",
    "pers_imager = PersistenceImage()\n",
    "pers_img = pers_imager.fit_transform([diag])\n",
    "\n",
    "# Flatten persistence images for classification\n",
    "X_features = pers_img.reshape(pers_img.shape[0], -1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc469f-0a1c-42c5-aeb5-571d0664228b",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543643f6-d9bc-41cc-87ee-e610afd9d3b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07905b48-4f0a-4f71-9b30-f80943a92611",
   "metadata": {},
   "source": [
    "%%time \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from umap import UMAP\n",
    "\n",
    "# Filter numerical columns\n",
    "numerical_cols = ['pos', 'mlogp', 'af_alt_cases', 'af_alt_controls']\n",
    "\n",
    "# Filter data for chromosome \n",
    "data = data[data['#chrom'] == 6]\n",
    "\n",
    "# Sort the data by 'pos' column\n",
    "data.sort_values(by='pos', inplace=True)\n",
    "\n",
    "X = data[numerical_cols]\n",
    "y = data['finemapped']\n",
    "\n",
    "# Create a scaler and UMAP instances\n",
    "scaler = RobustScaler()\n",
    "umap = UMAP(n_components=2, random_state=42) # Change to 2 components for plotting\n",
    "\n",
    "# Apply transformations\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "embedding = umap.fit_transform(X_scaled)\n",
    "\n",
    "# Create DataFrame for easy plotting\n",
    "plot_data = pd.DataFrame(embedding, columns=['Component 1', 'Component 2'])\n",
    "plot_data['finemapped'] = y.values\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(100, 100))\n",
    "finemapped = plot_data[plot_data['finemapped'] == 1]\n",
    "not_finemapped = plot_data[plot_data['finemapped'] == 0]\n",
    "plt.scatter(finemapped['Component 1'], finemapped['Component 2'], color='red', label='Finemapped')\n",
    "plt.scatter(not_finemapped['Component 1'], not_finemapped['Component 2'], color='blue', label='Not finemapped')\n",
    "plt.legend()\n",
    "plt.title('UMAP Projection of the Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a1969-ce4a-45e9-ab8f-8c42be901ba4",
   "metadata": {},
   "source": [
    "### Classification + Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474aac49-dc5e-4e29-8089-3b62bd685438",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c6959e-e91c-4626-a831-dd3557102226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10h 5min 45s\n",
      "Wall time: 1h 16min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from umap import UMAP\n",
    "\n",
    "# Filter numerical columns\n",
    "numerical_cols = [\n",
    "    'pos', 'mlogp', 'af_alt_cases', 'af_alt_controls'\n",
    "]\n",
    "\n",
    "# Filter data for chromosome \n",
    "data = data[data['#chrom'] == 2]\n",
    "\n",
    "# Sort the data by 'pos' column\n",
    "data.sort_values(by='pos', inplace=True)\n",
    "\n",
    "X = data[numerical_cols]\n",
    "y = data['finemapped']\n",
    "\n",
    "# Split the data into training set and temp set (validation + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ") # leaving 40% for the validation and test sets\n",
    "\n",
    "# Split the temp set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ") # splitting the 40% evenly into validation and test sets, so they each are 20% of the original data\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaling', RobustScaler()), \n",
    "    ('umap', UMAP(n_components=4, random_state=42)), \n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the pipeline on training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model on validation set\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "# After model selection and tuning, finally test the model on the test set\n",
    "y_test_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5b4292-d877-4c46-ad52-b9af0d6f511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Accuracy: 0.9568329509939492\n",
      "Precision: 0.8491580229286524\n",
      "Recall: 0.737185563251914\n",
      "F1 Score: 0.7892199910231642\n",
      "ROC AUC Score: 0.9288726994894057\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.9570569310393062\n",
      "Precision: 0.8497526620273329\n",
      "Recall: 0.7389449892457439\n",
      "F1 Score: 0.7904845471385396\n",
      "ROC AUC Score: 0.9310159030253243\n",
      "\n",
      "\n",
      "Test Accuracy for finemapped nodes: 0.7389449892457439\n",
      "Test Accuracy for not finemapped nodes: 0.983912668773341\n",
      "\n",
      "\n",
      "CPU times: total: 26min 46s\n",
      "Wall time: 26min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "y_val_proba = pipeline.predict_proba(X_val)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "# Print metrics for validation set\n",
    "print(\"Validation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_val_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_val_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_val_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_val_pred)}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_val, y_val_proba)}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "y_test_proba = pipeline.predict_proba(X_test)[:, 1]  # get probabilities for the positive class\n",
    "\n",
    "# Print metrics for test set\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred)}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_test_proba)}\")\n",
    "\n",
    "# Masks for finemapped and not_finemapped\n",
    "finemapped_mask_test = y_test == 1\n",
    "not_finemapped_mask_test = y_test == 0\n",
    "\n",
    "# Apply masks to y_test_pred\n",
    "y_pred_finemapped_test = y_test_pred[finemapped_mask_test]\n",
    "y_pred_not_finemapped_test = y_test_pred[not_finemapped_mask_test]\n",
    "\n",
    "# Create masks for correctly predicted finemapped and not_finemapped\n",
    "correct_finemapped_mask_test = y_pred_finemapped_test == 1\n",
    "correct_not_finemapped_mask_test = y_pred_not_finemapped_test == 0\n",
    "\n",
    "# Calculate accuracy for both groups on test set\n",
    "accuracy_finemapped_test = sum(correct_finemapped_mask_test) / len(y_pred_finemapped_test)\n",
    "accuracy_not_finemapped_test = sum(correct_not_finemapped_mask_test) / len(y_pred_not_finemapped_test)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Test Accuracy for finemapped nodes: {accuracy_finemapped_test}\")\n",
    "print(f\"Test Accuracy for not finemapped nodes: {accuracy_not_finemapped_test}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73af2c7a-02a3-4e19-8bc8-55c401378e69",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e56c819f-98d7-44c2-9948-2dd43a0171d2",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute UMAP representations of the training data\n",
    "umap_transformer = UMAP(n_components=2, random_state=42)\n",
    "X_train_umap = umap_transformer.fit_transform(X_train)\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "umap_df = pd.DataFrame(data=X_train_umap, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['finemapped'] = y_train.values\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(100, 100))\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='finemapped', data=umap_df, palette='viridis')\n",
    "plt.title('UMAP Projection of the Genetic Data', fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
