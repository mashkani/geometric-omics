{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00910a35-ffbc-4497-bcc8-21f008c326fb",
   "metadata": {},
   "source": [
    "# Grapher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b033d-95f5-4584-b10c-72969a166612",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4345459-b1ef-477c-8f06-c8f54c194af0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]\n",
      "NumPy version: 1.24.3\n",
      "Pandas version: 2.0.1\n",
      "Matplotlib version: 3.7.1\n",
      "Scikit-learn version: 1.2.2\n",
      "Torch version: 2.0.0+cu118\n",
      "Torch Geometric version: 2.3.1\n",
      "NetworkX version: 3.0\n",
      "Using NVIDIA GeForce RTX 3060 Ti (cuda)\n",
      "CUDA version: 11.8\n",
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "import networkx as nx\n",
    "from scipy.spatial import cKDTree\n",
    "from typing import List, Dict\n",
    "import time\n",
    "import collections\n",
    "\n",
    "# Print versions of imported libraries\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Torch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddfa8cb-01df-491f-94f0-c8c228256b4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fe5b06-7392-4d62-a1e8-af081cdf3e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'string',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'causal': 'int64',\n",
    "    'LD': 'int64',\n",
    "    'lead': 'string',\n",
    "    'trait': 'string'\n",
    "}\n",
    "\n",
    "data = pd.read_csv('~/Desktop/gwas-graph/FinnGen/data/gwas-causal.csv', dtype=dtypes)\n",
    "\n",
    "# Assert column names\n",
    "expected_columns = ['#chrom', 'pos', 'ref', 'alt', 'rsids', 'nearest_genes', 'pval', 'mlogp', 'beta',\n",
    "                    'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls', 'causal', 'LD', 'lead',\n",
    "                    'id', 'trait']\n",
    "assert set(data.columns) == set(expected_columns), \"Unexpected columns in the data DataFrame.\"\n",
    "\n",
    "# Assert data types\n",
    "expected_dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'string',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'causal': 'int64',\n",
    "    'LD': 'int64',\n",
    "    'lead': 'string',\n",
    "    'trait': 'string'\n",
    "}\n",
    "\n",
    "for col, expected_dtype in expected_dtypes.items():\n",
    "    assert data[col].dtype == expected_dtype, f\"Unexpected data type for column {col}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d6d595-4ef8-41d5-b0a5-dbdc9f2d9b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in each column:\n",
      "#chrom                    0\n",
      "pos                       0\n",
      "ref                       0\n",
      "alt                       0\n",
      "rsids               1366396\n",
      "nearest_genes        727855\n",
      "pval                      0\n",
      "mlogp                     0\n",
      "beta                      0\n",
      "sebeta                    0\n",
      "af_alt                    0\n",
      "af_alt_cases              0\n",
      "af_alt_controls           0\n",
      "causal                    0\n",
      "LD                        0\n",
      "id                        0\n",
      "lead               20168881\n",
      "trait                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for total number of null values in each column\n",
    "null_counts = data.isnull().sum()\n",
    "\n",
    "print(\"Total number of null values in each column:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a754a-7836-439e-801c-7efca6d2dfc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc4255-7a42-4172-a91d-4df08665fccc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create new rows per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b729972-b0d7-4e38-b8e2-aedd07506c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['nearest_genes'] = data['nearest_genes'].astype(str)\n",
    "\n",
    "# Assert column 'nearest_genes' is a string\n",
    "assert data['nearest_genes'].dtype == 'object', \"Column 'nearest_genes' is not of string type.\"\n",
    "\n",
    "# Split the gene names in the 'nearest_genes' column\n",
    "split_genes = data['nearest_genes'].str.split(',')\n",
    "\n",
    "# Flatten the list of split gene names\n",
    "flat_genes = [item for sublist in split_genes for item in sublist]\n",
    "\n",
    "# Create a new DataFrame by repeating rows and substituting the gene names\n",
    "data_new = data.loc[data.index.repeat(split_genes.str.len())].copy()\n",
    "data_new['nearest_genes'] = flat_genes\n",
    "\n",
    "# Assert the shape of the new DataFrame is as expected\n",
    "expected_shape = (len(flat_genes), data.shape[1])\n",
    "assert data_new.shape == expected_shape, \"Shape of the new DataFrame is not as expected.\"\n",
    "\n",
    "# Reset index to have a standard index\n",
    "data = data_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55024792-dddf-4ee4-9dbc-fbcf01ce0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eddaed-2f48-4440-b6d6-0dc247f23ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe89142-2b65-469b-b330-1620d303312b",
   "metadata": {},
   "source": [
    "### Required Data:\n",
    "\n",
    "- `id`: id of the variant in the following format: #chrom:pos:ref:alt.\n",
    "- `#chrom`: chromosome on build GRCh38 (1-23)\n",
    "- `pos`: position in base pairs on build GRCh38\n",
    "- `ref`: reference allele\n",
    "- `alt`: alternative allele (effect allele)\n",
    "- `nearest_genes`: nearest gene(s) (comma separated) from variant\n",
    "- `pval`: p-value\n",
    "- `mlogp`: -log10(p-value)\n",
    "- `beta`: effect size (log(OR) scale)\n",
    "- `sebeta`: standard error of effect size\n",
    "- `af_alt`: alternative (effect) allele frequency\n",
    "- `af_alt_cases`: alternative (effect) allele frequency among cases\n",
    "- `af_alt_controls`: alternative (effect) allele frequency among controls\n",
    "\n",
    "### Procedure:\n",
    "\n",
    "**1. Node Creation:** \n",
    "\n",
    "- Create a node for each variant in the dataset. \n",
    "- Label the node with the `id`, `#chrom`, and `pos` fields.\n",
    "\n",
    "**2. Edge Creation:** \n",
    "\n",
    "- For each pair of variants within 200,000 base pairs of each other on the same `#chrom`, create an edge.\n",
    "- The physical distance is calculated using the `pos` field.\n",
    "\n",
    "**3. Edge Weighting:** \n",
    "\n",
    "- `finalWeight = absDiffAltAlleleFreq / (1 + exp(-distance/decayConstant))`\n",
    "- Based on typical distances between SNPs in LD, a reasonable range for the decay constant could be from 10^4 to 10^6 base pairs. \n",
    "\n",
    "\n",
    "**4. Graph Refinement:** \n",
    "\n",
    "- Simplify the graph and emphasize important connections by removing any edge with a weight below a certain threshold.\n",
    "\n",
    "**5. Clustering:** \n",
    "\n",
    "- Apply the Louvain method for community detection on the graph. \n",
    "\n",
    "**6. Cluster Evaluation:** \n",
    "\n",
    "- For each cluster, calculate the average edge weight by summing all the edge weights in the cluster and dividing by the number of edges. \n",
    "- Calculate the average physical distance in a similar manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abe533-6610-4f82-b8d6-533eb010858d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "raw",
   "id": "862ff436-f1d1-4093-9ef5-8f89e211c894",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import community as community_louvain\n",
    "import itertools\n",
    "\n",
    "def preprocess_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"Preprocessing data...\")\n",
    "    assert isinstance(data, pd.DataFrame), \"Input data must be a pandas DataFrame\"\n",
    "    data = data.fillna({'nearest_genes': 'N/A', '#chrom': 'N/A', 'pos': 0, 'ref': 'N/A', 'alt': 'N/A',\n",
    "                        'beta': 0, 'sebeta': 0, 'af_alt': 0, 'af_alt_cases': 0, 'af_alt_controls': 0})\n",
    "    data['absDiffAltAlleleFreq'] = abs(data['af_alt_cases'] - data['af_alt_controls'])\n",
    "    print(\"Data preprocessing completed!\")\n",
    "    return data\n",
    "\n",
    "def create_networkx_graph(features: pd.DataFrame, decay_constant: float) -> nx.Graph:\n",
    "    print(\"Creating NetworkX graph...\")\n",
    "    assert isinstance(features, pd.DataFrame), \"Features must be a pandas DataFrame\"\n",
    "    assert isinstance(decay_constant, (int, float)), \"Decay constant must be a numeric value\"\n",
    "    \n",
    "    # Group data by chromosome\n",
    "    grouped = features.groupby('#chrom')\n",
    "    \n",
    "    edges = [(row1['id'], row2['id'], row1['absDiffAltAlleleFreq'] / (1 + expit(-abs(row1['pos'] - row2['pos'])/decay_constant))) \n",
    "             for chrom, chr_data in grouped \n",
    "             for i, row1 in chr_data.iterrows() \n",
    "             for j, row2 in chr_data[i+1:].iterrows() \n",
    "             if abs(row1['pos'] - row2['pos']) <= 500000]\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(pd.DataFrame(edges, columns=['source', 'target', 'weight']), edge_attr=True)\n",
    "    \n",
    "    # Assign 'pos' as a node attribute\n",
    "    pos_dict = features.set_index('id')['pos'].to_dict()\n",
    "    nx.set_node_attributes(G, pos_dict, 'pos')\n",
    "    \n",
    "    print(\"NetworkX graph creation completed!\")\n",
    "    return G\n",
    "\n",
    "\n",
    "def refine_graph(G: nx.Graph, weight_threshold: float) -> nx.Graph:\n",
    "    print(\"Refining the graph...\")\n",
    "    assert isinstance(G, nx.Graph), \"Input must be a NetworkX graph\"\n",
    "    assert isinstance(weight_threshold, (int, float)), \"Weight threshold must be a numeric value\"\n",
    "    \n",
    "    # Use a set comprehension for more efficient membership test\n",
    "    edges_to_remove = {(u, v) for u, v, data in G.edges(data=True) if data['weight'] < weight_threshold}\n",
    "    \n",
    "    G.remove_edges_from(edges_to_remove)\n",
    "    print(\"Graph refinement completed!\")\n",
    "    return G\n",
    "\n",
    "def apply_clustering(G: nx.Graph) -> dict:\n",
    "    print(\"Applying Louvain method for community detection...\")\n",
    "    assert isinstance(G, nx.Graph), \"Input must be a NetworkX graph\"\n",
    "    partition = community_louvain.best_partition(G, weight='weight')\n",
    "    print(\"Community detection completed!\")\n",
    "    return partition\n",
    "\n",
    "def evaluate_clusters(G: nx.Graph, partition: dict) -> pd.DataFrame:\n",
    "    print(\"Evaluating clusters...\")\n",
    "    assert isinstance(G, nx.Graph), \"Graph must be a NetworkX graph\"\n",
    "    assert isinstance(partition, dict), \"Partition must be a dictionary\"\n",
    "    \n",
    "    clusters = pd.DataFrame([(node, cluster_id) for node, cluster_id in partition.items()],\n",
    "                            columns=['node', 'cluster'])\n",
    "    cluster_stats = clusters.groupby('cluster')['node'].apply(list).apply(\n",
    "        lambda nodes: {'avg_weight': np.mean([G[u][v]['weight'] for u, v in itertools.combinations(nodes, 2) if G.has_edge(u, v)]) \n",
    "                       if any(G.has_edge(u, v) for u, v in itertools.combinations(nodes, 2)) else None,\n",
    "                       'avg_distance': np.mean([abs(G.nodes[u]['pos'] - G.nodes[v]['pos']) for u, v in itertools.combinations(nodes, 2) if G.has_edge(u, v)]) \n",
    "                       if any(G.has_edge(u, v) for u, v in itertools.combinations(nodes, 2)) else None}).apply(pd.Series)\n",
    "    print(\"Cluster evaluation completed!\")\n",
    "    return cluster_stats\n",
    "\n",
    "# Preprocess data\n",
    "data = preprocess_data(data)\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Step 1: Check the data\n",
    "print(\"Minimum pos difference in data:\", data['pos'].diff().abs().min())\n",
    "print(\"Maximum pos difference in data:\", data['pos'].diff().abs().max())\n",
    "\n",
    "# Step 2: Adjust the parameters\n",
    "decay_constant = 1e5  # adjust this\n",
    "weight_threshold = 0.001  # adjust this\n",
    "\n",
    "# Create graph\n",
    "G = create_networkx_graph(data, decay_constant=decay_constant)\n",
    "\n",
    "# Step 3: Check the output of your graph before the refinement step\n",
    "if not nx.is_empty(G):\n",
    "    print(\"Graph has\", G.number_of_edges(), \"edges before refinement.\")\n",
    "else:\n",
    "    warnings.warn(\"The graph has no edges before refinement.\")\n",
    "\n",
    "# Refine graph\n",
    "G = refine_graph(G, weight_threshold=weight_threshold)\n",
    "\n",
    "if not nx.is_empty(G):\n",
    "    print(\"Graph has\", G.number_of_edges(), \"edges after refinement.\")\n",
    "else:\n",
    "    warnings.warn(\"The graph has no edges after refinement.\")\n",
    "\n",
    "# Apply Louvain method for community detection\n",
    "partition = apply_clustering(G)\n",
    "\n",
    "if partition:\n",
    "    print(\"Partition created with\", len(set(partition.values())), \"clusters.\")\n",
    "else:\n",
    "    warnings.warn(\"No clusters were formed. Please check the input data and parameters.\")\n",
    "\n",
    "# Evaluate clusters\n",
    "cluster_stats = evaluate_clusters(G, partition)\n",
    "\n",
    "if cluster_stats.empty:\n",
    "    warnings.warn(\"Cluster statistics are empty. Please check the clustering results and graph properties.\")\n",
    "\n",
    "print(cluster_stats)\n",
    "\n",
    "# Check for NaN, null, or empty values in the final DataFrame\n",
    "print(\"Checking for NaN, null, or empty values in the final DataFrame...\")\n",
    "print(\"Total NaN or Null values in cluster_stats DataFrame:\")\n",
    "print(cluster_stats.isna().sum())\n",
    "print()\n",
    "print(\"Total Empty values in cluster_stats DataFrame:\")\n",
    "print(cluster_stats.eq('').sum())\n",
    "print(\"Check completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab8d7f2-4a15-472e-8135-512b4c1fd2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Data preprocessing completed!\n",
      "Minimum pos difference in data: 27.0\n",
      "Maximum pos difference in data: 248430921.0\n",
      "Creating Networkit graph...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m decay_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e5\u001b[39m  \u001b[38;5;66;03m# adjust this\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Create graph\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m G, pos_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_networkit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecay_constant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Apply PLM method for community detection\u001b[39;00m\n\u001b[0;32m     82\u001b[0m partition \u001b[38;5;241m=\u001b[39m apply_clustering(G)\n",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m, in \u001b[0;36mcreate_networkit_graph\u001b[1;34m(features, decay_constant)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chrom, chr_data \u001b[38;5;129;01min\u001b[39;00m grouped:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, row1 \u001b[38;5;129;01min\u001b[39;00m chr_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j, row2 \u001b[38;5;129;01min\u001b[39;00m chr_data[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     37\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(row1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m row2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500000\u001b[39m:\n\u001b[0;32m     38\u001b[0m                 weight \u001b[38;5;241m=\u001b[39m row1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabsDiffAltAlleleFreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m expit(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mabs\u001b[39m(row1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m row2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m/\u001b[39mdecay_constant))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:1400\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1398\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m-> 1400\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[0;32m   1402\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:511\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    509\u001b[0m     data \u001b[38;5;241m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m--> 511\u001b[0m     manager \u001b[38;5;241m=\u001b[39m \u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode.data_manager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    513\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleBlockManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:261\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:135\u001b[0m, in \u001b[0;36m_get_option\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_option\u001b[39m(pat: \u001b[38;5;28mstr\u001b[39m, silent: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 135\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     root, k \u001b[38;5;241m=\u001b[39m _get_root(key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:127\u001b[0m, in \u001b[0;36m_get_single_key\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    124\u001b[0m key \u001b[38;5;241m=\u001b[39m keys[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[1;32m--> 127\u001b[0m     \u001b[43m_warn_if_deprecated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m key \u001b[38;5;241m=\u001b[39m _translate_key(key)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:657\u001b[0m, in \u001b[0;36m_warn_if_deprecated\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_warn_if_deprecated\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    650\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;124;03m    Checks if `key` is a deprecated option and if so, prints a warning.\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;124;03m    bool - True if `key` is deprecated, False otherwise.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43m_get_deprecated_option\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m d:\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m.\u001b[39mmsg:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:610\u001b[0m, in \u001b[0;36m_get_deprecated_option\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    606\u001b[0m     key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m _deprecated_options\n\u001b[1;32m--> 610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_deprecated_option\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    611\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03m    Retrieves the metadata for a deprecated option, if `key` is deprecated.\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;124;03m    DeprecatedOption (namedtuple) if key is deprecated, None otherwise\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkit as nk\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import community as community_louvain\n",
    "import itertools\n",
    "\n",
    "def preprocess_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"Preprocessing data...\")\n",
    "    assert isinstance(data, pd.DataFrame), \"Input data must be a pandas DataFrame\"\n",
    "    data = data.fillna({'nearest_genes': 'N/A', '#chrom': 'N/A', 'pos': 0, 'ref': 'N/A', 'alt': 'N/A',\n",
    "                        'beta': 0, 'sebeta': 0, 'af_alt': 0, 'af_alt_cases': 0, 'af_alt_controls': 0})\n",
    "    data['absDiffAltAlleleFreq'] = abs(data['af_alt_cases'] - data['af_alt_controls'])\n",
    "    print(\"Data preprocessing completed!\")\n",
    "    return data\n",
    "\n",
    "def create_networkit_graph(features: pd.DataFrame, decay_constant: float) -> nk.Graph:\n",
    "    print(\"Creating Networkit graph...\")\n",
    "    assert isinstance(features, pd.DataFrame), \"Features must be a pandas DataFrame\"\n",
    "    assert isinstance(decay_constant, (int, float)), \"Decay constant must be a numeric value\"\n",
    "    \n",
    "    # Group data by chromosome\n",
    "    grouped = features.groupby('#chrom')\n",
    "\n",
    "    # Initialize an undirected graph with number of nodes equal to the length of the features dataframe\n",
    "    G = nk.Graph(len(features), weighted=True)\n",
    "\n",
    "    # A dictionary to store the position of each node\n",
    "    pos_dict = {}\n",
    "\n",
    "    for index, row in features.iterrows():\n",
    "        pos_dict[index] = row['pos']\n",
    "\n",
    "    for chrom, chr_data in grouped:\n",
    "        for i, row1 in chr_data.iterrows():\n",
    "            for j, row2 in chr_data[i+1:].iterrows():\n",
    "                if abs(row1['pos'] - row2['pos']) <= 500000:\n",
    "                    weight = row1['absDiffAltAlleleFreq'] / (1 + expit(-abs(row1['pos'] - row2['pos'])/decay_constant))\n",
    "                    G.addEdge(i, j, weight)\n",
    "                    \n",
    "    print(\"Networkit graph creation completed!\")\n",
    "    return G, pos_dict\n",
    "\n",
    "def apply_clustering(G: nk.Graph) -> nk.community.PLM:\n",
    "    print(\"Applying PLM method for community detection...\")\n",
    "    assert isinstance(G, nk.Graph), \"Input must be a Networkit graph\"\n",
    "    plm = nk.community.PLM(G, True)\n",
    "    plm.run()\n",
    "    print(\"Community detection completed!\")\n",
    "    return plm.getPartition()\n",
    "\n",
    "def evaluate_clusters(G: nk.Graph, partition: nk.community.PLM, pos_dict: dict) -> pd.DataFrame:\n",
    "    print(\"Evaluating clusters...\")\n",
    "    assert isinstance(G, nk.Graph), \"Graph must be a Networkit graph\"\n",
    "    assert isinstance(partition, nk.community.PLM), \"Partition must be a PLM object\"\n",
    "    \n",
    "    clusters = pd.DataFrame([(node, cluster_id) for node, cluster_id in enumerate(partition)], columns=['node', 'cluster'])\n",
    "    cluster_stats = clusters.groupby('cluster')['node'].apply(list).apply(\n",
    "        lambda nodes: {'avg_weight': np.mean([G.weight(u, v) for u, v in itertools.combinations(nodes, 2) if G.hasEdge(u, v)]) \n",
    "                       if any(G.hasEdge(u, v) for u, v in itertools.combinations(nodes, 2)) else None,\n",
    "                       'avg_distance': np.mean([abs(pos_dict[u] - pos_dict[v]) for u, v in itertools.combinations(nodes, 2) if G.hasEdge(u, v)]) \n",
    "                       if any(G.hasEdge(u, v) for u, v in itertools.combinations(nodes, 2)) else None}).apply(pd.Series)\n",
    "    print(\"Cluster evaluation completed!\")\n",
    "    return cluster_stats\n",
    "\n",
    "# Preprocess data\n",
    "data = preprocess_data(data)\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Step 1: Check the data\n",
    "print(\"Minimum pos difference in data:\", data['pos'].diff().abs().min())\n",
    "print(\"Maximum pos difference in data:\", data['pos'].diff().abs().max())\n",
    "\n",
    "# Step 2: Adjust the parameters\n",
    "decay_constant = 1e5  # adjust this\n",
    "\n",
    "# Create graph\n",
    "G, pos_dict = create_networkit_graph(data, decay_constant=decay_constant)\n",
    "\n",
    "# Apply PLM method for community detection\n",
    "partition = apply_clustering(G)\n",
    "\n",
    "if partition.numberOfSubsets() > 0:\n",
    "    print(\"Partition created with\", partition.numberOfSubsets(), \"clusters.\")\n",
    "else:\n",
    "    warnings.warn(\"No clusters were formed. Please check the input data and parameters.\")\n",
    "\n",
    "# Evaluate clusters\n",
    "cluster_stats = evaluate_clusters(G, partition, pos_dict)\n",
    "\n",
    "if cluster_stats.empty:\n",
    "    warnings.warn(\"Cluster statistics are empty. Please check the clustering results and graph properties.\")\n",
    "\n",
    "print(cluster_stats)\n",
    "\n",
    "# Check for NaN, null, or empty values in the final DataFrame\n",
    "print(\"Checking for NaN, null, or empty values in the final DataFrame...\")\n",
    "print(\"Total NaN or Null values in cluster_stats DataFrame:\")\n",
    "print(cluster_stats.isna().sum())\n",
    "print()\n",
    "print(\"Total Empty values in cluster_stats DataFrame:\")\n",
    "print(cluster_stats.eq('').sum())\n",
    "print(\"Check completed!\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7540f41c-e985-4788-b725-2a581e811c43",
   "metadata": {
    "tags": []
   },
   "source": [
    "def get_graph_statistics(G: nx.Graph) -> None:\n",
    "    \"\"\"\n",
    "    Function to compute and print various graph statistics.\n",
    "    \"\"\"\n",
    "    assert isinstance(G, nx.Graph), \"G must be a NetworkX graph.\"\n",
    "\n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "\n",
    "    degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
    "    print(f\"Degree sequence: {degree_sequence}\")\n",
    "    \n",
    "    density = nx.density(G)\n",
    "    print(f\"Network density: {density}\")\n",
    "\n",
    "    if nx.is_connected(G):\n",
    "        avg_shortest_path_length = nx.average_shortest_path_length(G)\n",
    "        print(f\"Average shortest path length: {avg_shortest_path_length}\")\n",
    "    else:\n",
    "        print(\"Graph is not connected.\")\n",
    "\n",
    "    transitivity = nx.transitivity(G)\n",
    "    print(f\"Transitivity: {transitivity}\")\n",
    "\n",
    "    clustering_coefficient = nx.average_clustering(G)\n",
    "    print(f\"Average clustering coefficient: {clustering_coefficient}\")\n",
    "    \n",
    "    if G.number_of_nodes() > 0:\n",
    "        diameter = nx.diameter(G)\n",
    "        print(f\"Diameter: {diameter}\")\n",
    "    else:\n",
    "        print(\"Graph has no nodes.\")\n",
    "    \n",
    "    connected_components = nx.number_connected_components(G)\n",
    "    print(f\"Number of connected components: {connected_components}\")\n",
    "\n",
    "get_graph_statistics(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed52e8-1999-4bc8-ba01-1ed8a9a9ed56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_graph(graph, chromosome: str):\n",
    "    plt.figure(figsize=(25, 25))  # Increase figure size for better visibility\n",
    "    \n",
    "    # Create a subgraph for the specified chromosome\n",
    "    nodes_chromosome = [node for node, attr in graph.nodes(data=True) if attr.get('#chrom') == chromosome]\n",
    "    subgraph = graph.subgraph(nodes_chromosome)\n",
    "\n",
    "    if subgraph.number_of_nodes() == 0:\n",
    "        print(f\"No nodes found for chromosome {chromosome}.\")\n",
    "        return\n",
    "\n",
    "    # Get a list of unique chromosomes in the subgraph\n",
    "    chroms = list(set(nx.get_node_attributes(subgraph, '#chrom').values()))\n",
    "    # Assign each chromosome a color\n",
    "    colormap = plt.cm.tab20\n",
    "    \n",
    "    # Get node colors\n",
    "    node_colors = [colormap(chroms.index(subgraph.nodes[node]['#chrom'])) for node in subgraph.nodes]\n",
    "\n",
    "    pos = nx.spring_layout(subgraph, k=0.25)  \n",
    "    nx.draw(subgraph, pos, with_labels=True, node_color=node_colors, node_size=20, \n",
    "            font_size=8, edge_color='gray')  \n",
    "    \n",
    "    edge_labels = nx.get_edge_attributes(subgraph, 'label')\n",
    "    nx.draw_networkx_edge_labels(subgraph, pos, edge_labels=edge_labels, font_size=8)  \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# To visualize a specific chromosome, pass the chromosome number as a string. For example:\n",
    "visualize_graph(graph, \"23\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
