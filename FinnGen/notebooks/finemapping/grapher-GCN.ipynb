{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00910a35-ffbc-4497-bcc8-21f008c326fb",
   "metadata": {},
   "source": [
    "# Grapher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1805a-55dc-409c-9ccf-512eb1f88667",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8ec1d-73be-4b8c-95dc-79489e84998b",
   "metadata": {},
   "source": [
    "- `id`: This column represents the id of the variant in the following format: #chrom:pos:ref:alt (string).\n",
    "\n",
    "- `#chrom`: This column represents the chromosome number where the genetic variant is located.\n",
    "\n",
    "- `pos`: This is the position of the genetic variant on the chromosome.\n",
    "\n",
    "- `ref`: This column represents the reference allele (or variant) at the genomic position.\n",
    "\n",
    "- `alt`: This is the alternate allele observed at this position.\n",
    "\n",
    "- `rsids`: This stands for reference SNP cluster ID. It's a unique identifier for each variant used in the dbSNP database.\n",
    "\n",
    "- `nearest_genes`: This column represents the gene which is nearest to the variant.\n",
    "\n",
    "- `pval`: This represents the p-value, which is a statistical measure for the strength of evidence against the null hypothesis.\n",
    "\n",
    "- `mlogp`: This represents the minus log of the p-value, commonly used in genomic studies.\n",
    "\n",
    "- `beta`: The beta coefficient represents the effect size of the variant.\n",
    "\n",
    "- `sebeta`: This is the standard error of the beta coefficient.\n",
    "\n",
    "- `af_alt`: This is the allele frequency of the alternate variant in the general population.\n",
    "\n",
    "- `af_alt_cases`: This is the allele frequency of the alternate variant in the cases group.\n",
    "\n",
    "- `af_alt_controls`: This is the allele frequency of the alternate variant in the control group.\n",
    "\n",
    "- `finemapped`: This column represents whether the variant is included in the post-finemapped dataset (1) or not (0). \n",
    "\n",
    "- `trait`: This column represents the trait associated with the variant. In this dataset, it is the response to the drug paracetamol and NSAIDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b033d-95f5-4584-b10c-72969a166612",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4345459-b1ef-477c-8f06-c8f54c194af0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]\n",
      "NumPy version: 1.24.3\n",
      "Pandas version: 2.0.1\n",
      "Matplotlib version: 3.7.1\n",
      "Scikit-learn version: 1.2.2\n",
      "Torch version: 2.0.0+cu118\n",
      "Torch Geometric version: 2.3.1\n",
      "NetworkX version: 3.0\n",
      "Using NVIDIA GeForce RTX 3060 Ti (cuda)\n",
      "CUDA version: 11.8\n",
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from numba import jit, prange\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "import networkx as nx\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.special import expit\n",
    "from typing import List, Dict\n",
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "\n",
    "# Print versions of imported libraries\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Torch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddfa8cb-01df-491f-94f0-c8c228256b4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fe5b06-7392-4d62-a1e8-af081cdf3e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'string',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'finemapped': 'int64'\n",
    "}\n",
    "\n",
    "data = pd.read_csv('~/Desktop/gwas-graph/FinnGen/data/gwas-finemap.csv', dtype=dtypes)\n",
    "\n",
    "# Assert column names\n",
    "expected_columns = ['#chrom', 'pos', 'ref', 'alt', 'rsids', 'nearest_genes', 'pval', 'mlogp', 'beta',\n",
    "                    'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls', 'finemapped',\n",
    "                    'id', 'trait']\n",
    "assert set(data.columns) == set(expected_columns), \"Unexpected columns in the data DataFrame.\"\n",
    "\n",
    "# Assert data types\n",
    "expected_dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'string',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'finemapped': 'int64'\n",
    "}\n",
    "\n",
    "for col, expected_dtype in expected_dtypes.items():\n",
    "    assert data[col].dtype == expected_dtype, f\"Unexpected data type for column {col}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d6d595-4ef8-41d5-b0a5-dbdc9f2d9b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in each column:\n",
      "#chrom                   0\n",
      "pos                      0\n",
      "ref                      0\n",
      "alt                      0\n",
      "rsids              1366396\n",
      "nearest_genes       727855\n",
      "pval                     0\n",
      "mlogp                    0\n",
      "beta                     0\n",
      "sebeta                   0\n",
      "af_alt                   0\n",
      "af_alt_cases             0\n",
      "af_alt_controls          0\n",
      "id                       0\n",
      "finemapped               0\n",
      "trait                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for total number of null values in each column\n",
    "null_counts = data.isnull().sum()\n",
    "\n",
    "print(\"Total number of null values in each column:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a754a-7836-439e-801c-7efca6d2dfc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc4255-7a42-4172-a91d-4df08665fccc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create new rows per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b729972-b0d7-4e38-b8e2-aedd07506c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['nearest_genes'] = data['nearest_genes'].astype(str)\n",
    "\n",
    "# Assert column 'nearest_genes' is a string\n",
    "assert data['nearest_genes'].dtype == 'object', \"Column 'nearest_genes' is not of string type.\"\n",
    "\n",
    "# Split the gene names in the 'nearest_genes' column\n",
    "split_genes = data['nearest_genes'].str.split(',')\n",
    "\n",
    "# Flatten the list of split gene names\n",
    "flat_genes = [item for sublist in split_genes for item in sublist]\n",
    "\n",
    "# Create a new DataFrame by repeating rows and substituting the gene names\n",
    "data_new = data.loc[data.index.repeat(split_genes.str.len())].copy()\n",
    "data_new['nearest_genes'] = flat_genes\n",
    "\n",
    "# Assert the shape of the new DataFrame is as expected\n",
    "expected_shape = (len(flat_genes), data.shape[1])\n",
    "assert data_new.shape == expected_shape, \"Shape of the new DataFrame is not as expected.\"\n",
    "\n",
    "# Reset index to have a standard index\n",
    "data = data_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513cafa0-f3f8-47b5-9d22-96062449edde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eddaed-2f48-4440-b6d6-0dc247f23ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe89142-2b65-469b-b330-1620d303312b",
   "metadata": {},
   "source": [
    "`data` df:\n",
    "\n",
    "- `id`: This column represents the id of the variant in the following format: #chrom:pos:ref:alt (string).\n",
    "\n",
    "- `#chrom`: This column represents the chromosome number where the genetic variant is located.\n",
    "\n",
    "- `pos`: This is the position of the genetic variant on the chromosome.\n",
    "\n",
    "- `ref`: This column represents the reference allele (or variant) at the genomic position.\n",
    "\n",
    "- `alt`: This is the alternate allele observed at this position.\n",
    "\n",
    "- `rsids`: This stands for reference SNP cluster ID. It's a unique identifier for each variant used in the dbSNP database.\n",
    "\n",
    "- `nearest_genes`: This column represents the gene which is nearest to the variant.\n",
    "\n",
    "- `pval`: This represents the p-value, which is a statistical measure for the strength of evidence against the null hypothesis.\n",
    "\n",
    "- `mlogp`: This represents the minus log of the p-value, commonly used in genomic studies.\n",
    "\n",
    "- `beta`: The beta coefficient represents the effect size of the variant.\n",
    "\n",
    "- `sebeta`: This is the standard error of the beta coefficient.\n",
    "\n",
    "- `af_alt`: This is the allele frequency of the alternate variant in the general population.\n",
    "\n",
    "- `af_alt_cases`: This is the allele frequency of the alternate variant in the cases group.\n",
    "\n",
    "- `af_alt_controls`: This is the allele frequency of the alternate variant in the control group.\n",
    "\n",
    "- `finemapped`: This column represents whether the variant is included in the post-finemapped dataset (1) or not (0). \n",
    "\n",
    "- `trait`: This column represents the trait associated with the variant. In this dataset, it is the response to the drug paracetamol and NSAIDs.\n",
    "\n",
    "**Task Overview**\n",
    "- The objective is to design and implement a binary node classification GNN model to predict whether variants are included after post-finemapping or not.\n",
    "\n",
    "**Nodes and Their Features**\n",
    "- There is one types of node: SNP nodes.\n",
    "- *SNP Nodes*: Each SNP Node is characterized by various features, including `id`, `nearest_genes`, `#chrom`, `pos`, `ref`, `alt`, `beta`, `sebeta`, `finemapped`, `af_alt`, and `af_alt_cases` columns. \n",
    "\n",
    "**Edges, Their Features, and Labels**\n",
    "- Edges represent relationships between SNP nodes. The edges in this graph are created based on the proximity of SNPs on a chromosome.\n",
    "- Specifically, for each pair of SNPs (row1 and row2) that exist on the same chromosome (#chrom), an edge is created if the absolute difference between their positions (pos) is less than or equal to 200,000.\n",
    "- The weight of an edge is determined by a function of the absolute difference in the alternate allele frequency (absDiffAltAlleleFreq) and the absolute difference in position (pos) between the two SNPs. Specifically, the weight is given by:\n",
    "\n",
    "- `weight = row1['absDiffAltAlleleFreq'] / (1 + expit(-abs(row1['pos'] - row2['pos'])/decay_constant))`where expit is the logistic sigmoid function, and decay_constant is a parameter that controls the rate at which the weight decays with increasing difference in position. The absDiffAltAlleleFreq is calculated by taking the absolute difference between af_alt of the two SNPs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abe533-6610-4f82-b8d6-533eb010858d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0a2540-a59c-4869-a2f2-f2f93c3e4ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 20566\n",
      "Number of edges: 31243\n",
      "Node feature dimension: 9\n",
      "Execution time: 181.7657985687256 seconds\n",
      "         104269693 function calls (102256695 primitive calls) in 181.764 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 970 to 5 due to restriction <5>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       14    0.000    0.000  181.763   12.983 C:\\Users\\falty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3472(run_code)\n",
      "       14    0.000    0.000  181.763   12.983 {built-in method builtins.exec}\n",
      "        1    0.002    0.002  181.630  181.630 C:\\Users\\falty\\AppData\\Local\\Temp\\ipykernel_18580\\1596713975.py:1(<module>)\n",
      "        1    1.039    1.039  181.628  181.628 C:\\Users\\falty\\AppData\\Local\\Temp\\ipykernel_18580\\1596713975.py:39(preprocess_positive_edges)\n",
      "    20567    4.946    0.000  130.980    0.006 C:\\Users\\falty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4314(map)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "from scipy.special import expit\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "decay_constant = 1e5  # Define decay constant as per your requirements\n",
    "\n",
    "def get_unique_snps(data: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Function to create mappings for SNPs to integer indices.\n",
    "    \"\"\"\n",
    "    return {snp: idx for idx, snp in enumerate(data['id'].unique())}\n",
    "\n",
    "def preprocess_snp_features(data: pd.DataFrame, snp_to_idx: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to create node feature vectors for SNPs and preprocess categorical and numerical features.\n",
    "    \"\"\"\n",
    "    snp_features = data.loc[data['id'].isin(snp_to_idx.keys()), ['id', 'nearest_genes', '#chrom', 'pos', 'ref', 'alt', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']].set_index('id').sort_index()\n",
    "    le = LabelEncoder()\n",
    "    scaler = StandardScaler()\n",
    "    for col in snp_features.columns:\n",
    "        if col in ['ref', 'alt', 'nearest_genes', '#chrom']:\n",
    "            snp_features[col] = le.fit_transform(snp_features[col].astype(str))\n",
    "        else:\n",
    "            snp_features[col] = pd.Series(scaler.fit_transform(snp_features[col].to_frame()).flatten())\n",
    "\n",
    "    snp_features.loc[:, 'nearest_genes'] = snp_features['nearest_genes'].fillna('N/A')\n",
    "    snp_features.loc[:, '#chrom'] = snp_features['#chrom'].fillna('N/A')\n",
    "    snp_features[['pos', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']] = snp_features[['pos', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']].fillna(0)\n",
    "    snp_features.loc[:, ['ref', 'alt']] = snp_features[['ref', 'alt']].fillna('N/A')\n",
    "\n",
    "    return snp_features\n",
    "\n",
    "def preprocess_positive_edges(data: pd.DataFrame, snp_to_idx: dict) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Function to create positive SNP-SNP edges and preprocess them.\n",
    "    \"\"\"\n",
    "    positive_edges_snp_snp = []\n",
    "    snp_weights = []\n",
    "\n",
    "    for _, group in data.groupby('#chrom'):\n",
    "        sorted_group = group.sort_values(by='pos')\n",
    "        for idx, row in sorted_group.iterrows():\n",
    "            pos_diff = sorted_group['pos'] - row['pos']\n",
    "            mask = (pos_diff > 0) & (pos_diff <= 200000)\n",
    "            filtered_group = sorted_group[mask]\n",
    "\n",
    "            ids = filtered_group['id'].map(snp_to_idx)\n",
    "            af_alt_diff = abs(row['af_alt'] - filtered_group['af_alt'])\n",
    "            pos_diff_abs = abs(row['pos'] - filtered_group['pos'])\n",
    "\n",
    "            weights = af_alt_diff / (1 + expit(-pos_diff_abs / decay_constant))\n",
    "\n",
    "            positive_edges_snp_snp.extend(zip([snp_to_idx[row['id']]] * len(ids), ids))\n",
    "            snp_weights.extend(weights)\n",
    "\n",
    "    return torch.tensor(positive_edges_snp_snp, dtype=torch.long).t().contiguous(), torch.tensor(snp_weights, dtype=torch.float)\n",
    "\n",
    "def create_pytorch_graph(features: torch.Tensor, edges: torch.Tensor, edge_weights: torch.Tensor) -> Data:\n",
    "    \"\"\"\n",
    "    Function to create the PyTorch Geometric graph.\n",
    "    \"\"\"\n",
    "    return Data(x=features, edge_index=edges, edge_attr=edge_weights)\n",
    "\n",
    "# Add profiling\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "snp_to_idx = get_unique_snps(data)\n",
    "\n",
    "labels = data['finemapped'].map(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "snp_features = preprocess_snp_features(data, snp_to_idx)\n",
    "features = torch.tensor(snp_features.values, dtype=torch.float)\n",
    "\n",
    "positive_edges_snp_snp, edge_weights = preprocess_positive_edges(data, snp_to_idx)\n",
    "graph = create_pytorch_graph(features, positive_edges_snp_snp, edge_weights)\n",
    "\n",
    "# Set labels here after creating the graph\n",
    "graph.y = torch.tensor(labels.values, dtype=torch.long)\n",
    "\n",
    "print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "print(f\"Number of edges: {graph.num_edges}\")\n",
    "print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")\n",
    "\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "sortby = 'cumulative'\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats(5)  # Only print the top 5 lines\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bba9103-b4af-4311-9bd8-033e04770339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PyTorch Geometric graph\n",
    "#torch.save(graph, \"pytorch_geometric_graph.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4462c-4130-4242-9a7d-09c6ed71b613",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c98f83-a35d-4010-8adf-078fd4fbe799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph stats:\n",
      "Number of nodes: 20566\n",
      "Number of positive SNP-SNP edges: 31243\n",
      "Number of edges: 31243\n",
      "Node feature dimension: 9\n",
      "Average Degree: 1.519157886505127\n",
      "Median Degree: 1.0\n",
      "Standard Deviation of Degree: 1.329643964767456\n",
      "Density: 0.0001477421\n",
      "Features with NaN values:\n",
      "[]\n",
      "Edge weight stats:\n",
      "Number of edges: 31243\n",
      "Average edge weight: 0.14570282399654388\n",
      "Median edge weight: 0.0459057055413723\n",
      "Standard deviation of edge weights: 0.1975155621767044\n",
      "Maximum edge weight: 0.8884702324867249\n",
      "Minimum edge weight: 0.0\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree\n",
    "\n",
    "def print_graph_stats(graph, positive_edges_snp_snp, features_list):\n",
    "    print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "    print(f\"Number of positive SNP-SNP edges: {positive_edges_snp_snp.size(1)}\")\n",
    "    print(f\"Number of edges: {graph.num_edges}\")\n",
    "    print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "\n",
    "    # Compute and print degree-related stats\n",
    "    degrees = degree(graph.edge_index[0].long(), num_nodes=graph.num_nodes)\n",
    "    average_degree = degrees.float().mean().item()\n",
    "    median_degree = np.median(degrees.numpy())\n",
    "    std_degree = degrees.float().std().item()\n",
    "\n",
    "    print(f\"Average Degree: {average_degree}\")\n",
    "    print(f\"Median Degree: {median_degree}\")\n",
    "    print(f\"Standard Deviation of Degree: {std_degree}\")\n",
    "\n",
    "    # Density is the ratio of actual edges to the maximum number of possible edges\n",
    "    num_possible_edges = graph.num_nodes * (graph.num_nodes - 1) / 2\n",
    "    density = graph.num_edges / num_possible_edges\n",
    "\n",
    "    print(f\"Density: {density:.10f}\")\n",
    "\n",
    "    # Check for NaN values in features\n",
    "    nan_mask = torch.isnan(graph.x)\n",
    "    nan_features = []\n",
    "    for feature_idx, feature_name in enumerate(features_list):\n",
    "        if nan_mask[:, feature_idx].any():\n",
    "            nan_features.append(feature_name)\n",
    "\n",
    "    print(\"Features with NaN values:\")\n",
    "    print(nan_features)\n",
    "\n",
    "def print_edge_weight_stats(edge_weights):\n",
    "    print(f\"Number of edges: {edge_weights.size(0)}\")\n",
    "    print(f\"Average edge weight: {edge_weights.float().mean().item()}\")\n",
    "    print(f\"Median edge weight: {np.median(edge_weights.numpy())}\")\n",
    "    print(f\"Standard deviation of edge weights: {edge_weights.float().std().item()}\")\n",
    "    print(f\"Maximum edge weight: {edge_weights.max().item()}\")\n",
    "    print(f\"Minimum edge weight: {edge_weights.min().item()}\")\n",
    "\n",
    "# Print graph stats\n",
    "print(\"Graph stats:\")\n",
    "print_graph_stats(graph, positive_edges_snp_snp, snp_features.columns)\n",
    "\n",
    "print(\"Edge weight stats:\")\n",
    "print_edge_weight_stats(graph.edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51e96d-660c-4b4f-8ac4-9a07dba5bcc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79fb79d-4729-4d4d-8dff-229108b6cac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train nodes: 2000\n",
      "Validation nodes: 4113\n",
      "Test nodes: 4113\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "transform = RandomNodeSplit(split=\"random\", num_train_per_class=1000, num_val=0.2, num_test=0.2, key='y')\n",
    "graph = transform(graph)\n",
    "\n",
    "print(f\"Train nodes: {graph.train_mask.sum().item()}\")\n",
    "print(f\"Validation nodes: {graph.val_mask.sum().item()}\")\n",
    "print(f\"Test nodes: {graph.test_mask.sum().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665050a-5cd9-4960-a2ef-8a4cf2cb5e40",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2557f-d84e-4a1b-bda8-7b26620f526b",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "555e09d5-089e-4d51-85de-25cbe30656f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 45.8633766174, Train Acc: 0.4995000000, Val Acc: 0.8653051301, Test Acc: 0.8743009968\n",
      "Epoch: 2, Loss: 47.1373519897, Train Acc: 0.4975000000, Val Acc: 0.8584974471, Test Acc: 0.8672501823\n",
      "Epoch: 3, Loss: 44.6423950195, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 4, Loss: 46.7130393982, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 5, Loss: 48.3965263367, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 6, Loss: 49.7029418945, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 7, Loss: 50.1112785339, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 8, Loss: 49.8173828125, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 9, Loss: 50.0652313232, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 10, Loss: 49.9016990662, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 11, Loss: 49.9516830444, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 12, Loss: 49.8612976074, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 13, Loss: 49.8676681519, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 14, Loss: 49.9555053711, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 15, Loss: 49.8583984375, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 16, Loss: 49.9163398743, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 17, Loss: 49.9101333618, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 18, Loss: 49.9565048218, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 19, Loss: 50.0000000000, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 20, Loss: 49.8557395935, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 21, Loss: 50.0000000000, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 22, Loss: 49.9500007629, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 23, Loss: 49.9500045776, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 24, Loss: 49.9571456909, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 25, Loss: 49.9579620361, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 26, Loss: 50.0000000000, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 27, Loss: 49.7590904236, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 28, Loss: 49.9065132141, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 29, Loss: 49.9104080200, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 30, Loss: 49.9127693176, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 31, Loss: 49.9708137512, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 32, Loss: 49.8087577820, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 33, Loss: 49.9555168152, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 34, Loss: 49.8573608398, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 35, Loss: 49.9000015259, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 36, Loss: 50.0039443970, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 37, Loss: 49.6579704285, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 38, Loss: 49.7603607178, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 39, Loss: 49.9812698364, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 40, Loss: 49.8645668030, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 41, Loss: 49.9067573547, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 42, Loss: 49.9175834656, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 43, Loss: 49.9000015259, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 44, Loss: 49.7781715393, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 45, Loss: 49.8570175171, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 46, Loss: 49.9000053406, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 47, Loss: 49.9745330811, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 48, Loss: 49.9962844849, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 49, Loss: 49.9680938721, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 50, Loss: 49.9051094055, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 51, Loss: 49.9000053406, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 52, Loss: 49.8574218750, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 53, Loss: 49.9581947327, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 54, Loss: 50.0000000000, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 55, Loss: 49.8061103821, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 56, Loss: 49.9841270447, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 57, Loss: 50.0000076294, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 58, Loss: 49.9251518250, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 59, Loss: 49.8595046997, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 60, Loss: 49.9500007629, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 61, Loss: 49.9500083923, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 62, Loss: 49.9500007629, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 63, Loss: 49.9136276245, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 64, Loss: 49.9500007629, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 65, Loss: 49.9000015259, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 66, Loss: 49.9500007629, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 67, Loss: 49.8545188904, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 68, Loss: 49.8045539856, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 69, Loss: 49.7521705627, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 70, Loss: 49.9140701294, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 71, Loss: 49.8604393005, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 72, Loss: 49.7123451233, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 73, Loss: 49.8263320923, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 74, Loss: 49.7520217896, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 75, Loss: 49.7550315857, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 76, Loss: 49.8184165955, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 77, Loss: 49.7608261108, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 78, Loss: 49.8569946289, Train Acc: 0.5000000000, Val Acc: 0.1232676878, Test Acc: 0.1184050571\n",
      "Epoch: 79, Loss: 49.7832946777, Train Acc: 0.5015000000, Val Acc: 0.1235108194, Test Acc: 0.1186481887\n",
      "Epoch: 80, Loss: 49.7376670837, Train Acc: 0.5020000000, Val Acc: 0.1244833455, Test Acc: 0.1188913202\n",
      "Epoch: 81, Loss: 49.7633438110, Train Acc: 0.5025000000, Val Acc: 0.1244833455, Test Acc: 0.1188913202\n",
      "Epoch: 82, Loss: 49.7549057007, Train Acc: 0.5030000000, Val Acc: 0.1264283978, Test Acc: 0.1213226355\n",
      "Epoch: 83, Loss: 49.7553138733, Train Acc: 0.5030000000, Val Acc: 0.1264283978, Test Acc: 0.1213226355\n",
      "Epoch: 84, Loss: 49.8800392151, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1218088986\n",
      "Epoch: 85, Loss: 49.6243858337, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1218088986\n",
      "Epoch: 86, Loss: 49.6620597839, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1218088986\n",
      "Epoch: 87, Loss: 49.6825904846, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1218088986\n",
      "Epoch: 88, Loss: 49.6596984863, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 89, Loss: 49.6300506592, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 90, Loss: 49.6105155945, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 91, Loss: 49.6141815186, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 92, Loss: 49.7105598450, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 93, Loss: 49.6763038635, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 94, Loss: 49.6649818420, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 95, Loss: 49.6192092896, Train Acc: 0.5030000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 96, Loss: 49.7122077942, Train Acc: 0.5030000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 97, Loss: 49.7796134949, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 98, Loss: 49.7112197876, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 99, Loss: 49.6503753662, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 100, Loss: 49.5789146423, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 101, Loss: 49.6128578186, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 102, Loss: 49.7159919739, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 103, Loss: 49.7864265442, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 104, Loss: 49.5583419800, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 105, Loss: 49.6441459656, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 106, Loss: 49.6526718140, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 107, Loss: 49.5750732422, Train Acc: 0.5035000000, Val Acc: 0.1274009239, Test Acc: 0.1222951617\n",
      "Epoch: 108, Loss: 49.5659866333, Train Acc: 0.5035000000, Val Acc: 0.1274009239, Test Acc: 0.1222951617\n",
      "Epoch: 109, Loss: 49.5955810547, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 110, Loss: 49.7627334595, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 111, Loss: 49.7393302917, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 112, Loss: 49.6446533203, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 113, Loss: 49.5589752197, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 114, Loss: 49.5179786682, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 115, Loss: 49.5380020142, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 116, Loss: 49.5798721313, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 117, Loss: 49.6943626404, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1222951617\n",
      "Epoch: 118, Loss: 49.5783348083, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1227814248\n",
      "Epoch: 119, Loss: 49.5542945862, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1225382932\n",
      "Epoch: 120, Loss: 49.5261459351, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1225382932\n",
      "Epoch: 121, Loss: 49.5747642517, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1225382932\n",
      "Epoch: 122, Loss: 49.5548782349, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1225382932\n",
      "Epoch: 123, Loss: 49.6327209473, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1225382932\n",
      "Epoch: 124, Loss: 49.5179176331, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1225382932\n",
      "Epoch: 125, Loss: 49.5946884155, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1225382932\n",
      "Epoch: 126, Loss: 49.6993751526, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1225382932\n",
      "Epoch: 127, Loss: 49.5942726135, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1222951617\n",
      "Epoch: 128, Loss: 49.5085830688, Train Acc: 0.5030000000, Val Acc: 0.1278871870, Test Acc: 0.1222951617\n",
      "Epoch: 129, Loss: 49.6064720154, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 130, Loss: 49.5022163391, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 131, Loss: 49.5714378357, Train Acc: 0.5035000000, Val Acc: 0.1276440554, Test Acc: 0.1222951617\n",
      "Epoch: 132, Loss: 49.6607208252, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 133, Loss: 49.5797729492, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 134, Loss: 49.6082000732, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 135, Loss: 49.6258621216, Train Acc: 0.5035000000, Val Acc: 0.1261852662, Test Acc: 0.1220520301\n",
      "Epoch: 136, Loss: 49.5303192139, Train Acc: 0.5030000000, Val Acc: 0.1254558716, Test Acc: 0.1203501094\n",
      "Epoch: 137, Loss: 49.6681900024, Train Acc: 0.5030000000, Val Acc: 0.1254558716, Test Acc: 0.1201069779\n",
      "Epoch: 138, Loss: 49.6560935974, Train Acc: 0.5025000000, Val Acc: 0.1254558716, Test Acc: 0.1198638463\n",
      "Epoch: 139, Loss: 49.6552352905, Train Acc: 0.5025000000, Val Acc: 0.1254558716, Test Acc: 0.1198638463\n",
      "Epoch: 140, Loss: 49.6678543091, Train Acc: 0.5025000000, Val Acc: 0.1254558716, Test Acc: 0.1198638463\n",
      "Epoch: 141, Loss: 49.5949440002, Train Acc: 0.5025000000, Val Acc: 0.1254558716, Test Acc: 0.1198638463\n",
      "Epoch: 142, Loss: 49.5048599243, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 143, Loss: 49.6157035828, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 144, Loss: 49.4962120056, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 145, Loss: 49.6371345520, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 146, Loss: 49.6090011597, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 147, Loss: 49.6087951660, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 148, Loss: 49.6036300659, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 149, Loss: 49.5561447144, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 150, Loss: 49.6473655701, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 151, Loss: 49.6637268066, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 152, Loss: 49.6184272766, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 153, Loss: 49.5913200378, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 154, Loss: 49.7257995605, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 155, Loss: 49.5670547485, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 156, Loss: 49.5653648376, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 157, Loss: 49.6219482422, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 158, Loss: 49.5545616150, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 159, Loss: 49.6615791321, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 160, Loss: 49.5094261169, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 161, Loss: 49.5056915283, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 162, Loss: 49.5764961243, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 163, Loss: 49.5075225830, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 164, Loss: 49.5788078308, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 165, Loss: 49.5701255798, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 166, Loss: 49.5696716309, Train Acc: 0.5030000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 167, Loss: 49.5700569153, Train Acc: 0.5030000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 168, Loss: 49.5198974609, Train Acc: 0.5030000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 169, Loss: 49.5594673157, Train Acc: 0.5030000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 170, Loss: 49.5101699829, Train Acc: 0.5030000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 171, Loss: 49.4589309692, Train Acc: 0.5030000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 172, Loss: 49.5589065552, Train Acc: 0.5030000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 173, Loss: 49.4644279480, Train Acc: 0.5030000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 174, Loss: 49.6187705994, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 175, Loss: 49.5604591370, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 176, Loss: 49.6144676208, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1218088986\n",
      "Epoch: 177, Loss: 49.6011199951, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1218088986\n",
      "Epoch: 178, Loss: 49.5562400818, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 179, Loss: 49.6191673279, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 180, Loss: 49.5662803650, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 181, Loss: 49.5522956848, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 182, Loss: 49.5773620605, Train Acc: 0.5035000000, Val Acc: 0.1264283978, Test Acc: 0.1220520301\n",
      "Epoch: 183, Loss: 49.5548820496, Train Acc: 0.5035000000, Val Acc: 0.1261852662, Test Acc: 0.1220520301\n",
      "Epoch: 184, Loss: 49.5579757690, Train Acc: 0.5035000000, Val Acc: 0.1261852662, Test Acc: 0.1220520301\n",
      "Epoch: 185, Loss: 49.5179367065, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 186, Loss: 49.5548477173, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 187, Loss: 49.6118316650, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 188, Loss: 49.4689025879, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1218088986\n",
      "Epoch: 189, Loss: 49.4659080505, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 190, Loss: 49.5513229370, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 191, Loss: 49.5221900940, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 192, Loss: 49.5673332214, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 193, Loss: 49.5183982849, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 194, Loss: 49.5198402405, Train Acc: 0.5035000000, Val Acc: 0.1266715293, Test Acc: 0.1222951617\n",
      "Epoch: 195, Loss: 49.5285110474, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 196, Loss: 49.5250587463, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 197, Loss: 49.4786758423, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 198, Loss: 49.5667915344, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 199, Loss: 49.5500183105, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n",
      "Epoch: 200, Loss: 49.5154037476, Train Acc: 0.5040000000, Val Acc: 0.1266715293, Test Acc: 0.1220520301\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 64)\n",
    "        self.conv2 = GCNConv(64, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "model = GCNModel(graph.num_node_features, 1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)[data.train_mask].squeeze()\n",
    "    loss = F.binary_cross_entropy(out, data.y[data.train_mask].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(data, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(data)[mask].squeeze()\n",
    "        preds = (preds > 0.5).long()\n",
    "        acc = preds.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "    return acc\n",
    "\n",
    "for epoch in range(200):\n",
    "    loss = train(graph)\n",
    "    train_acc = evaluate(graph, graph.train_mask)\n",
    "    val_acc = evaluate(graph, graph.val_mask)\n",
    "    test_acc = evaluate(graph, graph.test_mask)\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss:.10f}, Train Acc: {train_acc:.10f}, Val Acc: {val_acc:.10f}, Test Acc: {test_acc:.10f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
