{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00910a35-ffbc-4497-bcc8-21f008c326fb",
   "metadata": {},
   "source": [
    "# Grapher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1805a-55dc-409c-9ccf-512eb1f88667",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8ec1d-73be-4b8c-95dc-79489e84998b",
   "metadata": {},
   "source": [
    "- `id`: This column represents the id of the variant in the following format: #chrom:pos:ref:alt (string).\n",
    "\n",
    "- `#chrom`: This column represents the chromosome number where the genetic variant is located.\n",
    "\n",
    "- `pos`: This is the position of the genetic variant on the chromosome.\n",
    "\n",
    "- `ref`: This column represents the reference allele (or variant) at the genomic position.\n",
    "\n",
    "- `alt`: This is the alternate allele observed at this position.\n",
    "\n",
    "- `rsids`: This stands for reference SNP cluster ID. It's a unique identifier for each variant used in the dbSNP database.\n",
    "\n",
    "- `nearest_genes`: This column represents the gene which is nearest to the variant.\n",
    "\n",
    "- `pval`: This represents the p-value, which is a statistical measure for the strength of evidence against the null hypothesis.\n",
    "\n",
    "- `mlogp`: This represents the minus log of the p-value, commonly used in genomic studies.\n",
    "\n",
    "- `beta`: The beta coefficient represents the effect size of the variant.\n",
    "\n",
    "- `sebeta`: This is the standard error of the beta coefficient.\n",
    "\n",
    "- `af_alt`: This is the allele frequency of the alternate variant in the general population.\n",
    "\n",
    "- `af_alt_cases`: This is the allele frequency of the alternate variant in the cases group.\n",
    "\n",
    "- `af_alt_controls`: This is the allele frequency of the alternate variant in the control group.\n",
    "\n",
    "- `finemapped`: This column represents whether the variant is included in the post-finemapped dataset (1) or not (0). \n",
    "\n",
    "- `trait`: This column represents the trait associated with the variant. In this dataset, it is the response to the drug paracetamol and NSAIDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b033d-95f5-4584-b10c-72969a166612",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4345459-b1ef-477c-8f06-c8f54c194af0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]\n",
      "NumPy version: 1.24.3\n",
      "Pandas version: 2.0.1\n",
      "Matplotlib version: 3.7.1\n",
      "Scikit-learn version: 1.2.2\n",
      "Torch version: 2.0.0+cu118\n",
      "Torch Geometric version: 2.3.1\n",
      "NetworkX version: 3.0\n",
      "Using NVIDIA GeForce RTX 3060 Ti (cuda)\n",
      "CUDA version: 11.8\n",
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from numba import jit, prange\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "import networkx as nx\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.special import expit\n",
    "from typing import List, Dict\n",
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "from category_encoders import BinaryEncoder, OrdinalEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Print versions of imported libraries\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Torch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddfa8cb-01df-491f-94f0-c8c228256b4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fe5b06-7392-4d62-a1e8-af081cdf3e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'string',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'finemapped': 'int64'\n",
    "}\n",
    "\n",
    "data = pd.read_csv('~/Desktop/gwas-graph/FinnGen/data/gwas-finemap.csv', dtype=dtypes)\n",
    "\n",
    "# Assert column names\n",
    "expected_columns = ['#chrom', 'pos', 'ref', 'alt', 'rsids', 'nearest_genes', 'pval', 'mlogp', 'beta',\n",
    "                    'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls', 'finemapped',\n",
    "                    'id', 'trait']\n",
    "assert set(data.columns) == set(expected_columns), \"Unexpected columns in the data DataFrame.\"\n",
    "\n",
    "# Assert data types\n",
    "expected_dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'string',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'finemapped': 'int64'\n",
    "}\n",
    "\n",
    "for col, expected_dtype in expected_dtypes.items():\n",
    "    assert data[col].dtype == expected_dtype, f\"Unexpected data type for column {col}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d6d595-4ef8-41d5-b0a5-dbdc9f2d9b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in each column:\n",
      "#chrom                   0\n",
      "pos                      0\n",
      "ref                      0\n",
      "alt                      0\n",
      "rsids              1366396\n",
      "nearest_genes       727855\n",
      "pval                     0\n",
      "mlogp                    0\n",
      "beta                     0\n",
      "sebeta                   0\n",
      "af_alt                   0\n",
      "af_alt_cases             0\n",
      "af_alt_controls          0\n",
      "id                       0\n",
      "finemapped               0\n",
      "trait                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for total number of null values in each column\n",
    "null_counts = data.isnull().sum()\n",
    "\n",
    "print(\"Total number of null values in each column:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a754a-7836-439e-801c-7efca6d2dfc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513cafa0-f3f8-47b5-9d22-96062449edde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460fab1f-46fa-40a5-a8c5-aa746b1db7eb",
   "metadata": {},
   "source": [
    "### Find nearest gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b729972-b0d7-4e38-b8e2-aedd07506c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['nearest_genes'] = data['nearest_genes'].astype(str)\n",
    "\n",
    "# Assert column 'nearest_genes' is a string\n",
    "assert data['nearest_genes'].dtype == 'object', \"Column 'nearest_genes' is not of string type.\"\n",
    "\n",
    "# Get the length of the data before transformation\n",
    "original_length = len(data)\n",
    "\n",
    "# Extract the first gene name from the 'nearest_genes' column\n",
    "data['nearest_genes'] = data['nearest_genes'].str.split(',').str[0]\n",
    "\n",
    "# Reset index to have a standard index\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Assert the length of the data remains the same\n",
    "assert len(data) == original_length, \"Length of the data has changed after transformation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eddaed-2f48-4440-b6d6-0dc247f23ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe89142-2b65-469b-b330-1620d303312b",
   "metadata": {},
   "source": [
    "Here's the adjusted spec in markdown format:\n",
    "\n",
    "### Data\n",
    "\n",
    "`data` Pandas DataFrame:\n",
    "\n",
    "- `id`: This column represents the id of the variant in the following format: #chrom:pos:ref:alt (string).\n",
    "- `#chrom`: This column represents the chromosome number where the genetic variant is located.\n",
    "- `pos`: This is the position of the genetic variant on the chromosome (int: 1-200,000).\n",
    "- `ref`: This column represents the reference allele (or variant) at the genomic position.\n",
    "- `alt`: This is the alternate allele observed at this position.\n",
    "- `rsids`: This stands for reference SNP cluster ID. It's a unique identifier for each variant used in the dbSNP database.\n",
    "- `nearest_genes`: This column represents the gene which is nearest to the variant (string).\n",
    "- `pval`: This represents the p-value, which is a statistical measure for the strength of evidence against the null hypothesis.\n",
    "- `mlogp`: This represents the minus log of the p-value, commonly used in genomic studies.\n",
    "- `beta`: The beta coefficient represents the effect size of the variant.\n",
    "- `sebeta`: This is the standard error of the beta coefficient.\n",
    "- `af_alt`: This is the allele frequency of the alternate variant in the general population (float: 0-1.\n",
    "- `af_alt_cases`: This is the allele frequency of the alternate variant in the cases group (float: 0-1).\n",
    "- `af_alt_controls`: This is the allele frequency of the alternate variant in the control group (float: 0-1).\n",
    "- `finemapped`: This column represents whether the variant is included in the post-finemapped dataset (1) or not (0) (int).\n",
    "- `trait`: This column represents the trait associated with the variant. In this dataset, it is the response to the drug paracetamol and NSAIDs.\n",
    "\n",
    "### Task Overview\n",
    "\n",
    "The objective is to design and implement a binary node classification GNN model to predict whether variants are included after post-finemapping or not based on `finemapping`.\n",
    "\n",
    "### Nodes and Their Features\n",
    "\n",
    "There is one type of node: SNP nodes.\n",
    "\n",
    "- **SNP Nodes**: Each SNP Node is characterized by various features, including `id`, `nearest_genes`, `#chrom`, `pos`, `ref`, `alt`, `beta`, `sebeta`,  `af_alt`, `af_alt_cases`, and `af_alt_controls` columns.\n",
    "\n",
    "### Edges, Their Features, and Labels\n",
    "\n",
    "Edges represent relationships between SNP nodes in the graph.\n",
    "\n",
    "1. **Type 1 Edges: LD-based edges**\n",
    "\n",
    "   - For each pair of SNPs (row1 and row2) that exist on the same chromosome (`#chrom`), an edge is created if the absolute difference between their positions (`pos`) is less than or equal to 500,000 and greater than 1 (no loops).\n",
    "   - The weight of the edge is determined by the following formula:\n",
    "     \n",
    "```\n",
    " weights = (1 / (1 + abs(standardized_pos - row['pos']))) * \\\n",
    "                      af_alt_diff * \\\n",
    "                      abs(row['af_alt_cases'] - filtered_group['af_alt_cases']) * \\\n",
    "                      abs(row['af_alt_controls'] - filtered_group['af_alt_controls'])\n",
    "```\n",
    "\n",
    "    - For each chromosome, standardize the edge weights between 0 and 1 after all weights have been computed.\n",
    "    - Prune any edges that have a weight of less than `1e-3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51485cfb-989a-430f-874b-af2d5f79d9f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph creation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1dc8f567-51f0-480e-8e3c-acd975af1eec",
   "metadata": {
    "tags": []
   },
   "source": [
    "edge_weight_cutoff = 1e-2  # set the cutoff value, this is an example and you can choose any suitable value\n",
    "\n",
    "\n",
    "def get_unique_snps(data: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Function to create mappings for SNPs to integer indices.\n",
    "    \"\"\"\n",
    "    return {snp: idx for idx, snp in enumerate(data['id'].unique())}\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_snp_features(data: pd.DataFrame, snp_to_idx: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to create node feature vectors for SNPs and preprocess categorical and numerical features.\n",
    "    \"\"\"\n",
    "    snp_features = data.loc[data['id'].isin(snp_to_idx.keys()), ['id', 'nearest_genes', '#chrom', 'pos', 'ref', 'alt', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls']].set_index('id').sort_index()\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    binary_encoder = BinaryEncoder()\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "    for col in snp_features.columns:\n",
    "        if col in ['#chrom']:\n",
    "            snp_features[col] = ordinal_encoder.fit_transform(snp_features[col].astype(str).to_frame())\n",
    "        elif col in ['ref', 'alt', 'nearest_genes']:\n",
    "            binary_encoded_df = binary_encoder.fit_transform(snp_features[col].astype(str).to_frame())\n",
    "            binary_encoded_df.columns = [f\"{col}_{bin_col}\" for bin_col in binary_encoded_df.columns]\n",
    "            snp_features = pd.concat([snp_features.drop(col, axis=1), binary_encoded_df], axis=1)\n",
    "        else:\n",
    "            snp_features[col] = pd.Series(scaler.fit_transform(snp_features[col].to_frame()).flatten())\n",
    "\n",
    "    # Filling N/A values for newly binary encoded columns\n",
    "    binary_encoded_cols = [col for col in snp_features.columns if ('ref_' in col) or ('alt_' in col) or ('nearest_genes_' in col)]\n",
    "    snp_features.loc[:, binary_encoded_cols] = snp_features[binary_encoded_cols].fillna(0)\n",
    "\n",
    "    # Filling N/A values for ordinal encoded column\n",
    "    snp_features.loc[:, '#chrom'] = snp_features['#chrom'].fillna(-1)\n",
    "\n",
    "    # Filling 0 values for other columns\n",
    "    snp_features[['pos', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls']] = snp_features[['pos', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls']].fillna(0)\n",
    "    \n",
    "    return snp_features\n",
    "\n",
    "\n",
    "def preprocess_positive_edges(data: pd.DataFrame, snp_to_idx: dict) -> torch.Tensor:\n",
    "    positive_edges_snp_snp = []\n",
    "    snp_weights = []\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "\n",
    "    for _, group in data.groupby('#chrom'):\n",
    "        # Skip if group is empty\n",
    "        if group.empty:\n",
    "            continue\n",
    "        sorted_group = group.sort_values(by='pos')\n",
    "        min_pos = sorted_group['pos'].min()\n",
    "        max_pos = sorted_group['pos'].max()\n",
    "        pos_range = max_pos - min_pos\n",
    "        for idx, row in sorted_group.iterrows():\n",
    "            pos_diff = sorted_group['pos'] - row['pos']\n",
    "            mask = (pos_diff > 0) & (pos_diff <= 500000)\n",
    "            filtered_group = sorted_group[mask]\n",
    "            if filtered_group.empty:\n",
    "                continue\n",
    "            ids = filtered_group['id'].map(snp_to_idx)\n",
    "            af_alt_diff = abs(row['af_alt'] - filtered_group['af_alt'])\n",
    "            pos_diff_abs = abs(row['pos'] - filtered_group['pos'])\n",
    "            standardized_pos = (filtered_group['pos'] - min_pos) / pos_range\n",
    "            weights = (1 / (1 + pos_diff_abs)) * \\\n",
    "                      af_alt_diff * \\\n",
    "                      abs(row['af_alt_cases'] - filtered_group['af_alt_cases']) * \\\n",
    "                      abs(row['af_alt_controls'] - filtered_group['af_alt_controls'])\n",
    "            # Skip if weights are empty\n",
    "            if len(weights) == 0:\n",
    "                continue\n",
    "            positive_edges_snp_snp.extend(zip([snp_to_idx[row['id']]] * len(ids), ids))\n",
    "            snp_weights.extend(weights)\n",
    "\n",
    "    # Normalize weights\n",
    "    snp_weights = scaler.fit_transform(np.array(snp_weights).reshape(-1, 1)).flatten()\n",
    "    mask_cutoff = snp_weights >= edge_weight_cutoff\n",
    "    filtered_edges = np.array(positive_edges_snp_snp)[mask_cutoff]\n",
    "    filtered_weights = snp_weights[mask_cutoff]\n",
    "    \n",
    "    return torch.tensor(filtered_edges, dtype=torch.long).t().contiguous(), torch.tensor(filtered_weights, dtype=torch.float), len(filtered_edges)\n",
    "\n",
    "\n",
    "def create_pytorch_graph(features: torch.Tensor, edges: torch.Tensor, edge_weights: torch.Tensor) -> Data:\n",
    "    \n",
    "    return Data(x=features, edge_index=edges, edge_attr=edge_weights)\n",
    "\n",
    "\n",
    "# Add profiling\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Main\n",
    "snp_to_idx = get_unique_snps(data)\n",
    "labels = data['finemapped'].map(lambda x: 1 if x > 0 else 0)\n",
    "snp_features = preprocess_snp_features(data, snp_to_idx)\n",
    "features = torch.tensor(snp_features.values, dtype=torch.float)\n",
    "\n",
    "positive_edges_snp_snp, snp_weights, len_positive_edges = preprocess_positive_edges(data, snp_to_idx)\n",
    "print(len_positive_edges)\n",
    "\n",
    "# Create the graph with the positive edges\n",
    "graph = create_pytorch_graph(features, positive_edges_snp_snp, snp_weights)\n",
    "graph.y = torch.tensor(labels.values, dtype=torch.long)\n",
    "\n",
    "# Store lengths of different edge types in the graph\n",
    "graph.edge_lengths = {'positive': len_positive_edges}\n",
    "\n",
    "print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "print(f\"Number of edges: {graph.num_edges}\")\n",
    "print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")\n",
    "\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "sortby = 'cumulative'\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats(5)  # Only print the top 5 lines\n",
    "print(s.getvalue())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abe533-6610-4f82-b8d6-533eb010858d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save/Load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bba9103-b4af-4311-9bd8-033e04770339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PyTorch Geometric graph\n",
    "\n",
    "#torch.save(graph, \"pytorch_geometric_graph.pt\")\n",
    "graph = torch.load(\"pytorch_geometric_graph.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4462c-4130-4242-9a7d-09c6ed71b613",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph stats"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2e62fad-1f8d-49b1-bf2b-9d51168e0d7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "from torch_geometric.utils import degree\n",
    "\n",
    "def print_graph_stats(graph, positive_edges_snp_snp, features_list):\n",
    "    print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "    print(f\"Number of edges: {graph.num_edges}\")\n",
    "    print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "    print(f\"Number of finemapped nodes: {data['finemapped'].sum()}\")\n",
    "\n",
    "    # Compute and print degree-related stats\n",
    "    degrees = degree(graph.edge_index[0].long(), num_nodes=graph.num_nodes)\n",
    "    average_degree = degrees.float().mean().item()\n",
    "    median_degree = np.median(degrees.numpy())\n",
    "    std_degree = degrees.float().std().item()\n",
    "\n",
    "    print(f\"Average Degree: {average_degree}\")\n",
    "    print(f\"Median Degree: {median_degree}\")\n",
    "    print(f\"Standard Deviation of Degree: {std_degree}\")\n",
    "\n",
    "    # Density is the ratio of actual edges to the maximum number of possible edges\n",
    "    num_possible_edges = graph.num_nodes * (graph.num_nodes - 1) / 2\n",
    "    density = graph.num_edges / num_possible_edges\n",
    "\n",
    "    print(f\"Density: {density:.10f}\")\n",
    "\n",
    "    # Check for NaN values in features\n",
    "    nan_mask = torch.isnan(graph.x)\n",
    "    nan_features = []\n",
    "    for feature_idx, feature_name in enumerate(features_list):\n",
    "        if nan_mask[:, feature_idx].any():\n",
    "            nan_features.append(feature_name)\n",
    "\n",
    "    print(\"Features with NaN values:\")\n",
    "    print(nan_features)\n",
    "\n",
    "def print_edge_weight_stats(edge_weights):\n",
    "    print(f\"Number of edges: {edge_weights.size(0)}\")\n",
    "    print(f\"Average edge weight: {edge_weights.float().mean().item()}\")\n",
    "    print(f\"Median edge weight: {np.median(edge_weights.numpy())}\")\n",
    "    print(f\"Standard deviation of edge weights: {edge_weights.float().std().item()}\")\n",
    "    print(f\"Maximum edge weight: {edge_weights.max().item()}\")\n",
    "    print(f\"Minimum edge weight: {edge_weights.min().item()}\")\n",
    "\n",
    "# Print graph stats\n",
    "print(\"Graph stats:\")\n",
    "print_graph_stats(graph, positive_edges_snp_snp, snp_features.columns)\n",
    "\n",
    "print(\"Edge weight stats:\")\n",
    "print_edge_weight_stats(graph.edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51e96d-660c-4b4f-8ac4-9a07dba5bcc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79fb79d-4729-4d4d-8dff-229108b6cac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes per class in each set:\n",
      "Train set:\n",
      "Class 0: 10197 nodes\n",
      "Class 1: 1905 nodes\n",
      "Validation set:\n",
      "Class 0: 80518 nodes\n",
      "Class 1: 14281 nodes\n",
      "Test set:\n",
      "Class 0: 80325 nodes\n",
      "Class 1: 14474 nodes\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "from collections import Counter\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "transform = RandomNodeSplit(split=\"train_rest\", num_val=0.47, num_test=0.47, key='y')\n",
    "graph = transform(graph)\n",
    "\n",
    "# Count the number of nodes per class in each set\n",
    "train_class_counts = Counter(graph.y[graph.train_mask].numpy())\n",
    "val_class_counts = Counter(graph.y[graph.val_mask].numpy())\n",
    "test_class_counts = Counter(graph.y[graph.test_mask].numpy())\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of nodes per class in each set:\")\n",
    "print(\"Train set:\")\n",
    "for class_label, count in train_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} nodes\")\n",
    "print(\"Validation set:\")\n",
    "for class_label, count in val_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} nodes\")\n",
    "print(\"Test set:\")\n",
    "for class_label, count in test_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} nodes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665050a-5cd9-4960-a2ef-8a4cf2cb5e40",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2557f-d84e-4a1b-bda8-7b26620f526b",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555e09d5-089e-4d51-85de-25cbe30656f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1574, 0.8426], device='cuda:0')\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 1, Loss: 0.0470851846, Train ROC AUC: 0.4969901600, Val ROC AUC: 0.5131496653, Test ROC AUC: 0.5109153471\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 2, Loss: 0.0467175990, Train ROC AUC: 0.4966204099, Val ROC AUC: 0.5128558736, Test ROC AUC: 0.5106720147\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 3, Loss: 0.0463238843, Train ROC AUC: 0.4962340578, Val ROC AUC: 0.5125088523, Test ROC AUC: 0.5104153501\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 4, Loss: 0.0458828993, Train ROC AUC: 0.4958930332, Val ROC AUC: 0.5121309681, Test ROC AUC: 0.5101377616\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 5, Loss: 0.0453025773, Train ROC AUC: 0.4955591128, Val ROC AUC: 0.5117257867, Test ROC AUC: 0.5098430082\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 6, Loss: 0.0448214523, Train ROC AUC: 0.4952271743, Val ROC AUC: 0.5113319057, Test ROC AUC: 0.5095007092\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 7, Loss: 0.0441732481, Train ROC AUC: 0.4949379121, Val ROC AUC: 0.5109337024, Test ROC AUC: 0.5091524182\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 8, Loss: 0.0438456088, Train ROC AUC: 0.4947397426, Val ROC AUC: 0.5105183847, Test ROC AUC: 0.5087586232\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 9, Loss: 0.0434974171, Train ROC AUC: 0.4946027562, Val ROC AUC: 0.5100961058, Test ROC AUC: 0.5083382732\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [1]\n",
      "Epoch: 10, Loss: 0.0429141298, Train ROC AUC: 0.4943882419, Val ROC AUC: 0.5096036830, Test ROC AUC: 0.5078638189\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 11, Loss: 0.0424370095, Train ROC AUC: 0.4941908446, Val ROC AUC: 0.5090419523, Test ROC AUC: 0.5073643208\n",
      "Classes predicted: [1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 12, Loss: 0.0418904871, Train ROC AUC: 0.4939208099, Val ROC AUC: 0.5084530222, Test ROC AUC: 0.5068677734\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 13, Loss: 0.0414547771, Train ROC AUC: 0.4936173909, Val ROC AUC: 0.5078106146, Test ROC AUC: 0.5063118435\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 14, Loss: 0.0409830995, Train ROC AUC: 0.4932865850, Val ROC AUC: 0.5070646696, Test ROC AUC: 0.5056632021\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 15, Loss: 0.0407252908, Train ROC AUC: 0.4928226278, Val ROC AUC: 0.5062534406, Test ROC AUC: 0.5049411355\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 16, Loss: 0.0400635749, Train ROC AUC: 0.4922640260, Val ROC AUC: 0.5053473154, Test ROC AUC: 0.5041334948\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 17, Loss: 0.0394035839, Train ROC AUC: 0.4917801721, Val ROC AUC: 0.5043582610, Test ROC AUC: 0.5031863886\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 18, Loss: 0.0392080545, Train ROC AUC: 0.4914071016, Val ROC AUC: 0.5032524593, Test ROC AUC: 0.5021406812\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 19, Loss: 0.0385433882, Train ROC AUC: 0.4912001548, Val ROC AUC: 0.5019540607, Test ROC AUC: 0.5010187842\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 20, Loss: 0.0381478369, Train ROC AUC: 0.4913118392, Val ROC AUC: 0.5006016623, Test ROC AUC: 0.4998374307\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 21, Loss: 0.0377137884, Train ROC AUC: 0.4917880999, Val ROC AUC: 0.4992451309, Test ROC AUC: 0.4986075301\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 22, Loss: 0.0373428538, Train ROC AUC: 0.4923031245, Val ROC AUC: 0.4978564535, Test ROC AUC: 0.4973319982\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 23, Loss: 0.0365785509, Train ROC AUC: 0.4927643275, Val ROC AUC: 0.4965430485, Test ROC AUC: 0.4961464194\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 24, Loss: 0.0362400226, Train ROC AUC: 0.4929655344, Val ROC AUC: 0.4952864851, Test ROC AUC: 0.4950745097\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 25, Loss: 0.0358933099, Train ROC AUC: 0.4930206429, Val ROC AUC: 0.4940675227, Test ROC AUC: 0.4940828082\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 26, Loss: 0.0353596918, Train ROC AUC: 0.4930302696, Val ROC AUC: 0.4929273331, Test ROC AUC: 0.4931600985\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 27, Loss: 0.0351590402, Train ROC AUC: 0.4929475681, Val ROC AUC: 0.4917995691, Test ROC AUC: 0.4923115667\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 28, Loss: 0.0345435627, Train ROC AUC: 0.4928130269, Val ROC AUC: 0.4907315649, Test ROC AUC: 0.4914722911\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 29, Loss: 0.0341203026, Train ROC AUC: 0.4926242781, Val ROC AUC: 0.4897831774, Test ROC AUC: 0.4907138946\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 30, Loss: 0.0337258764, Train ROC AUC: 0.4924200083, Val ROC AUC: 0.4888882713, Test ROC AUC: 0.4900243243\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 31, Loss: 0.0333298519, Train ROC AUC: 0.4922123408, Val ROC AUC: 0.4880466421, Test ROC AUC: 0.4893415197\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 32, Loss: 0.0328779146, Train ROC AUC: 0.4919969514, Val ROC AUC: 0.4872536494, Test ROC AUC: 0.4886829384\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 33, Loss: 0.0324823372, Train ROC AUC: 0.4918273271, Val ROC AUC: 0.4865543745, Test ROC AUC: 0.4880319653\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 34, Loss: 0.0320959128, Train ROC AUC: 0.4916058632, Val ROC AUC: 0.4859161192, Test ROC AUC: 0.4873965694\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 35, Loss: 0.0316741839, Train ROC AUC: 0.4912016735, Val ROC AUC: 0.4853798899, Test ROC AUC: 0.4868140763\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 36, Loss: 0.0314720124, Train ROC AUC: 0.4909049468, Val ROC AUC: 0.4849309312, Test ROC AUC: 0.4862965393\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 37, Loss: 0.0310781114, Train ROC AUC: 0.4906294296, Val ROC AUC: 0.4845236531, Test ROC AUC: 0.4858127690\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 38, Loss: 0.0307484511, Train ROC AUC: 0.4903470657, Val ROC AUC: 0.4841763674, Test ROC AUC: 0.4853797674\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 39, Loss: 0.0302859135, Train ROC AUC: 0.4901075325, Val ROC AUC: 0.4838800806, Test ROC AUC: 0.4849855527\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 40, Loss: 0.0299889259, Train ROC AUC: 0.4898821819, Val ROC AUC: 0.4836058449, Test ROC AUC: 0.4846296415\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 41, Loss: 0.0296950284, Train ROC AUC: 0.4896534594, Val ROC AUC: 0.4833519009, Test ROC AUC: 0.4842948505\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 42, Loss: 0.0292182900, Train ROC AUC: 0.4895681325, Val ROC AUC: 0.4831220739, Test ROC AUC: 0.4840067806\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 43, Loss: 0.0290526524, Train ROC AUC: 0.4894831144, Val ROC AUC: 0.4829010364, Test ROC AUC: 0.4837364052\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 44, Loss: 0.0286340769, Train ROC AUC: 0.4894802573, Val ROC AUC: 0.4826776831, Test ROC AUC: 0.4834809937\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 45, Loss: 0.0285204817, Train ROC AUC: 0.4895203854, Val ROC AUC: 0.4824394020, Test ROC AUC: 0.4832451453\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 46, Loss: 0.0280506238, Train ROC AUC: 0.4895969609, Val ROC AUC: 0.4822355316, Test ROC AUC: 0.4830447443\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 47, Loss: 0.0277915746, Train ROC AUC: 0.4896580668, Val ROC AUC: 0.4820686286, Test ROC AUC: 0.4828705586\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 48, Loss: 0.0276367776, Train ROC AUC: 0.4896779635, Val ROC AUC: 0.4819256669, Test ROC AUC: 0.4827304575\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 49, Loss: 0.0273837186, Train ROC AUC: 0.4896460206, Val ROC AUC: 0.4818118370, Test ROC AUC: 0.4825932945\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 50, Loss: 0.0270028170, Train ROC AUC: 0.4895798440, Val ROC AUC: 0.4816916233, Test ROC AUC: 0.4824542744\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 51, Loss: 0.0267051868, Train ROC AUC: 0.4895398961, Val ROC AUC: 0.4815711065, Test ROC AUC: 0.4823054366\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 52, Loss: 0.0264408290, Train ROC AUC: 0.4894927410, Val ROC AUC: 0.4814724669, Test ROC AUC: 0.4821672973\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 53, Loss: 0.0263500158, Train ROC AUC: 0.4894240162, Val ROC AUC: 0.4813514762, Test ROC AUC: 0.4820294213\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 54, Loss: 0.0260288455, Train ROC AUC: 0.4893841712, Val ROC AUC: 0.4812418745, Test ROC AUC: 0.4818816336\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 55, Loss: 0.0258446187, Train ROC AUC: 0.4893774017, Val ROC AUC: 0.4811450812, Test ROC AUC: 0.4817440195\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 56, Loss: 0.0256095584, Train ROC AUC: 0.4893625242, Val ROC AUC: 0.4810719678, Test ROC AUC: 0.4816326696\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 57, Loss: 0.0253630541, Train ROC AUC: 0.4893146741, Val ROC AUC: 0.4810004710, Test ROC AUC: 0.4815336480\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 58, Loss: 0.0251547266, Train ROC AUC: 0.4891901972, Val ROC AUC: 0.4809252765, Test ROC AUC: 0.4814219072\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 59, Loss: 0.0250818860, Train ROC AUC: 0.4891012667, Val ROC AUC: 0.4808368010, Test ROC AUC: 0.4812942640\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 60, Loss: 0.0248253830, Train ROC AUC: 0.4889544993, Val ROC AUC: 0.4807407094, Test ROC AUC: 0.4811661487\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 61, Loss: 0.0245638601, Train ROC AUC: 0.4888245912, Val ROC AUC: 0.4806451980, Test ROC AUC: 0.4810376260\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 62, Loss: 0.0245190542, Train ROC AUC: 0.4887371279, Val ROC AUC: 0.4805653964, Test ROC AUC: 0.4809330445\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 63, Loss: 0.0243277401, Train ROC AUC: 0.4886812986, Val ROC AUC: 0.4805070206, Test ROC AUC: 0.4808476252\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 64, Loss: 0.0241538305, Train ROC AUC: 0.4885923167, Val ROC AUC: 0.4804681939, Test ROC AUC: 0.4807809807\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 65, Loss: 0.0239175521, Train ROC AUC: 0.4884809927, Val ROC AUC: 0.4804419672, Test ROC AUC: 0.4807298705\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 66, Loss: 0.0238280185, Train ROC AUC: 0.4883931175, Val ROC AUC: 0.4804226156, Test ROC AUC: 0.4806961266\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 67, Loss: 0.0236857273, Train ROC AUC: 0.4883211495, Val ROC AUC: 0.4804334393, Test ROC AUC: 0.4806841648\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 68, Loss: 0.0234751608, Train ROC AUC: 0.4882686148, Val ROC AUC: 0.4804708377, Test ROC AUC: 0.4806885343\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 69, Loss: 0.0233341213, Train ROC AUC: 0.4881894140, Val ROC AUC: 0.4805165804, Test ROC AUC: 0.4806872682\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 70, Loss: 0.0232828427, Train ROC AUC: 0.4881036237, Val ROC AUC: 0.4805543218, Test ROC AUC: 0.4806693092\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 71, Loss: 0.0231933109, Train ROC AUC: 0.4880085157, Val ROC AUC: 0.4805949678, Test ROC AUC: 0.4806515270\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 72, Loss: 0.0230897367, Train ROC AUC: 0.4878769346, Val ROC AUC: 0.4806208406, Test ROC AUC: 0.4806359093\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 73, Loss: 0.0229485538, Train ROC AUC: 0.4877685192, Val ROC AUC: 0.4806606074, Test ROC AUC: 0.4806240611\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 74, Loss: 0.0228058621, Train ROC AUC: 0.4876585594, Val ROC AUC: 0.4807025084, Test ROC AUC: 0.4806086305\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 75, Loss: 0.0227219481, Train ROC AUC: 0.4875551118, Val ROC AUC: 0.4807426557, Test ROC AUC: 0.4805932649\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 76, Loss: 0.0225783996, Train ROC AUC: 0.4874523849, Val ROC AUC: 0.4807770872, Test ROC AUC: 0.4805769737\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 77, Loss: 0.0224814843, Train ROC AUC: 0.4873753204, Val ROC AUC: 0.4808179659, Test ROC AUC: 0.4805638628\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 78, Loss: 0.0223881695, Train ROC AUC: 0.4873289118, Val ROC AUC: 0.4808596312, Test ROC AUC: 0.4805508406\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 79, Loss: 0.0223013330, Train ROC AUC: 0.4872822973, Val ROC AUC: 0.4809023662, Test ROC AUC: 0.4805379714\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 80, Loss: 0.0221976452, Train ROC AUC: 0.4872246919, Val ROC AUC: 0.4809419256, Test ROC AUC: 0.4805249410\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 81, Loss: 0.0220991857, Train ROC AUC: 0.4871341656, Val ROC AUC: 0.4809853611, Test ROC AUC: 0.4805142690\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 82, Loss: 0.0220937692, Train ROC AUC: 0.4870802925, Val ROC AUC: 0.4810274795, Test ROC AUC: 0.4805032921\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 83, Loss: 0.0219367035, Train ROC AUC: 0.4870212458, Val ROC AUC: 0.4810635908, Test ROC AUC: 0.4804885062\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 84, Loss: 0.0218760651, Train ROC AUC: 0.4869911561, Val ROC AUC: 0.4810970956, Test ROC AUC: 0.4804689065\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 85, Loss: 0.0217686631, Train ROC AUC: 0.4869505132, Val ROC AUC: 0.4811238807, Test ROC AUC: 0.4804523431\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 86, Loss: 0.0217138920, Train ROC AUC: 0.4869185960, Val ROC AUC: 0.4811524537, Test ROC AUC: 0.4804339924\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 87, Loss: 0.0216461252, Train ROC AUC: 0.4868867046, Val ROC AUC: 0.4811773324, Test ROC AUC: 0.4804199186\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 88, Loss: 0.0215721503, Train ROC AUC: 0.4868433591, Val ROC AUC: 0.4812065503, Test ROC AUC: 0.4804090634\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 89, Loss: 0.0215103254, Train ROC AUC: 0.4868062167, Val ROC AUC: 0.4812361674, Test ROC AUC: 0.4804021326\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 90, Loss: 0.0214736052, Train ROC AUC: 0.4867880188, Val ROC AUC: 0.4812620893, Test ROC AUC: 0.4803908400\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 91, Loss: 0.0213868041, Train ROC AUC: 0.4867445188, Val ROC AUC: 0.4812812000, Test ROC AUC: 0.4803774294\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 92, Loss: 0.0213099383, Train ROC AUC: 0.4866978013, Val ROC AUC: 0.4812930017, Test ROC AUC: 0.4803580646\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 93, Loss: 0.0212508440, Train ROC AUC: 0.4866318049, Val ROC AUC: 0.4813043055, Test ROC AUC: 0.4803348352\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 94, Loss: 0.0211833734, Train ROC AUC: 0.4865827709, Val ROC AUC: 0.4813207299, Test ROC AUC: 0.4803167920\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 95, Loss: 0.0211818404, Train ROC AUC: 0.4865385759, Val ROC AUC: 0.4813324677, Test ROC AUC: 0.4802917375\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 96, Loss: 0.0210670158, Train ROC AUC: 0.4865152558, Val ROC AUC: 0.4813445955, Test ROC AUC: 0.4802690117\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 97, Loss: 0.0210251063, Train ROC AUC: 0.4864836217, Val ROC AUC: 0.4813536312, Test ROC AUC: 0.4802424971\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 98, Loss: 0.0209835786, Train ROC AUC: 0.4864344590, Val ROC AUC: 0.4813631770, Test ROC AUC: 0.4802204410\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 99, Loss: 0.0209641345, Train ROC AUC: 0.4864072265, Val ROC AUC: 0.4813744804, Test ROC AUC: 0.4802015239\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 100, Loss: 0.0209037587, Train ROC AUC: 0.4863754123, Val ROC AUC: 0.4813857381, Test ROC AUC: 0.4801831112\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 101, Loss: 0.0208723769, Train ROC AUC: 0.4863696981, Val ROC AUC: 0.4813867517, Test ROC AUC: 0.4801790510\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 102, Loss: 0.0207878742, Train ROC AUC: 0.4863528901, Val ROC AUC: 0.4813869591, Test ROC AUC: 0.4801747022\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 103, Loss: 0.0208107848, Train ROC AUC: 0.4863418220, Val ROC AUC: 0.4813877340, Test ROC AUC: 0.4801701509\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 104, Loss: 0.0208288655, Train ROC AUC: 0.4863350782, Val ROC AUC: 0.4813883501, Test ROC AUC: 0.4801656623\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 105, Loss: 0.0208217911, Train ROC AUC: 0.4863188108, Val ROC AUC: 0.4813895377, Test ROC AUC: 0.4801607622\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 106, Loss: 0.0208027940, Train ROC AUC: 0.4863040877, Val ROC AUC: 0.4813900955, Test ROC AUC: 0.4801556225\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 107, Loss: 0.0208262149, Train ROC AUC: 0.4862884895, Val ROC AUC: 0.4813900942, Test ROC AUC: 0.4801495466\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 108, Loss: 0.0207679812, Train ROC AUC: 0.4862780649, Val ROC AUC: 0.4813891150, Test ROC AUC: 0.4801445540\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 109, Loss: 0.0208011586, Train ROC AUC: 0.4862648605, Val ROC AUC: 0.4813890098, Test ROC AUC: 0.4801385319\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 110, Loss: 0.0207954366, Train ROC AUC: 0.4862522223, Val ROC AUC: 0.4813891589, Test ROC AUC: 0.4801318990\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 111, Loss: 0.0207782183, Train ROC AUC: 0.4862374992, Val ROC AUC: 0.4813887632, Test ROC AUC: 0.4801260300\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 112, Loss: 0.0207769405, Train ROC AUC: 0.4862290051, Val ROC AUC: 0.4813880618, Test ROC AUC: 0.4801201592\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 113, Loss: 0.0207444299, Train ROC AUC: 0.4862227247, Val ROC AUC: 0.4813869917, Test ROC AUC: 0.4801144790\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 114, Loss: 0.0207592770, Train ROC AUC: 0.4862128921, Val ROC AUC: 0.4813857807, Test ROC AUC: 0.4801074840\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 115, Loss: 0.0207406953, Train ROC AUC: 0.4862014380, Val ROC AUC: 0.4813839144, Test ROC AUC: 0.4801008236\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 116, Loss: 0.0207056310, Train ROC AUC: 0.4861891602, Val ROC AUC: 0.4813822660, Test ROC AUC: 0.4800932425\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 117, Loss: 0.0207161866, Train ROC AUC: 0.4861771655, Val ROC AUC: 0.4813800797, Test ROC AUC: 0.4800855289\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 118, Loss: 0.0207662918, Train ROC AUC: 0.4861666380, Val ROC AUC: 0.4813772816, Test ROC AUC: 0.4800784910\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 119, Loss: 0.0206851810, Train ROC AUC: 0.4861525584, Val ROC AUC: 0.4813747391, Test ROC AUC: 0.4800705594\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 120, Loss: 0.0207065940, Train ROC AUC: 0.4861421853, Val ROC AUC: 0.4813726872, Test ROC AUC: 0.4800632019\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 121, Loss: 0.0206631925, Train ROC AUC: 0.4861348238, Val ROC AUC: 0.4813711848, Test ROC AUC: 0.4800566636\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 122, Loss: 0.0207115076, Train ROC AUC: 0.4861205383, Val ROC AUC: 0.4813700578, Test ROC AUC: 0.4800497620\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 123, Loss: 0.0207137000, Train ROC AUC: 0.4861070764, Val ROC AUC: 0.4813696851, Test ROC AUC: 0.4800424260\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 124, Loss: 0.0206326526, Train ROC AUC: 0.4860983249, Val ROC AUC: 0.4813692598, Test ROC AUC: 0.4800366576\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 125, Loss: 0.0206910409, Train ROC AUC: 0.4860887241, Val ROC AUC: 0.4813686472, Test ROC AUC: 0.4800303370\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 126, Loss: 0.0206843521, Train ROC AUC: 0.4860750048, Val ROC AUC: 0.4813688176, Test ROC AUC: 0.4800243204\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 127, Loss: 0.0206433926, Train ROC AUC: 0.4860632161, Val ROC AUC: 0.4813683980, Test ROC AUC: 0.4800183219\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 128, Loss: 0.0206196159, Train ROC AUC: 0.4860546190, Val ROC AUC: 0.4813682867, Test ROC AUC: 0.4800132739\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 129, Loss: 0.0206443984, Train ROC AUC: 0.4860467427, Val ROC AUC: 0.4813672070, Test ROC AUC: 0.4800080422\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 130, Loss: 0.0205923803, Train ROC AUC: 0.4860326631, Val ROC AUC: 0.4813676875, Test ROC AUC: 0.4800026264\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 131, Loss: 0.0206476469, Train ROC AUC: 0.4860258164, Val ROC AUC: 0.4813671814, Test ROC AUC: 0.4799969960\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 132, Loss: 0.0206133183, Train ROC AUC: 0.4860172708, Val ROC AUC: 0.4813657303, Test ROC AUC: 0.4799909838\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 133, Loss: 0.0206550509, Train ROC AUC: 0.4860134356, Val ROC AUC: 0.4813660099, Test ROC AUC: 0.4799855689\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 134, Loss: 0.0206317157, Train ROC AUC: 0.4860096261, Val ROC AUC: 0.4813651616, Test ROC AUC: 0.4799813538\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 135, Loss: 0.0205705296, Train ROC AUC: 0.4859978116, Val ROC AUC: 0.4813639354, Test ROC AUC: 0.4799767427\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 136, Loss: 0.0206177942, Train ROC AUC: 0.4859903214, Val ROC AUC: 0.4813634957, Test ROC AUC: 0.4799715794\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 137, Loss: 0.0205900166, Train ROC AUC: 0.4859754181, Val ROC AUC: 0.4813621304, Test ROC AUC: 0.4799663197\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 138, Loss: 0.0205975939, Train ROC AUC: 0.4859715314, Val ROC AUC: 0.4813599889, Test ROC AUC: 0.4799623494\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 139, Loss: 0.0205953009, Train ROC AUC: 0.4859645560, Val ROC AUC: 0.4813576160, Test ROC AUC: 0.4799578475\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 140, Loss: 0.0205550641, Train ROC AUC: 0.4859546977, Val ROC AUC: 0.4813548840, Test ROC AUC: 0.4799535744\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 141, Loss: 0.0205495246, Train ROC AUC: 0.4859449681, Val ROC AUC: 0.4813529503, Test ROC AUC: 0.4799493693\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 142, Loss: 0.0205355026, Train ROC AUC: 0.4859392797, Val ROC AUC: 0.4813520041, Test ROC AUC: 0.4799462986\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 143, Loss: 0.0205419082, Train ROC AUC: 0.4859338228, Val ROC AUC: 0.4813507674, Test ROC AUC: 0.4799433033\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 144, Loss: 0.0205294788, Train ROC AUC: 0.4859256376, Val ROC AUC: 0.4813502317, Test ROC AUC: 0.4799399969\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 145, Loss: 0.0205725227, Train ROC AUC: 0.4859225746, Val ROC AUC: 0.4813496077, Test ROC AUC: 0.4799368162\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 146, Loss: 0.0205472857, Train ROC AUC: 0.4859169891, Val ROC AUC: 0.4813486937, Test ROC AUC: 0.4799336479\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 147, Loss: 0.0205279998, Train ROC AUC: 0.4859095761, Val ROC AUC: 0.4813481798, Test ROC AUC: 0.4799301864\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 148, Loss: 0.0205449369, Train ROC AUC: 0.4859033728, Val ROC AUC: 0.4813478854, Test ROC AUC: 0.4799269816\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 149, Loss: 0.0205132868, Train ROC AUC: 0.4859018027, Val ROC AUC: 0.4813481311, Test ROC AUC: 0.4799236701\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Classes predicted: [0 1]\n",
      "Epoch: 150, Loss: 0.0205043554, Train ROC AUC: 0.4858924078, Val ROC AUC: 0.4813480658, Test ROC AUC: 0.4799199784\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class GraphSAGEModel(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_layers, num_classes):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_node_features, hidden_layers[0])\n",
    "        self.conv2 = SAGEConv(hidden_layers[0], hidden_layers[1])\n",
    "        self.conv3 = SAGEConv(hidden_layers[1], num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        return torch.sigmoid(x.view(-1))\n",
    "\n",
    "# Use the GraphSAGE model\n",
    "hidden_layers = [64, 64]  \n",
    "model = GraphSAGEModel(graph.num_node_features, hidden_layers, 1).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.2)\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[targets.long()].view(-1, 1)\n",
    "            logpt = -F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "            logpt = logpt * alpha_t\n",
    "        else:\n",
    "            logpt = -F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        \n",
    "        pt = torch.exp(logpt)\n",
    "        F_loss = -((1 - pt) ** self.gamma) * logpt\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "class_counts = graph.y[graph.train_mask].bincount(minlength=2).float()\n",
    "class_weights = 1. / class_counts\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = class_weights.detach().to(device)  # Add to(device)\n",
    "print(class_weights)\n",
    "\n",
    "loss_fn = FocalLoss(alpha=class_weights, gamma=2)\n",
    "\n",
    "def train(data):\n",
    "    data = data.to(device)  # Add this line\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)[data.train_mask].squeeze()\n",
    "    loss = loss_fn(out, data.y[data.train_mask].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()  # Update learning rate\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(data, mask):\n",
    "    data = data.to(device)  # Add this line\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)[mask].squeeze()  # Predicted probabilities\n",
    "        preds = (out > 0.5).long()  # Binary predictions\n",
    "        print(f\"Classes predicted: {preds.unique().cpu().numpy()}\")  # Move to CPU before converting to NumPy\n",
    "        accuracy = preds.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        precision = precision_score(data.y[mask].cpu().numpy(), preds.cpu().numpy(), zero_division=1)  # Move to CPU\n",
    "        recall = recall_score(data.y[mask].cpu().numpy(), preds.cpu().numpy(), zero_division=1)  # Move to CPU\n",
    "        f1 = f1_score(data.y[mask].cpu().numpy(), preds.cpu().numpy(), zero_division=1)  # Move to CPU\n",
    "        roc_auc = roc_auc_score(data.y[mask].cpu().numpy(), out.cpu().numpy())  # Use out, not preds\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "\n",
    "for epoch in range(150):\n",
    "    loss = train(graph)\n",
    "    train_metrics = evaluate(graph, graph.train_mask)\n",
    "    val_metrics = evaluate(graph, graph.val_mask)\n",
    "    test_metrics = evaluate(graph, graph.test_mask)\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss:.10f}, Train ROC AUC: {train_metrics[4]:.10f}, Val ROC AUC: {val_metrics[4]:.10f}, Test ROC AUC: {test_metrics[4]:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d6780-b31b-4cf9-bc60-f513b87d93d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
