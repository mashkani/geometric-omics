{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8135f00d-05d2-4652-a01d-c47e77855f44",
   "metadata": {},
   "source": [
    "# Predicting Causal SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c81768a-68f0-4a35-8903-ed78915e978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "NumPy version: 1.24.1\n",
      "Pandas version: 1.5.3\n",
      "Matplotlib version: 3.7.1\n",
      "Scikit-learn version: 1.3.0\n",
      "Torch version: 2.0.1+cu117\n",
      "Torch Geometric version: 2.3.1\n",
      "NetworkX version: 3.0\n",
      "Using NVIDIA RTX A6000 (cuda)\n",
      "CUDA version: 11.7\n",
      "Number of CUDA devices: 2\n"
     ]
    }
   ],
   "source": [
    "# You can get rid of whatever libraries you dont need\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from numba import jit, prange\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "import networkx as nx\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.special import expit\n",
    "from typing import List, Dict\n",
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "import category_encoders as ce\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import copy\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "# Print versions of imported libraries\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Torch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2788a26-5087-40df-b72b-de4923abb7c4",
   "metadata": {},
   "source": [
    "## Spec\n",
    "\n",
    "### Data Description\n",
    "\n",
    "The dataset is a Pandas DataFrame named `data`, which includes the following columns:\n",
    "\n",
    "- `id`: Unique ID of the variant in the format #chrom:pos:ref:alt (string).\n",
    "- `#chrom`: Chromosome number where the genetic variant is located.\n",
    "- `pos`: Position of the genetic variant on the chromosome (integer between 1 and 200,000).\n",
    "- `ref`: Reference allele (or variant) at the genomic position.\n",
    "- `alt`: Alternate allele observed at the genomic position.\n",
    "- `rsids`: Reference SNP cluster ID, a unique identifier for each variant used in the dbSNP database.\n",
    "- `nearest_genes`: Gene nearest to the variant (string).\n",
    "- `pval`: P-value, a statistical measure for the strength of evidence against the null hypothesis.\n",
    "- `mlogp`: Minus log of the p-value, commonly used in genomic studies.\n",
    "- `beta`: Beta coefficient, representing the effect size of the variant.\n",
    "- `sebeta`: Standard error of the beta coefficient.\n",
    "- `af_alt`: Allele frequency of the alternate variant in the general population (float between 0 and 1).\n",
    "- `af_alt_cases`: Allele frequency of the alternate variant in the cases group (float between 0 and 1).\n",
    "- `af_alt_controls`: Allele frequency of the alternate variant in the control group (float between 0 and 1).\n",
    "- `finemapped`: Indicator whether the variant is included in the post-finemapped subset (1) or not (0) (integer).\n",
    "- `precausal`: Indicator whether the variant is included in the precausal subset (1) or not (0) (integer).\n",
    "- `causal`: Indicator whether the variant is included in the causal subset (1) or not (0) (integer).\n",
    "- `trait`: Trait associated with the variant. In this dataset, it refers to the response to the drug paracetamol and NSAIDs.\n",
    "\n",
    "### Data Subset \n",
    "From least likely to be causal (left) to most likely to be causal (right):\n",
    "\n",
    "GWAS (20 million SNPs) --> Finemapped (3 million SNPs) --> Precausal (1300 SNPs) --> Causal (21 SNPs)\n",
    "\n",
    "### Task Overview\n",
    "\n",
    "The task is to build a binary classifier that predicts whether a SNP is included in the causal dataset (i.e., `causal=1`).\n",
    "\n",
    "### Resources \n",
    "- FinnGen Docs: https://finngen.gitbook.io/documentation/\n",
    "- GWAS YouTube Video: https://www.youtube.com/watch?v=sOP8WacfBM8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5786d9cc-1279-4892-a87b-1a982dd9d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'int64',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'finemapped': 'int64',\n",
    "    'precausal': 'int64',\n",
    "    'causal': 'int64'\n",
    "}\n",
    "\n",
    "data = pd.read_csv('t2d-precausal-2-causal.csv', dtype=dtypes)\n",
    "\n",
    "# Assert column names\n",
    "expected_columns = ['#chrom', 'pos', 'ref', 'alt', 'rsids', 'nearest_genes', 'pval', 'mlogp', 'beta',\n",
    "                    'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls', 'finemapped',\n",
    "                    'id', 'trait', 'causal', 'precausal']\n",
    "assert set(data.columns) == set(expected_columns), \"Unexpected columns in the data DataFrame.\"\n",
    "\n",
    "# Assert data types\n",
    "expected_dtypes = {\n",
    "    'id': 'string',\n",
    "    '#chrom': 'int64',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'finemapped': 'int64',\n",
    "    'precausal': 'int64',\n",
    "    'causal': 'int64'\n",
    "}\n",
    "\n",
    "for col, expected_dtype in expected_dtypes.items():\n",
    "    assert data[col].dtype == expected_dtype, f\"Unexpected data type for column {col}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c584b1-60aa-4d15-ac36-e555700b5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "df = pd.read_csv('t2d-precausal-2-causal.csv')\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b780db71-b3f3-405e-9c22-3936b46c51c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming you already have a DataFrame 'df' and you want to encode its 'ref' column\n",
    "\n",
    "# First, we create an instance of the OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Reshape your data as 'fit_transform' expects 2D and 'df['ref']' is 1D\n",
    "reshaped_data = df['ref'].values.reshape(-1, 1)\n",
    "\n",
    "# Use the encoder to fit_transform your data\n",
    "one_hot_encoded_data = one_hot_encoder.fit_transform(reshaped_data)\n",
    "\n",
    "# The output is an array which you can convert into a DataFrame\n",
    "df_encoded = pd.DataFrame(one_hot_encoded_data, columns=one_hot_encoder.get_feature_names_out(['ref']))\n",
    "\n",
    "# Optionally, if you want to add this data back into your original DataFrame, you can do so\n",
    "df = pd.concat([df, df_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90245c88-dfd4-49ee-9d56-c7e50744e2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#chrom', 'pos', 'ref', 'alt', 'rsids', 'nearest_genes', 'pval',\n",
       "       'mlogp', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls',\n",
       "       'id', 'finemapped', 'causal', 'precausal', 'trait', 'ref_A',\n",
       "       'ref_AAAATGATTGG', 'ref_ACAAGTAAATGC', 'ref_AG', 'ref_AT', 'ref_C',\n",
       "       'ref_CA', 'ref_CAA', 'ref_CT', 'ref_G', 'ref_GA', 'ref_GAA', 'ref_GT',\n",
       "       'ref_T', 'ref_TA', 'ref_TAA', 'ref_TG', 'ref_TGCA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b5a93-da65-49b6-a399-4f766df71a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "data[['pos', 'mlogp']] = scaler.fit_transform(data[['pos', 'mlogp']])\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a color map for finemapped status\n",
    "colors = {0: 'blue', 1: 'red'}\n",
    "\n",
    "chromosomes = data['#chrom'].unique()\n",
    "\n",
    "for chrom in chromosomes:\n",
    "    data_chrom = data[data['#chrom'] == chrom]\n",
    "    \n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.scatterplot(x='pos', y='mlogp', hue='causal', data=data_chrom, palette=colors)\n",
    "    \n",
    "    plt.title(f'Chromosome {chrom}: Position vs mlogp (scaled with RobustScaler)')\n",
    "    plt.xlabel('Position (scaled)')\n",
    "    plt.ylabel('mlogp (scaled)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154565c-9e9a-468e-843e-c4fc85c454fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
