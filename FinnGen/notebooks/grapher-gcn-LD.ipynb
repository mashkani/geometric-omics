{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00910a35-ffbc-4497-bcc8-21f008c326fb",
   "metadata": {},
   "source": [
    "# Grapher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1805a-55dc-409c-9ccf-512eb1f88667",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8ec1d-73be-4b8c-95dc-79489e84998b",
   "metadata": {},
   "source": [
    "- `#chrom`: This column represents the chromosome number where the genetic variant is located.\n",
    "\n",
    "- `pos`: This is the position of the genetic variant on the chromosome.\n",
    "\n",
    "- `ref`: This column represents the reference allele (or variant) at the genomic position.\n",
    "\n",
    "- `alt`: This is the alternate allele observed at this position.\n",
    "\n",
    "- `rsids`: This stands for reference SNP cluster ID. It's a unique identifier for each variant used in the dbSNP database.\n",
    "\n",
    "- `nearest_genes`: This column represents the gene which is nearest to the variant.\n",
    "\n",
    "- `pval`: This represents the p-value, which is a statistical measure for the strength of evidence against the null hypothesis.\n",
    "\n",
    "- `mlogp`: This represents the minus log of the p-value, commonly used in genomic studies.\n",
    "\n",
    "- `beta`: The beta coefficient represents the effect size of the variant.\n",
    "\n",
    "- `sebeta`: This is the standard error of the beta coefficient.\n",
    "\n",
    "- `af_alt`: This is the allele frequency of the alternate variant in the general population.\n",
    "\n",
    "- `af_alt_cases`: This is the allele frequency of the alternate variant in the cases group.\n",
    "\n",
    "- `af_alt_controls`: This is the allele frequency of the alternate variant in the control group.\n",
    "\n",
    "- `causal`: This binary column indicates whether the variant is determined to be causal (1) or not (0).\n",
    "\n",
    "- `LD`: This binary column indicates whether the variant is determined to be in linkage disequilibrium (1) or not (0).\n",
    "\n",
    "- `lead`: This string column contains the rsid of the SNP of which the variant is in LD with.\n",
    "\n",
    "- `lead_in_rsids`: This boolean column indicates whether the rsid in the `lead` column is in another row of the `rsids` column (`True`) or not (`False`).\n",
    "\n",
    "- `trait`: This column represents the trait associated with the variant. In this dataset, it is the response to the drug paracetamol and NSAIDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b033d-95f5-4584-b10c-72969a166612",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4345459-b1ef-477c-8f06-c8f54c194af0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]\n",
      "NumPy version: 1.24.3\n",
      "Pandas version: 2.0.1\n",
      "Matplotlib version: 3.7.1\n",
      "Scikit-learn version: 1.2.2\n",
      "Torch version: 2.0.0+cu118\n",
      "Torch Geometric version: 2.3.1\n",
      "NetworkX version: 3.0\n",
      "Using NVIDIA GeForce RTX 3060 Ti (cuda)\n",
      "CUDA version: 11.8\n",
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "import networkx as nx\n",
    "from scipy.spatial import cKDTree\n",
    "from typing import List, Dict\n",
    "import time\n",
    "\n",
    "# Print versions of imported libraries\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Torch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddfa8cb-01df-491f-94f0-c8c228256b4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fe5b06-7392-4d62-a1e8-af081cdf3e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    '#chrom': 'string',\n",
    "    'pos': 'int64',\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': 'float64',\n",
    "    'mlogp': 'float64',\n",
    "    'beta': 'float64',\n",
    "    'sebeta': 'float64',\n",
    "    'af_alt': 'float64',\n",
    "    'af_alt_cases': 'float64',\n",
    "    'af_alt_controls': 'float64',\n",
    "    'causal': 'int64',\n",
    "    'LD': 'int64',\n",
    "    'lead': 'string',\n",
    "    'lead_in_rsids': 'bool',\n",
    "    'trait': 'string'\n",
    "}\n",
    "\n",
    "data = pd.read_csv('~/Desktop/gwas-graph/FinnGen/data/gwas-causal.csv', dtype=dtypes)\n",
    "\n",
    "# Assert column names\n",
    "expected_columns = ['#chrom', 'pos', 'ref', 'alt', 'rsids', 'nearest_genes', 'pval', 'mlogp', 'beta',\n",
    "                    'sebeta', 'af_alt', 'af_alt_cases', 'af_alt_controls', 'causal', 'LD', 'lead',\n",
    "                    'lead_in_rsids', 'trait']\n",
    "assert set(data.columns) == set(expected_columns), \"Unexpected columns in the data DataFrame.\"\n",
    "\n",
    "# Assert data types\n",
    "expected_dtypes = {\n",
    "    '#chrom': 'string',\n",
    "    'pos': np.int64,\n",
    "    'ref': 'string',\n",
    "    'alt': 'string',\n",
    "    'rsids': 'string',\n",
    "    'nearest_genes': 'string',\n",
    "    'pval': np.float64,\n",
    "    'mlogp': np.float64,\n",
    "    'beta': np.float64,\n",
    "    'sebeta': np.float64,\n",
    "    'af_alt': np.float64,\n",
    "    'af_alt_cases': np.float64,\n",
    "    'af_alt_controls': np.float64,\n",
    "    'causal': np.int64,\n",
    "    'LD': np.int64,\n",
    "    'lead': 'string',\n",
    "    'lead_in_rsids': bool,\n",
    "    'trait': 'string'\n",
    "}\n",
    "\n",
    "for col, expected_dtype in expected_dtypes.items():\n",
    "    assert data[col].dtype == expected_dtype, f\"Unexpected data type for column {col}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d6d595-4ef8-41d5-b0a5-dbdc9f2d9b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in each column:\n",
      "#chrom                    0\n",
      "pos                       0\n",
      "ref                       0\n",
      "alt                       0\n",
      "rsids               1366396\n",
      "nearest_genes        727855\n",
      "pval                      0\n",
      "mlogp                     0\n",
      "beta                      0\n",
      "sebeta                    0\n",
      "af_alt                    0\n",
      "af_alt_cases              0\n",
      "af_alt_controls           0\n",
      "causal                    0\n",
      "LD                        0\n",
      "lead               20117400\n",
      "lead_in_rsids             0\n",
      "trait                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for total number of null values in each column\n",
    "null_counts = data.isnull().sum()\n",
    "\n",
    "print(\"Total number of null values in each column:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a754a-7836-439e-801c-7efca6d2dfc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc4255-7a42-4172-a91d-4df08665fccc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create new rows per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b729972-b0d7-4e38-b8e2-aedd07506c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['nearest_genes'] = data['nearest_genes'].astype(str)\n",
    "\n",
    "# Assert column 'nearest_genes' is a string\n",
    "assert data['nearest_genes'].dtype == 'object', \"Column 'nearest_genes' is not of string type.\"\n",
    "\n",
    "# Split the gene names in the 'nearest_genes' column\n",
    "split_genes = data['nearest_genes'].str.split(',')\n",
    "\n",
    "# Flatten the list of split gene names\n",
    "flat_genes = [item for sublist in split_genes for item in sublist]\n",
    "\n",
    "# Create a new DataFrame by repeating rows and substituting the gene names\n",
    "data_new = data.loc[data.index.repeat(split_genes.str.len())].copy()\n",
    "data_new['nearest_genes'] = flat_genes\n",
    "\n",
    "# Assert the shape of the new DataFrame is as expected\n",
    "expected_shape = (len(flat_genes), data.shape[1])\n",
    "assert data_new.shape == expected_shape, \"Shape of the new DataFrame is not as expected.\"\n",
    "\n",
    "# Reset index to have a standard index\n",
    "data = data_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513cafa0-f3f8-47b5-9d22-96062449edde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>rsids</th>\n",
       "      <th>nearest_genes</th>\n",
       "      <th>pval</th>\n",
       "      <th>mlogp</th>\n",
       "      <th>beta</th>\n",
       "      <th>sebeta</th>\n",
       "      <th>af_alt</th>\n",
       "      <th>af_alt_cases</th>\n",
       "      <th>af_alt_controls</th>\n",
       "      <th>causal</th>\n",
       "      <th>LD</th>\n",
       "      <th>lead</th>\n",
       "      <th>lead_in_rsids</th>\n",
       "      <th>trait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13668</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>rs2691328</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.024860</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>0.084918</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rs912813</td>\n",
       "      <td>True</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14773</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>rs878915777</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.844305</td>\n",
       "      <td>0.073501</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>0.013485</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15585</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>rs533630043</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.841908</td>\n",
       "      <td>0.074735</td>\n",
       "      <td>0.031464</td>\n",
       "      <td>0.157751</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16549</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>rs1262014613</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.343308</td>\n",
       "      <td>0.464316</td>\n",
       "      <td>0.241377</td>\n",
       "      <td>0.254711</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16567</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>rs1194064194</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.130736</td>\n",
       "      <td>0.086319</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565622</th>\n",
       "      <td>23</td>\n",
       "      <td>155697920</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.027115</td>\n",
       "      <td>1.566790</td>\n",
       "      <td>-0.013475</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.290961</td>\n",
       "      <td>0.286054</td>\n",
       "      <td>0.291879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565623</th>\n",
       "      <td>23</td>\n",
       "      <td>155698443</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.178417</td>\n",
       "      <td>0.748564</td>\n",
       "      <td>-0.069907</td>\n",
       "      <td>0.051951</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565624</th>\n",
       "      <td>23</td>\n",
       "      <td>155698490</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.279640</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>-0.020245</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>0.024312</td>\n",
       "      <td>0.024423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565625</th>\n",
       "      <td>23</td>\n",
       "      <td>155699751</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.078864</td>\n",
       "      <td>1.103120</td>\n",
       "      <td>-0.011284</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.244829</td>\n",
       "      <td>0.241257</td>\n",
       "      <td>0.245498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565626</th>\n",
       "      <td>23</td>\n",
       "      <td>155700291</td>\n",
       "      <td>CAA</td>\n",
       "      <td>C</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.071590</td>\n",
       "      <td>1.145150</td>\n",
       "      <td>-0.011563</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.245328</td>\n",
       "      <td>0.241724</td>\n",
       "      <td>0.246003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>T2D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20565627 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         #chrom        pos  ref alt         rsids nearest_genes      pval   \n",
       "0             1      13668    G   A     rs2691328         OR4F5  0.944365  \\\n",
       "1             1      14773    C   T   rs878915777         OR4F5  0.844305   \n",
       "2             1      15585    G   A   rs533630043         OR4F5  0.841908   \n",
       "3             1      16549    T   C  rs1262014613         OR4F5  0.343308   \n",
       "4             1      16567    G   C  rs1194064194         OR4F5  0.129883   \n",
       "...         ...        ...  ...  ..           ...           ...       ...   \n",
       "20565622     23  155697920    G   A          <NA>          <NA>  0.027115   \n",
       "20565623     23  155698443    C   A          <NA>          <NA>  0.178417   \n",
       "20565624     23  155698490    C   T          <NA>          <NA>  0.279640   \n",
       "20565625     23  155699751    C   T          <NA>          <NA>  0.078864   \n",
       "20565626     23  155700291  CAA   C          <NA>          <NA>  0.071590   \n",
       "\n",
       "             mlogp      beta    sebeta    af_alt  af_alt_cases   \n",
       "0         0.024860 -0.005926  0.084918  0.005842      0.005729  \\\n",
       "1         0.073501  0.010088  0.051369  0.013495      0.013547   \n",
       "2         0.074735  0.031464  0.157751  0.001113      0.001125   \n",
       "3         0.464316  0.241377  0.254711  0.000561      0.000620   \n",
       "4         0.886447  0.130736  0.086319  0.004170      0.004250   \n",
       "...            ...       ...       ...       ...           ...   \n",
       "20565622  1.566790 -0.013475  0.006097  0.290961      0.286054   \n",
       "20565623  0.748564 -0.069907  0.051951  0.003259      0.003022   \n",
       "20565624  0.553400 -0.020245  0.018725  0.024406      0.024312   \n",
       "20565625  1.103120 -0.011284  0.006421  0.244829      0.241257   \n",
       "20565626  1.145150 -0.011563  0.006418  0.245328      0.241724   \n",
       "\n",
       "          af_alt_controls  causal  LD      lead  lead_in_rsids trait  \n",
       "0                0.005863       0   0  rs912813           True   T2D  \n",
       "1                0.013485       0   0      <NA>          False   T2D  \n",
       "2                0.001110       0   0      <NA>          False   T2D  \n",
       "3                0.000550       0   0      <NA>          False   T2D  \n",
       "4                0.004154       0   0      <NA>          False   T2D  \n",
       "...                   ...     ...  ..       ...            ...   ...  \n",
       "20565622         0.291879       0   0      <NA>          False   T2D  \n",
       "20565623         0.003304       0   0      <NA>          False   T2D  \n",
       "20565624         0.024423       0   0      <NA>          False   T2D  \n",
       "20565625         0.245498       0   0      <NA>          False   T2D  \n",
       "20565626         0.246003       0   0      <NA>          False   T2D  \n",
       "\n",
       "[20565627 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e14ab37-9bcf-458b-882d-94604efbc5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in 'rsids' column\n",
    "data.dropna(subset=['rsids'], inplace=True)\n",
    "\n",
    "# Assert that there are no NaN values in the 'rsids' column\n",
    "assert data['rsids'].isnull().sum() == 0, \"NaN values still present in the 'rsids' column.\"\n",
    "\n",
    "# Keep only rows with unique values in 'rsids' column\n",
    "duplicate_mask = data.duplicated(subset='rsids', keep=False)\n",
    "data = data[~duplicate_mask]\n",
    "\n",
    "# Assert that there are no duplicate values in the 'rsids' column\n",
    "assert data['rsids'].duplicated().sum() == 0, \"Duplicate values still present in the 'rsids' column.\"\n",
    "\n",
    "# Adjust the index if necessary\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eddaed-2f48-4440-b6d6-0dc247f23ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe89142-2b65-469b-b330-1620d303312b",
   "metadata": {},
   "source": [
    "**Task Overview**\n",
    "- The objective is to design and implement a link prediction deep neural network model for predicting Linkage Disequilibrium between SNPs.\n",
    "\n",
    "**Nodes and Their Features**\n",
    "- There is one types of node: SNP nodes.\n",
    "- *SNP Nodes*: Each SNP Node is characterized by various features, including `rsids`, `nearest_genes`, `#chrom`, `pos`, `ref`, `alt`, `beta`, `sebeta`, `af_alt`, and `af_alt_cases` columns.\n",
    "\n",
    "**Edges, Their Features, and Labels**\n",
    "- Edges represent relationships between nodes. There is one type of edge: SNP-SNP.\n",
    "- *SNP-SNP Edges*:\n",
    "  - These edges are undirected, linking an SNP Node (as identified by the `rsids` column) to another SNP Node (as identified by the `lead` column) in the same data row.\n",
    "  - The label for each edge is determined by the `LD` column in the data:\n",
    "    - A label of +1 is assigned when `data['LD']` is 1, signifying that the two SNPs are in linkage disequilibrium.\n",
    "    - A label of -1 is assigned when `data['LD']` is 0, indicating that the two SNPs are not in linkage disequilibrium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abe533-6610-4f82-b8d6-533eb010858d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f0a2540-a59c-4869-a2f2-f2f93c3e4ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique SNPs: 18295392\n",
      "Number of positive SNP-SNP edges: 28\n",
      "Number of nodes: 18295392\n",
      "Number of edges: 28\n",
      "Node feature dimension: 9\n",
      "Execution time: 146.22503781318665 seconds\n"
     ]
    }
   ],
   "source": [
    "def get_unique_snps(data: pd.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Function to create mappings for SNPs to integer indices.\n",
    "    \"\"\"\n",
    "    assert 'rsids' in data.columns, \"rsids column is missing in the data DataFrame.\"\n",
    "    assert not data['rsids'].isnull().any(), \"rsids column contains NaN values.\"\n",
    "\n",
    "    return {snp: idx for idx, snp in enumerate(data['rsids'].unique())}\n",
    "\n",
    "\n",
    "def preprocess_snp_features(data: pd.DataFrame, snp_to_idx: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to create node feature vectors for SNPs and preprocess categorical and numerical features.\n",
    "    \"\"\"\n",
    "    assert 'rsids' in data.columns, \"rsids column is missing in the data DataFrame.\"\n",
    "    assert not data['rsids'].isnull().any(), \"rsids column contains NaN values.\"\n",
    "\n",
    "    snp_features = data.loc[data['rsids'].isin(snp_to_idx.keys()),\n",
    "                            ['rsids', 'nearest_genes', '#chrom', 'pos', 'ref', 'alt', 'beta', 'sebeta',\n",
    "                             'af_alt', 'af_alt_cases']].drop_duplicates().set_index('rsids').sort_index()\n",
    "\n",
    "    # Fill NaNs with appropriate replacements\n",
    "    nan_replacements = {'nearest_genes': 'N/A', '#chrom': 'N/A', 'pos': 0, 'ref': 'N/A', 'alt': 'N/A',\n",
    "                        'beta': 0, 'sebeta': 0, 'af_alt': 0, 'af_alt_cases': 0}\n",
    "\n",
    "    for col in snp_features.columns:\n",
    "        assert col in nan_replacements, f\"{col} column is missing in nan_replacements dictionary.\"\n",
    "\n",
    "    # Impute missing values with appropriate replacements\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=nan_replacements)\n",
    "    snp_features = pd.DataFrame(imputer.fit_transform(snp_features), columns=snp_features.columns)\n",
    "\n",
    "    # Assert no empty or null values in features\n",
    "    assert not snp_features.isnull().any().any(), \"Features contain null values.\"\n",
    "    assert not snp_features.isna().any().any(), \"Features contain NaN values.\"\n",
    "    assert snp_features.size > 0, \"Features are empty.\"\n",
    "\n",
    "    # Label encoding for categorical columns and standardize numerical features\n",
    "    le = LabelEncoder()\n",
    "    scaler = StandardScaler()\n",
    "    for col in snp_features.columns:\n",
    "        if col in ['ref', 'alt', 'nearest_genes', '#chrom']:\n",
    "            snp_features[col] = le.fit_transform(snp_features[col].astype(str))\n",
    "        else:\n",
    "            snp_features[col] = pd.Series(scaler.fit_transform(snp_features[col].to_frame()).flatten())\n",
    "\n",
    "    return snp_features\n",
    "\n",
    "\n",
    "def preprocess_positive_edges(data: pd.DataFrame, snp_to_idx: Dict) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Function to create positive SNP-SNP edges and preprocess them.\n",
    "    \"\"\"\n",
    "    assert 'rsids' in data.columns, \"rsids column is missing in the data DataFrame.\"\n",
    "    assert 'lead' in data.columns, \"lead column is missing in the data DataFrame.\"\n",
    "    assert not data['rsids'].isnull().any(), \"rsids column contains NaN values.\"\n",
    "\n",
    "    positive_edges_snp_snp = data.loc[(data['LD'] == 1) & (data['rsids'].isin(snp_to_idx)) & (data['lead'].isin(snp_to_idx)),\n",
    "                                      ['rsids', 'lead']].drop_duplicates().applymap(snp_to_idx.get).values\n",
    "    assert positive_edges_snp_snp.size > 0, \"No positive SNP-SNP edges found.\"\n",
    "\n",
    "    return torch.tensor(positive_edges_snp_snp, dtype=torch.long).t().contiguous()\n",
    "\n",
    "\n",
    "def create_pytorch_graph(features: torch.Tensor, edges: torch.Tensor) -> Data:\n",
    "    \"\"\"\n",
    "    Function to create the PyTorch Geometric graph.\n",
    "    \"\"\"\n",
    "    assert isinstance(features, torch.Tensor), \"features must be a torch.Tensor.\"\n",
    "    assert isinstance(edges, torch.Tensor), \"edges must be a torch.Tensor.\"\n",
    "\n",
    "    # Create edge labels (+1 for positive edges)\n",
    "    edge_attr = torch.ones(edges.size(1), dtype=torch.float)\n",
    "\n",
    "    return Data(x=features, edge_index=edges, edge_attr=edge_attr)\n",
    "\n",
    "\n",
    "assert 'data' in globals(), \"data variable is not defined.\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "snp_to_idx = get_unique_snps(data)\n",
    "assert len(snp_to_idx) > 0, \"No unique SNPs found.\"\n",
    "print(f\"Number of unique SNPs: {len(snp_to_idx)}\")\n",
    "\n",
    "snp_features = preprocess_snp_features(data, snp_to_idx)\n",
    "features = torch.tensor(snp_features.values, dtype=torch.float)\n",
    "\n",
    "positive_edges_snp_snp = preprocess_positive_edges(data, snp_to_idx)\n",
    "assert positive_edges_snp_snp.size(1) > 0, \"No positive SNP-SNP edges found.\"\n",
    "print(f\"Number of positive SNP-SNP edges: {positive_edges_snp_snp.size(1)}\")\n",
    "\n",
    "graph = create_pytorch_graph(features, positive_edges_snp_snp)\n",
    "\n",
    "print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "print(f\"Number of edges: {graph.num_edges}\")\n",
    "print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1572767c-fd84-40b9-a802-9ba3e9689cf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "def fill_na(df, fill_values):\n",
    "    return df.fillna(fill_values)\n",
    "\n",
    "def encode_columns(df, columns):\n",
    "    le = LabelEncoder()\n",
    "    return df[columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "def scale_columns(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    return df[columns].apply(lambda x: pd.Series(scaler.fit_transform(x.values.reshape(-1, 1)).flatten(), index=x.index))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d35b0680-ae70-40e1-a573-3df6ec7575ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep copy the dataframe to avoid modifying the original data\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Convert columns into categorical data type initially to reduce redundancy\n",
    "categorical_columns = ['trait', 'rsids', 'lead']\n",
    "for col in categorical_columns:\n",
    "    data_copy[col] = data_copy[col].astype('category')\n",
    "    if 'N/A' not in data_copy[col].cat.categories:\n",
    "        data_copy[col] = data_copy[col].cat.add_categories('N/A')\n",
    "\n",
    "# Fill NaNs for 'lead' column\n",
    "data_copy['lead'] = data_copy['lead'].fillna('N/A')\n",
    "\n",
    "# Mapping traits and rsids to integers\n",
    "data_copy['trait_codes'] = data_copy['trait'].cat.codes\n",
    "data_copy['rsids_codes'] = data_copy['rsids'].cat.codes \n",
    "\n",
    "# Get unique traits and rsids\n",
    "unique_traits = data_copy['trait'].unique()\n",
    "unique_rsids = data_copy['rsids'].unique()\n",
    "\n",
    "assert len(unique_traits) == data_copy['trait'].nunique(), \"Mismatch in the number of unique traits\"\n",
    "assert len(unique_rsids) == data_copy['rsids'].nunique(), \"Mismatch in the number of unique rsids\"\n",
    "\n",
    "# Define node features and types\n",
    "node_features_columns = ['trait', 'rsids', 'nearest_genes', '#chrom', 'pos', 'ref', 'alt', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']\n",
    "node_features = data_copy[node_features_columns]\n",
    "\n",
    "# Keep the rows where either trait or rsid is unique\n",
    "node_features = node_features[node_features['trait'].isin(unique_traits) | node_features['rsids'].isin(unique_rsids)]\n",
    "\n",
    "# Create a new row with only 'trait' value and NaNs for all other cols\n",
    "new_row = pd.DataFrame([['trait'] + [np.nan] * (node_features.shape[1] - 1)], columns=node_features.columns)\n",
    "node_features = pd.concat([node_features, new_row], ignore_index=True)\n",
    "\n",
    "print(\"Node feature shape\", node_features.shape[0])\n",
    "print(\"Number of unique traits:\", len(unique_traits))\n",
    "print(\"Number of unique rsids:\", len(unique_rsids))\n",
    "\n",
    "# The node_features should not double the sum of unique traits and rsids\n",
    "assert node_features.shape[0] == len(unique_traits) + len(unique_rsids), \"Mismatch in the number of nodes and unique traits/rsids\"\n",
    "\n",
    "# Define node types separately for traits and unique rsids values\n",
    "trait_nodes = len(unique_traits)\n",
    "rsids_nodes = len(unique_rsids)\n",
    "total_nodes = trait_nodes + rsids_nodes\n",
    "node_types = torch.tensor([0] * trait_nodes + [1] * rsids_nodes, dtype=torch.long)\n",
    "\n",
    "print(\"Total number of nodes:\", total_nodes)\n",
    "print(\"Number of node types:\", len(node_types))\n",
    "\n",
    "assert len(node_types) == total_nodes, \"Mismatch in the number of nodes and node types\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b71e619-0319-446a-9b08-93ebaea8c008",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing edge data\n",
    "data_copy['lead'] = data_copy['lead'].fillna('N/A')  # Fill NaNs for 'lead' column\n",
    "data_copy['lead_codes'] = data_copy['lead'].cat.codes  # Now you can do the mapping\n",
    "\n",
    "edge_columns = ['rsids_codes', 'trait_codes', 'lead_codes', 'causal', 'LD']\n",
    "edges = data_copy[edge_columns]\n",
    "\n",
    "# Create edges based on 'causal' and 'LD' conditions\n",
    "positive_edges_snp_phenotype = edges[edges['causal'] == 1][['rsids_codes', 'trait_codes']].values.T\n",
    "negative_edges_snp_phenotype = edges[edges['causal'] == 0][['rsids_codes', 'trait_codes']].values.T\n",
    "positive_edges_snp_snp = edges[edges['LD'] == 1][['rsids_codes', 'lead_codes']].values.T\n",
    "negative_edges_snp_snp = edges[edges['LD'] == 0][['rsids_codes', 'lead_codes']].values.T\n",
    "\n",
    "# Combine all edges and their labels\n",
    "edges = np.concatenate([positive_edges_snp_phenotype, negative_edges_snp_phenotype, positive_edges_snp_snp, negative_edges_snp_snp], axis=1)\n",
    "edge_labels = np.concatenate([\n",
    "    np.full(positive_edges_snp_phenotype.shape[1], +1), # Label +1 for causal relationships in SNP-Phenotype edges\n",
    "    np.full(negative_edges_snp_phenotype.shape[1], -1), # Label -1 for non-causal relationships in SNP-Phenotype edges\n",
    "    np.full(positive_edges_snp_snp.shape[1], +1),       # Label +1 for linkage disequilibrium in SNP-SNP edges\n",
    "    np.full(negative_edges_snp_snp.shape[1], -1)        # Label -1 for non-linkage disequilibrium in SNP-SNP edges\n",
    "])\n",
    "\n",
    "edges = torch.from_numpy(edges)\n",
    "edge_labels = torch.from_numpy(edge_labels)\n",
    "\n",
    "# Print relevant information\n",
    "print(\"Positive SNP-Phenotype edges:\", positive_edges_snp_phenotype.shape[1])\n",
    "print(\"Negative SNP-Phenotype edges:\", negative_edges_snp_phenotype.shape[1])\n",
    "print(\"Positive SNP-SNP edges:\", positive_edges_snp_snp.shape[1])\n",
    "print(\"Negative SNP-SNP edges:\", negative_edges_snp_snp.shape[1])\n",
    "print(\"Final edges tensor:\", edges.size())\n",
    "print(\"Edge labels tensor:\", edge_labels.size())\n",
    "\n",
    "# Assertions\n",
    "assert edges.shape[0] == 2, \"Edges tensor should have shape (2, num_edges)\"\n",
    "assert edge_labels.ndim == 1, \"Edge labels tensor should be 1-dimensional\"\n",
    "assert edges.shape[1] == edge_labels.shape[0], \"Edges and edge_labels should have the same number of columns\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e68652f-4367-40dd-97f1-0354dd7a4bc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to encode and scale columns\n",
    "def process_columns(df, encode_cols, scale_cols):\n",
    "    # Encode columns\n",
    "    for col in encode_cols:\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "    # Scale columns\n",
    "    scaler = StandardScaler()\n",
    "    for col in scale_cols:\n",
    "        df[col] = scaler.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    return df\n",
    "\n",
    "# Preprocessing node features\n",
    "fill_values = {'nearest_genes': 'N/A', '#chrom': 'N/A', 'pos': 0, 'ref': 'N/A', 'alt': 'N/A', 'beta': 0, 'sebeta': 0, 'af_alt': 0, 'af_alt_cases': 0}\n",
    "node_features = fill_na(node_features, fill_values)\n",
    "\n",
    "# Define columns to be encoded and scaled\n",
    "categorical_columns = ['trait', 'rsids', 'nearest_genes', '#chrom', 'ref', 'alt']\n",
    "numerical_columns = ['pos', 'beta', 'sebeta', 'af_alt', 'af_alt_cases']\n",
    "\n",
    "# Process node features\n",
    "node_features = process_columns(node_features, categorical_columns, numerical_columns)\n",
    "\n",
    "# Convert to tensor\n",
    "node_features = torch.tensor(node_features.values, dtype=torch.float)\n",
    "\n",
    "# Compute edge attributes\n",
    "edge_attr = torch.tensor([0] * positive_edges_snp_phenotype.shape[1] + [0] * negative_edges_snp_phenotype.shape[1] + [1] * positive_edges_snp_snp.shape[1] + [1] * negative_edges_snp_snp.shape[1], dtype=torch.float)\n",
    "\n",
    "# Assertions\n",
    "assert node_features.ndim == 2, \"Node features tensor should have 2 dimensions\"\n",
    "assert edge_attr.ndim == 1, \"Edge attribute tensor should be 1-dimensional\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "55788dd6-84e2-43ef-9c84-64105f8a01a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert node features to tensor\n",
    "if isinstance(node_features, pd.DataFrame):\n",
    "    node_features_tensor = torch.tensor(node_features.values(), dtype=torch.float)\n",
    "else:\n",
    "    node_features_tensor = node_features\n",
    "\n",
    "# Create the PyTorch Geometric data object\n",
    "graph = Data(x=node_features_tensor, edge_index=edges, edge_attr=edge_attr)\n",
    "\n",
    "# Truncate the node_types tensor to match the adjusted number of nodes\n",
    "graph.node_types = node_types\n",
    "\n",
    "# Assertions\n",
    "assert graph.x.ndim == 2, \"Node features tensor should have 2 dimensions\"\n",
    "assert graph.edge_index.ndim == 2, \"Edge index tensor should have 2 dimensions\"\n",
    "assert graph.edge_attr.ndim == 1, \"Edge attribute tensor should be 1-dimensional\"\n",
    "assert graph.num_nodes == total_nodes, \"Number of nodes in the graph should match the total number of nodes\"\n",
    "assert graph.num_node_features == node_features_tensor.shape[1], \"Number of node features in the graph should match the number of columns in node_features\"\n",
    "assert graph.edge_index.size(1) == edges.shape[1], \"Number of edges in the graph should match the number of columns in edges\"\n",
    "assert graph.edge_attr.size(0) == graph.edge_index.size(1), \"Number of edge attributes should match the number of edges\"\n",
    "\n",
    "print(graph)\n",
    "print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "print(f\"Number of positive edges between SNPs and SNPs: {positive_edges_snp_snp.shape[1]}\")\n",
    "print(f\"Number of positive edges between SNPs and phenotypes: {positive_edges_snp_phenotype.shape[1]}\")\n",
    "print(f\"Number of negative edges for SNPs and SNPs: {negative_edges_snp_snp.shape[1]}\")\n",
    "print(f\"Number of negative edges for SNPs and phenotypes: {negative_edges_snp_phenotype.shape[1]}\")\n",
    "print(f\"Number of edges: {graph.num_edges}\")\n",
    "print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "print(f\"Node types: {graph.node_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60cae52-2493-43ae-9e27-e7dc67c3a7f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graph stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c98f83-a35d-4010-8adf-078fd4fbe799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph stats:\n",
      "Number of nodes: 18295392\n",
      "Number of positive SNP-SNP edges: 28\n",
      "Number of edges: 28\n",
      "Node feature dimension: 9\n",
      "Density: 0.0000000000\n",
      "Features with NaN values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree\n",
    "\n",
    "def print_graph_stats(graph, positive_edges_snp_snp):\n",
    "    print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "    print(f\"Number of positive SNP-SNP edges: {positive_edges_snp_snp.size(1)}\")\n",
    "    print(f\"Number of edges: {graph.num_edges}\")\n",
    "    print(f\"Node feature dimension: {graph.num_node_features}\")\n",
    "\n",
    "    # Compute and print degree-related stats\n",
    "    degrees = degree(graph.edge_index[0].long(), num_nodes=graph.num_nodes)\n",
    "    average_degree = degrees.float().mean().item()\n",
    "    median_degree = np.median(degrees.numpy())\n",
    "    std_degree = degrees.float().std().item()\n",
    "\n",
    "    # Assert average degree, median degree, and std degree\n",
    "    assert isinstance(average_degree, float), \"Average degree is not a float.\"\n",
    "    assert isinstance(std_degree, float), \"Standard deviation of degree is not a float.\"\n",
    "\n",
    "    # Density is the ratio of actual edges to the maximum number of possible edges\n",
    "    num_possible_edges = graph.num_nodes * (graph.num_nodes - 1) / 2\n",
    "    density = graph.num_edges / num_possible_edges\n",
    "\n",
    "    # Assert density\n",
    "    assert isinstance(density, float), \"Density is not a float.\"\n",
    "\n",
    "    print(f\"Density: {density:.10f}\")\n",
    "\n",
    "    # Check for NaN values in features\n",
    "    nan_mask = torch.isnan(graph.x)\n",
    "    nan_features = []\n",
    "    for feature_idx, feature_name in enumerate(snp_features.columns):\n",
    "        if nan_mask[:, feature_idx].any():\n",
    "            nan_features.append(feature_name)\n",
    "\n",
    "    print(\"Features with NaN values:\")\n",
    "    print(nan_features)\n",
    "\n",
    "# Print graph stats\n",
    "print(\"Graph stats:\")\n",
    "print_graph_stats(graph, positive_edges_snp_snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51e96d-660c-4b4f-8ac4-9a07dba5bcc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5650ea-db41-4f17-8599-86b148482867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[18295392, 9], edge_index=[2, 12], edge_attr=[12], pos_edge_label=[6], pos_edge_label_index=[2, 6], neg_edge_label=[6000], neg_edge_label_index=[2, 6000])\n",
      "Data(x=[18295392, 9], edge_index=[2, 12], edge_attr=[12], pos_edge_label=[11], pos_edge_label_index=[2, 11], neg_edge_label=[11000], neg_edge_label_index=[2, 11000])\n",
      "Data(x=[18295392, 9], edge_index=[2, 34], edge_attr=[34], pos_edge_label=[11], pos_edge_label_index=[2, 11], neg_edge_label=[11000], neg_edge_label_index=[2, 11000])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "transform = RandomLinkSplit(neg_sampling_ratio=1000, num_val=0.4, num_test=0.4, is_undirected=True, split_labels=True)\n",
    "\n",
    "graph_train, graph_val, graph_test = transform(graph)\n",
    "\n",
    "# Assert graph_train\n",
    "assert isinstance(graph_train, Data), \"graph_train is not an instance of torch_geometric.data.Data.\"\n",
    "assert graph_train.num_nodes == graph.num_nodes, \"Number of nodes in graph_train does not match the original graph.\"\n",
    "\n",
    "# Assert graph_val\n",
    "assert isinstance(graph_val, Data), \"graph_val is not an instance of torch_geometric.data.Data.\"\n",
    "\n",
    "# Assert graph_test\n",
    "assert isinstance(graph_test, Data), \"graph_test is not an instance of torch_geometric.data.Data.\"\n",
    "\n",
    "print(graph_train)\n",
    "print(graph_val)\n",
    "print(graph_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665050a-5cd9-4960-a2ef-8a4cf2cb5e40",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2557f-d84e-4a1b-bda8-7b26620f526b",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ae175ab-f1da-4ac9-bd1c-f180eb8e2313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 5.2066, Val ROC-AUC: 0.3837272727, Val Pos Edge Acc: 0.0019981835, Gamma: 2.00\n",
      "Epoch: 2, Loss: 2.0153, Val ROC-AUC: 0.4185702479, Val Pos Edge Acc: 0.0039963669, Gamma: 2.00\n",
      "Epoch: 3, Loss: 0.9119, Val ROC-AUC: 0.4283099174, Val Pos Edge Acc: 0.0063578565, Gamma: 2.00\n",
      "Epoch: 4, Loss: 0.4353, Val ROC-AUC: 0.4640578512, Val Pos Edge Acc: 0.0257947321, Gamma: 2.00\n",
      "Epoch: 5, Loss: 0.2331, Val ROC-AUC: 0.4620247934, Val Pos Edge Acc: 0.1169845595, Gamma: 2.10\n",
      "Epoch: 6, Loss: 0.1750, Val ROC-AUC: 0.5341818182, Val Pos Edge Acc: 0.3277020890, Gamma: 2.10\n",
      "Epoch: 7, Loss: 0.1620, Val ROC-AUC: 0.6257314050, Val Pos Edge Acc: 0.4739327884, Gamma: 2.10\n",
      "Epoch: 8, Loss: 0.1616, Val ROC-AUC: 0.6603884298, Val Pos Edge Acc: 0.4432334242, Gamma: 2.10\n",
      "Epoch: 9, Loss: 0.1618, Val ROC-AUC: 0.6789504132, Val Pos Edge Acc: 0.2521344233, Gamma: 2.10\n",
      "Epoch: 10, Loss: 0.1620, Val ROC-AUC: 0.6398181818, Val Pos Edge Acc: 0.0085376930, Gamma: 2.20\n",
      "Epoch: 11, Loss: 0.1511, Val ROC-AUC: 0.6257727273, Val Pos Edge Acc: 0.0019981835, Gamma: 2.30\n",
      "Epoch: 12, Loss: 0.1411, Val ROC-AUC: 0.6180371901, Val Pos Edge Acc: 0.0019981835, Gamma: 2.40\n",
      "Epoch: 13, Loss: 0.1318, Val ROC-AUC: 0.5987975207, Val Pos Edge Acc: 0.0019981835, Gamma: 2.50\n",
      "Epoch: 14, Loss: 0.1230, Val ROC-AUC: 0.5653140496, Val Pos Edge Acc: 0.0019981835, Gamma: 2.60\n",
      "Epoch: 15, Loss: 0.1148, Val ROC-AUC: 0.5081942149, Val Pos Edge Acc: 0.0019981835, Gamma: 2.70\n",
      "Epoch: 16, Loss: 0.1072, Val ROC-AUC: 0.4523842975, Val Pos Edge Acc: 0.0019981835, Gamma: 2.80\n",
      "Epoch: 17, Loss: 0.1000, Val ROC-AUC: 0.3961280992, Val Pos Edge Acc: 0.0019981835, Gamma: 2.90\n",
      "Epoch: 18, Loss: 0.0934, Val ROC-AUC: 0.3680578512, Val Pos Edge Acc: 0.0019981835, Gamma: 3.00\n",
      "Epoch: 19, Loss: 0.0872, Val ROC-AUC: 0.3562272727, Val Pos Edge Acc: 0.0019981835, Gamma: 3.10\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv, GINConv\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define the GCN model\n",
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GINConv(nn.Sequential(nn.Linear(hidden_channels, hidden_channels), nn.BatchNorm1d(hidden_channels), nn.LeakyReLU(), nn.Linear(hidden_channels, hidden_channels)))\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First conv layer\n",
    "        x1 = self.conv1(x, edge_index)\n",
    "        x1 = self.batchnorm1(x1)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        x1 = F.dropout(x1, p=0.5, training=self.training)\n",
    "        \n",
    "        # Second conv layer\n",
    "        x2 = self.conv2(x1, edge_index)\n",
    "        x2 = self.batchnorm2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "        x2 = F.dropout(x2, p=0.5, training=self.training)\n",
    "\n",
    "        # Third conv layer\n",
    "        x3 = self.conv3(x2, edge_index)\n",
    "        x3 = self.batchnorm3(x3)\n",
    "        x3 = F.leaky_relu(x3)\n",
    "\n",
    "        return x3 + x2 + x1  # Add residual connections\n",
    "\n",
    "# Continue with the rest of your training and evaluation code as before.\n",
    "\n",
    "\n",
    "# Train and evaluate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GCN(in_channels=9, hidden_channels=4).to(device)\n",
    "\n",
    "graph_train = graph_train.to(device)\n",
    "graph_val = graph_val.to(device)\n",
    "graph_test = graph_test.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "def compute_alpha_beta(targets):\n",
    "    num_positives = targets.sum()\n",
    "    num_samples = len(targets)\n",
    "    beta = num_positives / num_samples  # proportion of positive instances\n",
    "    alpha = 1 - beta  # proportion of negative instances\n",
    "    return alpha, beta\n",
    "\n",
    "def compute_adaptive_gamma(val_roc_auc, prev_val_roc_auc, gamma, increment_factor=0.1):\n",
    "    if val_roc_auc < prev_val_roc_auc:  # If the performance decreases, increase gamma\n",
    "        gamma += increment_factor\n",
    "    return gamma\n",
    "\n",
    "# Train function\n",
    "def train(prev_val_roc_auc, gamma):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model(graph_train.x.float(), graph_train.edge_index)\n",
    "\n",
    "    # Only consider positive edges for the positive score calculation\n",
    "    pos_edge_index = graph_train.pos_edge_label_index\n",
    "    pos = (z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    # Use the pre-generated negative labels\n",
    "    neg_edge_index = graph_train.neg_edge_label_index\n",
    "    neg = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    logits = torch.cat([pos, neg], dim=0)\n",
    "    targets = torch.tensor([1] * pos.size(0) + [0] * neg.size(0), dtype=torch.float32).to(device)\n",
    "\n",
    "    # Compute dynamic alpha and beta\n",
    "    alpha, beta = compute_alpha_beta(targets)\n",
    "\n",
    "    # Apply Focal Loss\n",
    "    bce_loss = BCEWithLogitsLoss(reduction='none')\n",
    "    bce = bce_loss(logits, targets)\n",
    "    pt = torch.exp(-bce)  # Compute the focal term\n",
    "    focal_loss = (alpha * (1 - pt) ** gamma * bce).mean()  # Compute the focal loss\n",
    "\n",
    "    focal_loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    optimizer.step()\n",
    "    return focal_loss.item()\n",
    "\n",
    "def pos_edge_accuracy(preds, true_labels):\n",
    "    # Get predictions and true labels for positive edges\n",
    "    pos_preds = preds[:len(true_labels)//2]\n",
    "    pos_labels = true_labels[:len(true_labels)//2]\n",
    "\n",
    "    # Convert predictions to binary labels\n",
    "    bin_preds = (pos_preds > 0.5).astype(int)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    accuracy = (bin_preds == pos_labels).mean()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(graph):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(graph.x.float(), graph.edge_index)\n",
    "\n",
    "        pos_edge_index = graph.pos_edge_label_index\n",
    "        pos = torch.sigmoid((z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=-1)).view(-1)\n",
    "\n",
    "        neg_edge_index = graph.neg_edge_label_index\n",
    "        neg = torch.sigmoid((z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=-1)).view(-1)\n",
    "\n",
    "        preds = torch.cat([pos, neg]).cpu().numpy()\n",
    "        true_labels = np.concatenate([np.ones_like(pos.cpu().numpy()), np.zeros_like(neg.cpu().numpy())])\n",
    "\n",
    "        # Handle NaN values\n",
    "        preds = np.nan_to_num(preds, nan=0.5)\n",
    "\n",
    "        roc_auc = roc_auc_score(true_labels, preds)\n",
    "        pos_edge_acc = pos_edge_accuracy(preds, true_labels)\n",
    "\n",
    "        return roc_auc, pos_edge_acc\n",
    "\n",
    "\n",
    "gamma = 2.0  # Starting value for gamma\n",
    "prev_val_roc_auc = 0.0  # Initial performance value\n",
    "best_val_roc_auc = 0.0  # Best validation ROC-AUC score\n",
    "early_stop = 10  # Number of epochs to continue without improvement before stopping\n",
    "epochs_no_improve = 0  # Counter for epochs without improvement\n",
    "\n",
    "for epoch in range(150):\n",
    "    loss = train(prev_val_roc_auc, gamma)\n",
    "    torch.cuda.empty_cache()  # Release unnecessary GPU memory\n",
    "    scheduler.step()\n",
    "    with torch.no_grad():  # Use torch.no_grad() during training\n",
    "        val_roc_auc, val_pos_edge_acc = evaluate(graph_val)\n",
    "        gamma = compute_adaptive_gamma(val_roc_auc, prev_val_roc_auc, gamma)\n",
    "        prev_val_roc_auc = val_roc_auc\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss:.4f}, Val ROC-AUC: {val_roc_auc:.10f}, Val Pos Edge Acc: {val_pos_edge_acc:.10f}, Gamma: {gamma:.2f}\")\n",
    "    if val_roc_auc > best_val_roc_auc:\n",
    "        best_val_roc_auc = val_roc_auc\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve == early_stop:\n",
    "        print(\"Early stopping!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9091d3a7-575b-4240-b65c-197cd787b666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
